# 고급 백엔드 스터디 9주차

- Recovery (pp. 157 - 164) (8p)
- Concurrency Control (pp. 165 - 176)
  ◦ Serializability
  ◦ Transaction Isolation
  ◦ Read and Write Anomalies
  ◦ Isolation Levels

## Concurrency Control

### Concurrency Control

“DBMS Architecture”에서 DBMS 아키텍처를 논의할 때, 트랜잭션 관리자와 락 관리자가 협력하여 동시성 제어를 처리한다고 언급했습니다. 동시성 제어는 동시에 실행되는 트랜잭션 간의 상호작용을 처리하기 위한 여러 기법들의 집합입니다. 이러한 기법들은 대략 다음과 같은 범주로 나눌 수 있습니다.

- 앞에서 1주차 DBMS 아키텍쳐 세션에서 트랜잭션 매니저와 락 매니저가 동시성 제어, 즉 병행 제어에 쓰인다고 했었음.
  - “트랜잭션 관리자와 락 관리자는 함께 동시성 제어(concurrency control)를 담당합니다. 이들은 논리적 및 물리적 데이터 무결성을 보장하는 동시에, 동시 실행되는 작업들이 가능한 한 효율적으로 수행되도록 합니다.”

**낙관적 동시성 제어(Optimistic concurrency control, OCC)**

트랜잭션들이 동시에 읽기 및 쓰기 연산을 수행하도록 허용하고, 이들의 실행 결과가 직렬화 가능한지 여부를 결정합니다. 다시 말해, 트랜잭션들은 서로를 차단하지 않고, 자신들의 연산 이력을 유지한 뒤 커밋 전에 이러한 이력들에서 발생 가능한 충돌을 검사합니다. 실행 결과가 충돌을 일으키는 경우, 충돌한 트랜잭션 중 하나는 중단(abort)됩니다.

- 트랜잭션들은 동시에 실행되며, 읽기와 쓰기 모두 병렬로 수행 가능
- 병렬 실행된 결과가 직렬화 가능(serializable, ‘직렬화 성질’을 가진다 라고도 표현)한지 여부를 커밋 시점에 판단
- 직렬화 가능성이 없다면 충돌로 간주
- 트랜잭션 간에 락을 통해 차단하지 않음 → 높은 병렬성
- 어떻게?
  - 각 트랜잭션은 자신의 읽기/쓰기 이력(read set / write set) 을 추적함
  - 커밋 직전에 다른 트랜잭션들과의 충돌을 검증(validation)
  - 예: 내가 읽은 값이 이후에 다른 트랜잭션에 의해 쓰였는지…
  - 만약 읽은 값이 변경됨 등 충돌이 발견되면, 트랜잭션 중 하나가 중단됨 (보통 후속 트랜잭션)

**다중 버전 동시성 제어(Multiversion concurrency control, MVCC)**

MVCC는 하나의 레코드에 대해 타임스탬프가 부여된 여러 버전을 존재하게 함으로써, 과거의 특정 시점에서 일관된 데이터베이스 뷰를 보장합니다. MVCC는 검증 기법을 사용하여 갱신하거나 커밋하려는 트랜잭션 중 하나만 성공하도록 하여 구현할 수 있으며, 타임스탬프 순서 기반과 같은 락이 없는(lockless) 방식이나, 2단계 잠금(two-phase locking)과 같은 락 기반(lock-based) 방식으로도 구현할 수 있습니다.

- 각 트랜잭션은 자신이 시작할 당시의 상태를 일관되게 관찰
- "타임스탬프 기반 스냅샷"이라고도 부름
- 하나의 레코드에 대해 과거와 현재의 여러 버전(값) 이 존재 가능
- 예: 값 A가 트랜잭션 T1에 의해 변경되었어도, T2는 그 이전 버전을 읽을 수 있음
- OCC와 유사한 검증 기법으로 충돌 방지 수행.
- 가령, 쓰기를 시도할 때, 동시에 쓰는 트랜잭션이 있다면 하나만 커밋을 허용
- 마찬가지로 락 없이, 각 트랜잭션의 타임스탬프 순서로 충돌을 해결
- 더 늦게 시작한 트랜잭션이 이전 트랜잭션의 변경을 보지 않도록 제한
- 물론 락을 사용하는 MVCC도 가능. PostgreSQL은 2PL 기반으로 MVCC 일부 구현

**비관적(보수적) 동시성 제어(Pessimistic concurrency control, PCC)**

공유 자원에 대한 접근을 어떻게 관리하고 허용하느냐에 따라, 락 기반 방식과 비락(nonlocking) 보수적 방식 모두 존재합니다. 락 기반 접근법은 트랜잭션이 데이터베이스 레코드에 락을 유지하도록 하여, 다른 트랜잭션이 해당 레코드를 수정하거나, 수정 중인 레코드에 접근하지 못하도록 합니다. 비락 방식은 읽기 및 쓰기 연산 리스트를 유지하고, 완료되지 않은 트랜잭션의 스케줄에 따라 실행을 제한합니다. 비관적 스케줄링은 여러 트랜잭션이 서로 락 해제를 기다리는 경우 교착 상태(deadlock)가 발생할 수 있습니다.

- 낙관적 접근과 정반대 방식.
- 두 가지 구현 방법이 있음:
  1. 락 기반(lock-based): 가장 일반적인 방식 (e.g., 2PL)
     - 트랜잭션은 접근 중인 레코드에 락을 걸고 유지
     - 다른 트랜잭션의 접근을 차단하여 일관성 유지
     - 락이 걸린 레코드는 수정도, 접근도 불가능
     - 일반적으로 읽기/쓰기 락 구분 (공유/배타적)
  2. 락 없는(nonlocking) 방식도 존재 → 연산 순서를 제한하거나 충돌 방지를 위한 스케줄링
     - 락을 사용하지 않고, 연산 목록을 추적하면서 충돌 가능성이 있는 실행을 제한
     - 아직 끝나지 않은 트랜잭션과 충돌 가능성 있는 연산을 실행하지 않음
     - 여러 트랜잭션이 서로의 락 해제를 기다릴 수 있음 → 교착 상태
     - 따라서 PCC에서는 교착 상태 탐지 혹은 회피가 중요함

→ OCC, MVCC, PCC 등에 대한 자세한 내용은 다음 주 서브섹션에서 따로 다룰 예정. 이런 게 있다 정도로만.

이번 장에서는 노드 로컬 수준의 동시성 제어 기법에 집중합니다. 분산 트랜잭션 및 Calvin과 같은 결정적 동시성 제어(deterministic concurrency control)를 포함한 기타 접근법에 대해서는 13장에서 확인할 수 있습니다.

동시성 제어에 대해 더 논의하기 전에, 우리가 해결하려는 문제들을 정의하고, 트랜잭션 연산들이 어떻게 겹쳐질 수 있는지, 그리고 이러한 겹침이 어떤 결과를 초래하는지를 살펴볼 필요가 있습니다.

- 이 장에서는 단일 노드 내에서의 동시성 제어가 주제. 분산 시스템의 복잡성은 다루지 않음
- 복수 노드(클러스터 등)에서의 동시성 제어는 이후 장(13장)에서 다룸
- 예: Two-Phase Commit, Calvin 등 분산 트랜잭션 프로토콜
  - Calvin은 결정적 방식의 동시성 제어 →트랜잭션 순서를 미리 정해두고 해당 순서대로 실행함. 레플리카, 장애 복구 등에 유리
- 동시성 제어의 핵심 목적/문제점을 먼저 정의해야 함.
  - 여러 트랜잭션이 같은 데이터에 접근하는 경우의 충돌 시나리오
  - 이 겹침(overlap)이 일관성, 무결성 등에 어떤 영향을 주는지 분석할 예정

### Serializability

트랜잭션은 데이터베이스 상태에 대해 실행되는 읽기 및 쓰기 연산과, 읽은 내용에 적용되는 비즈니스 로직(변환)으로 구성됩니다. 스케줄(schedule)이란 트랜잭션 집합을 실행하기 위해 필요한 연산들의 목록으로, 데이터베이스 시스템의 관점에서 정의됩니다. 즉, 읽기, 쓰기, 커밋, 중단(abort)과 같이 데이터베이스 상태에 영향을 미치는 연산만 포함하며, 그 외의 연산은 부작용이 없는 것으로 간주됩니다. 다시 말해, 데이터베이스 상태에 영향을 주지 않는다고 봅니다 [MOLINA08].

- 트랜잭션의 구성 요소는 두 가지임:
  - (1) 데이터베이스에 직접 접근하는 **읽기(read)** 및 **쓰기(write)** 연산
  - (2) 읽어온 데이터를 가공하거나 판단하는 **비즈니스 로직(transformations)**
- **스케줄**이란 여러 트랜잭션의 연산을 시간 순서대로 나열한 것
  - 다만 모든 연산이 포함되는 것은 아님
    - DBMS는 오직 **데이터베이스 상태에 영향을 미치는 연산만 추적**
  - 따라서 비즈니스 로직 등 **논리 연산이나 메모리 내 처리 과정은 포함되지 않음**
  - 포함되는 연산 예:
    - `read`: 데이터 읽기
    - `write`: 데이터 쓰기
    - `commit`: 트랜잭션 커밋 (변경사항 반영)
    - `abort`: 트랜잭션 중단 (변경사항 롤백)
  - 그 외 연산들은 다음과 같은 이유로 무시됨:
    - DB 상태를 변화시키지 않음
    - 시스템 외부의 계산 또는 임시 변수 처리처럼 부작용(side-effect) 이 없는 작업
- DBMS의 시점에서 보면, 실제로 **디스크의 데이터나 캐시된 상태를 바꾸지 않는 연산은 추적 대상이 아님**

스케줄은 해당 스케줄에서 실행된 모든 트랜잭션의 모든 연산을 포함할 경우 완전하다고 말합니다. 올바른 스케줄이란, 원래의 연산 목록과 논리적으로 동등하지만, ACID 속성과 개별 트랜잭션 결과의 정확성을 위배하지 않는 한, 그 일부 연산이 병렬로 실행되거나 최적화를 위해 순서가 재조정될 수 있는 스케줄을 의미합니다 [WEIKUM01].

- 스케줄(schedule)은 트랜잭션의 연산들이 시간 순서대로 나열된 목록임
- 올바른 스케줄(correct schedule)의 핵심:
  - 개별 트랜잭션의 수행 결과와 시스템 전체의 일관성이 직렬 실행과 동일하게 유지됨
  - **즉, 실제 실행 순서가 바뀌거나 병렬로 실행되더라도, 결과만큼은 직렬 실행과 같아야 함**
  - 논리적으로 동등(logical equivalence)하다는 의미?
    - 트랜잭션 실행의 결과(DB 상태, 사용자 입장)만 놓고 보면 동일
    - 즉, 내부적으로 연산 순서가 바뀌었어도 효과가 같다면 허용됨
  - 단, 전제 조건은 두 가지
    1. ACID 속성 위배 금지
       - 예: atomicity 보장되지 않으면 부분 커밋이 발생할 수 있음
    2. 각 트랜잭션의 결과 정확성 유지
       - 예: 트랜잭션 1의 계산 결과가 외부에 잘못 노출되면 안 됨
  - 이를 지킨다면 트랜잭션을 병렬로 실행하거나 심지어 순서를 재조정하여 실행할 수도 있음

트랜잭션들이 완전히 독립적으로, 그리고 서로 뒤섞이지 않고 실행될 경우, 해당 스케줄은 직렬 스케줄(serial schedule)이라고 합니다. 즉, 앞선 트랜잭션이 완전히 실행을 마친 후에 다음 트랜잭션이 시작됩니다. 직렬 실행은 여러 단계로 이루어진 트랜잭션들 사이에서 가능한 모든 뒤섞임(interleaving)과 비교했을 때, 이해하기 쉬운 실행 방식입니다. 그러나 항상 트랜잭션들을 하나씩 순차적으로 실행한다면, 시스템 처리량은 크게 제한되고 성능에 악영향을 미치게 됩니다.

- 직렬 스케줄(serial schedule)의 정의
  - 트랜잭션 간에 연산이 겹치지 않음 (interleaving 없음)
  - 하나의 트랜잭션이 시작되면, 그것이 모두 끝난 다음에야 다음 트랜잭션이 시작됨
  - 이 방식은 동시성(concurrency)이 전혀 없는 상태
  - T1 → T2 → T3 순으로 트랜잭션이 존재할 때, 반드시 T1이 모든 연산(read, write, commit 등) 을 마친 후 T2 시작
  - 어떤 트랜잭션도 중간 상태에서 다른 트랜잭션과 겹쳐 실행되지 않음
- “여러 단계로 이루어진 트랜잭션들 사이에서 가능한 모든 뒤섞임(interleaving)과 비교했을 때, 이해하기 쉬운 실행 방식”
  - 직렬 실행은 정형화된 순서이므로 이해·분석이 쉬움
- 하지만 직렬 실행은 병렬성(parallelism)을 전혀 활용하지 못함
  - 병목 현상 발생 → 하나의 트랜잭션이 오래 걸리면 전체 대기
  - 실제 시스템에서는 직렬화 가능한 동시에 병렬 실행도 허용하는 스케줄이 필요 → 직렬 스케쥴의 직렬 가능성만 취하면서도 병렬 실행을 하고 싶음

트랜잭션 연산들을 동시에 실행하면서도, 직렬 스케줄의 정확성과 단순성을 유지할 수 있는 방법을 찾아야 합니다. 이는 직렬가능 스케줄(serializable schedule)을 통해 달성할 수 있습니다. 스케줄이 직렬가능하다는 것은, 동일한 트랜잭션 집합에 대해 어떤 완전한 직렬 스케줄과 논리적으로 동등하다는 의미입니다. 다시 말해, 해당 스케줄이 트랜잭션들을 어떤 순서로든 하나씩 순차적으로 실행했을 때와 같은 결과를 만들어낸다는 뜻입니다. 그림 5-4는 세 개의 병행 트랜잭션과, 이들의 가능한 실행 이력(총 3! = 6가지 순서)을 보여줍니다.

- trade-off 고려
  - 직렬 실행은 단순하고 안전하지만 성능이 낮음
  - 병렬 실행은 성능이 좋지만 일관성 보장이 어려움
  - 따라서 **동시 실행 + 직렬 실행과 같은 결과**라는 균형점을 찾아야 함 → 직렬 가능 스케쥴
- ‘직렬 가능하다’의 의미 = “동일한 트랜잭션 집합에 대해 어떤 완전한 직렬 스케줄과 논리적으로 동등하다”
  - 여기서 말하는 “**논리적으로 동등**“하다는 것은:
    - 트랜잭션 결과와 DB 상태가 **직렬 스케줄과 동일**하다는 뜻
    - 즉, 사용자 입장에서 보면 순차 실행한 것과 구분되지 않음
  - 직렬가능 스케줄은 병렬 실행을 허용하지만, 항상 **어떤 직렬 순서 하나**와 동일한 결과를 보장해야 함 (즉 순서대로 실행한 것과 같은 결과를 내야 함)
    - 이러한 표현을 쓰는 게 좀 어색할 수 있음…
    - 즉 병렬 수행을 하면 예상치 못한 다양한 결과가 나올 수 있음. 이 다양한 결과 중에서 해당 트랜잭션을 직렬로 수행한 결과들 중 하나와 일치하는 결과를 내야 한다는 뜻.
  - 반대로 생각하면 3개의 트랜잭션을 가지고 6개의 직렬 스케쥴을 만들 수 있는데, 이 셋을 병렬로 실행했을 때 저 6개 중 하나와 일치하는 결과를 내야 함. 이게 직렬 가능하다는 뜻.

![image.png](%E1%84%80%E1%85%A9%E1%84%80%E1%85%B3%E1%86%B8%20%E1%84%87%E1%85%A2%E1%86%A8%E1%84%8B%E1%85%A6%E1%86%AB%E1%84%83%E1%85%B3%20%E1%84%89%E1%85%B3%E1%84%90%E1%85%A5%E1%84%83%E1%85%B5%209%E1%84%8C%E1%85%AE%E1%84%8E%E1%85%A1%20229998e1b70980e9bc1dc0a642271e7b/image.png)

### Transaction Isolation

트랜잭션을 지원하는 데이터베이스 시스템은 다양한 격리 수준을 허용합니다. 격리 수준(isolation level)은 트랜잭션의 일부 결과가 다른 트랜잭션에 언제, 어떻게 보일 수 있는지를 정의합니다. 다시 말해, 격리 수준은 하나의 트랜잭션이 동시에 실행 중인 다른 트랜잭션으로부터 얼마나 격리되어 있는지, 그리고 실행 중에 어떤 종류의 이상(anomaly)이 발생할 수 있는지를 설명합니다.

- 격리 수준 → 병렬 실행되는 트랜잭션이 얼마나 영향을 받지 않게 할 것인지 그 정도를 조정함.
- ‘읽거나 수정한 값’이 ‘ 다른 트랜잭션에게 ‘언제 어떻게’ 보일지를 결정
- “얼마나 격리되어 있는가” = 즉 동시 실행되는 트랜잭션과 데이터 공유를 얼마나 제한할 것인가
  - 낮은 격리 수준에서는:
    - dirty read, non-repeatable read, phantom read 등의 이상 현상(anomalies) 이 발생 가능
  - 높은 격리 수준일수록:
    - 격리는 강력해지지만 성능은 떨어짐

격리를 달성하는 데는 대가가 따릅니다. 미완료되었거나 일시적인 쓰기 결과가 트랜잭션 경계를 넘어 전파되지 않도록 하려면, 추가적인 조정(coordination)과 동기화(synchronization)가 필요하며, 이는 성능에 부정적인 영향을 미칩니다.

- “미완료되었거나 일시적인 쓰기 결과가 트랜잭션 경계를 넘어 전파되지 않도록 하려면” → 즉 중간 단계에서의 상태는 원자성에 의해 트랜잭션 경계 바깥에서 관측되지 않아야 함
- 격리 수준이 높을수록 → 시스템이 더 많은 조율, 제어, 동기화를 해야 함
  - 가령 쓰기 연산이 커밋될 때까지 다른 트랜잭션이 접근하지 못하게 하거나, 반복된 읽기를 동일하게 보장하기 위해 버전을 관리함
  - 이로 인해 지연(latency) 이 생기고, 처리량(throughput) 도 줄어들 수 있음

### Read and Write Anomalies

SQL 표준 [MELTON06]에서는 동시 실행되는 트랜잭션들 간에 발생할 수 있는 읽기 이상(read anomalies)을 다음과 같이 정의하고 설명합니다: 더티 읽기(dirty read), 반복 불가능한 읽기(nonrepeatable read), 팬텀 읽기(phantom read).

더티 읽기(dirty read)란, 한 트랜잭션이 다른 트랜잭션의 커밋되지 않은 변경사항을 읽을 수 있는 상황을 말합니다. 예를 들어, 트랜잭션 T1이 사용자 레코드의 주소 필드를 새로운 값으로 갱신하고, 트랜잭션 T2가 T1이 커밋하기 전에 그 갱신된 주소를 읽었다고 가정합니다. 이후 T1이 중단되고 실행 결과를 롤백합니다. 그러나 T2는 이미 해당 값을 읽었기 때문에, 커밋되지 않은 값을 접근한 셈이 됩니다.

- “커밋되지 않은 변경사항”은 **취소될 수 있는 임시 상태**이므로, 이를 읽는 것은 **위험한 동작**
- T1이 아직 커밋되지 않은 상태에서 address 값을 수정한다고 해보자
  - 이 시점에서 T1의 변경사항은 **다른 트랜잭션에는 보이지 않아야 안전함**
- 격리 수준이 낮다면, T2는 T1의 갱신 결과를 **커밋 전에** 읽을 수 있음
  - 이 경우 T2는 **더티 데이터에 접근한 것**
- T1이 어떤 이유로 **abort**되고, 수정한 내용이 **되돌려짐**
  - address 필드는 원래 값으로 복구됨
- T2는 더 이상 유효하지 않은, **존재하지 않는 값**을 읽은 상태
  - 이로 인해 T2의 로직, 계산, 판단 등이 **잘못된 데이터에 기반해 동작**할 수 있음 → 이후 더티 쓰기에서 이어서 설명

반복 불가능한 읽기(nonrepeatable read, 때때로 fuzzy read라고도 불림)란, 하나의 트랜잭션이 동일한 행(row)을 두 번 조회했을 때 서로 다른 결과를 얻는 상황을 말합니다. 예를 들어, 트랜잭션 T1이 어떤 행을 조회하고, 이후 트랜잭션 T2가 그 행을 수정한 뒤 커밋하는 경우를 생각해봅니다. 만약 T1이 실행을 끝내기 전에 동일한 행을 다시 요청한다면, 이전과는 다른 결과를 얻게 됩니다.

- 이 anomaly는 한 트랜잭션이 **동일한 쿼리를 두 번 실행했는데도 결과가 바뀌는 경우**
- “nonrepeatable”이라는 이름 그대로, **반복해서 읽을 수 없는(read가 repeat되지 않는)** 상황
- 일반적으로 READ COMMITTED 수준에서 발생할 수 있음
- T1이 첫 번째로 해당 row를 읽었을 때, 예를 들어 user.balance = 100
- T2는 같은 행을 수정 (예: balance = 200) 후 **커밋**
- T1보다 **나중에 시작했지만 더 빨리 커밋된 트랜잭션**
- T1이 다시 balance를 읽었을 때는 이미 **T2의 커밋 결과**를 보게 됨
  - 첫 번째 읽기: 100
  - 두 번째 읽기: 200
- 즉, T1 내부에서 **동일한 조건의 SELECT 결과가 달라짐**

유사한 의미를 가지는 쓰기(write) 이상들도 존재합니다. 대표적으로는 손실된 갱신(lost update), 더티 쓰기(dirty write), 쓰기 왜곡(write skew)가 있습니다.

- 지금까지 설명된 **읽기 이상(anomalies)** 외에도, 트랜잭션의 **쓰기 작업**과 관련된 오류적 실행도 존재함. 이러한 쓰기 이상도 동시성 제어와 격리 수준 설정의 주요 이유

손실된 갱신(lost update)은 트랜잭션 T1과 T2가 모두 값 V를 갱신하려고 시도할 때 발생합니다. T1과 T2는 V의 값을 읽습니다. T1이 V를 갱신하고 커밋하고, 그 이후 T2도 V를 갱신한 뒤 커밋합니다. 두 트랜잭션은 서로의 존재를 알지 못하므로, 둘 다 커밋이 허용되면 T1의 결과는 T2의 결과에 의해 덮어써지게 되어 T1의 갱신이 손실됩니다.

- 손실된 갱신(lost update)은 트랜잭션 T1과 T2가 모두 값 V를 갱신하려고 시도할 때 발생합니다.
  - 동일 데이터 항목 V에 대해 동시에 쓰기 경쟁이 일어남
  - 문제 핵심: 직후의 커밋 순서에 따라 이전 갱신이 사라질 위험
- T1과 T2는 V의 값을 읽습니다.
  - 두 트랜잭션 모두 초기값을 기반으로 작업 시작
  - 아직 서로의 존재나 진행 상황을 알 수 없음
- T1이 V를 갱신하고 커밋하고, 그 이후 T2도 V를 갱신한 뒤 커밋합니다.
  - 실행·커밋 순서: T1 먼저, T2 나중
  - T2의 갱신 시점에서 매우 구형(old) 값을 토대로 수정 수행
- 두 트랜잭션은 서로의 존재를 알지 못하므로, 둘 다 커밋이 허용되면 T1의 결과는 T2의 결과에 의해 덮어써지게 되어 T1의 갱신이 손실됩니다.
  - 동시성 제어 부재 시 최종값은 T2가 기록한 값
  - T1 변경 내용은 영원히 사라져 데이터 무결성 훼손
- → 보통 갱신 분실이라고 표현하는듯.

더티 쓰기(dirty write)는 한 트랜잭션이 커밋되지 않은 값(즉, 더티 읽기로 얻은 값)을 가져와 수정한 뒤 저장하는 상황을 말합니다. 다시 말해, 트랜잭션 결과가 한 번도 커밋된 적이 없는 값에 기반할 때 발생합니다.

- 커밋되지 않은 값 (아직 확정되지 않은 임시 데이터, 롤백될 가능성이 있음) << 더티 읽기에서 얻은 값
- 읽은 값이 확정되지 않았는데 (즉 한 번도 커밋되지 않았는데) 그대로 쓰기로 이어짐

쓰기 왜곡(write skew)은 각 개별 트랜잭션은 요구되는 불변조건을 만족하지만, 그 조합이 이러한 불변조건을 충족하지 못할 때 발생합니다. 예를 들어, 트랜잭션 T1과 T2가 두 개의 계좌 A1과 A2의 값을 수정합니다. A1은 100달러로 시작하고 A2는 150달러로 시작합니다. 각 계좌 값은 A1 + A2 ≥ 0이라는 조건, 즉 두 계좌의 합이 음수가 아니기만 하면 음수가 되어도 허용됩니다. T1과 T2는 각각 A1과 A2에서 200달러를 출금하려고 합니다. 이 트랜잭션들이 시작될 때 A1 + A2 = 250달러이므로, 총 250달러가 사용 가능합니다. 두 트랜잭션 모두 자신들이 불변조건을 지키고 있다고 가정하여 커밋이 허용됩니다. 그러나 커밋 후에는 A1이 -100달러, A2가 -50달러가 되어, 두 계좌의 합을 양수로 유지해야 한다는 요구사항을 명백히 위반합니다 [FEKETE04].

- 개별 트랜잭션의 관점
  - 각 트랜잭션은 **로컬 불변조건**(invariant)을 검사·충족한 뒤 커밋
  - 예: `balance ≥ 0` 조건을 확인하고 통과
- 전체 시스템 관점
  - 동시에 커밋된 여러 트랜잭션의 **합성 결과**가 전역 불변조건을 위반
  - 가령 잔액이 70원인데, 두 트랜잭션이 각각 다른 계좌에서 70씩 인출 → 각 계좌는 ≥ 0이지만 총합 -40으로 음수
- 즉 쓰기 왜곡(write skew)은 각 개별 트랜잭션은 요구 불변조건을 만족하지만, 함께 커밋되면 조건 위반이 발생. 트랜잭션 간 전역 불변조건 검증 부재로 인해 문제 생김
  - 예를 들어, 트랜잭션 T1과 T2가 두 계좌 A1, A2를 수정함
    - **동일 시점**에 각기 다른 계좌를 대상으로 작업 수행
  - A1은 100달러, A2는 150달러로 시작함
    - 초기 합계 250달러
    - 각 계좌는 개별적으로 양수 상태
  - 불변조건: **A1 + A2 ≥ 0**이면 각 계좌는 음수 허용
    - 전역 합만 양수 유지하면 시스템 일관성 유지된다고 정의됨
  - T1과 T2는 각각 A1, A2에서 200달러 출금 시도함
    - T1: A1 → -100달러
    - T2: A2 → -50달러
- 트랜잭션 시작 시점 합계 250달러 → 인출 가능 판단함
  - 각 트랜잭션 **로컬 조건 검사 통과**
  - 서로의 출금 계획 인지하지 못함
- 두 트랜잭션 모두 조건을 지킨다고 판단하여 커밋 허용됨
  - 동시 커밋으로 인해 전역 상태 검증 생략
  - Snapshot Isolation 등에서 빈번히 발생
- 커밋 후 A1 = -100달러, A2 = -50달러 → 합계 -150달러
  - 전역 불변조건 **A1 + A2 ≥ 0** 위반
  - 쓰기 왜곡은 **전역 일관성 훼손**의 대표 사례

### Isolation Levels

가장 낮은(다시 말해, 가장 약한) 격리 수준은 Read Uncommitted입니다. 이 격리 수준에서는 하나의 트랜잭션이 다른 동시 실행 중인 트랜잭션의 커밋되지 않은 변경사항을 관찰할 수 있습니다. 다시 말해, 더티 읽기가 허용됩니다.

- 격리 수준은 낮을수록 동시성은 높고 보호 기능은 약화됨
- Read Uncommitted는 네 가지 ANSI 격리 단계 중 최하위 단계에 해당함
  - 아직 확정되지 않은(롤백될 가능성이 있는) 데이터가 외부에 노출됨
  - 즉, 더티 읽기가 발생할 수 있게 됨

우리는 일부 이상 현상을 피할 수 있습니다. 예를 들어, 특정 트랜잭션에 의해 수행되는 모든 읽기 연산이 이미 커밋된 변경만을 읽도록 보장할 수 있습니다. 그러나 트랜잭션이 이후 시점에 동일한 데이터 레코드를 다시 읽으려 할 때도 동일한 값을 보게 된다는 보장은 없습니다. 두 번의 읽기 사이에 커밋된 수정이 있었다면, 동일한 트랜잭션의 두 쿼리는 서로 다른 결과를 산출할 것입니다. 다시 말해, 더티 읽기는 허용되지 않지만, 팬텀 읽기와 반복 불가능한 읽기는 허용됩니다. 이 격리 수준을 Read Committed라 부릅니다. 만약 반복 불가능한 읽기까지 금지한다면, 우리는 Repeatable Read 격리 수준을 얻게 됩니다.

- “예를 들어, 특정 트랜잭션에 의해 수행되는 모든 읽기 연산이 이미 커밋된 변경만을 읽도록 보장할 수 있습니다.”
  - 더티 읽기 문제는 커밋되지 않은 데이터를 읽기 때문이 발생함
  - 그렇다면 커밋된 변경사항만을 보게 한다면? 더티 읽기 이상현상을 해결할 수 있음
- “그러나 트랜잭션이 이후 시점에 동일한 데이터 레코드를 다시 읽으려 할 때도 동일한 값을 보게 된다는 보장은 없습니다.”
  - 만약 같은 트랜잭션에서 같은 데이터를 대상으로 한다 하더라도, 다시 조회한다면 다른 값이 나올 수도 있음.
  - 왜? 두 읽기 사이에 시간 간격이 있고, 이 사이에 변경사항이 발생했을 수도 있기 때문.
  - 이걸 Nonrepeatable Read 이상현상이라고 함
- “다시 말해, 더티 읽기는 허용되지 않지만, 팬텀 읽기와 반복 불가능한 읽기는 허용됩니다.”
  - Nonrepeatable Read는 방금 봤는데, Phantom Read는 이 문장에서 처음 등장함. 팬텀 리드가 뭘까?
  - 팬텀 리드 → 첫 번째 쿼리에서 보이지 않던 새로운 행이 등장하는 것. 논리피터블 리드와 다른 점은 ‘단건 읽기’에서 ‘행 내부의 값’이 바뀌냐 아니면 ‘다건 읽기’에서 ‘결과 집합 행의 개수’가 바뀌냐’인 것임.
  - 하지만 둘을 분리된 아노말리로 생각해야 하긴 함.
- 이렇게 더티 리드는 막되 논리피터블 리드와 팬텀 리드는 못 막는 수준을 Read Commited라고 함. 즉 커밋된 데이터를 읽는다는 것
- 여기서 더 나아가 논리피터블 리드를 막는다면 격리 수준은 Repeatable Read가 됨. 하지만 팬텀 리드는 여전히 발생
  - “MVCC 기반 DB는 보통 팬텀도 막지만, 순수 2PL 기반에서는 여전히 팬텀 가능” << 재밌는 점은 MVCC 기반 DB에서는 팬텀 리드가 발생하지 않는다고 함.
    - Repeatable Read가 스냅샷 격리(Snapshot Isolation)로 구현된 시스템은 트랜잭션이 시작될 때 읽기용 스냅샷 시점이 고정됨. 이후 어떤 범위 쿼리를 반복 실행해도 새로 커밋된 행은 스냅샷에 포함되지 않으므로 팬텀 행이 보이지 않음
    - MySQL InnoDB는 MVCC 스냅샷에 더해 갭 락(Next-key Lock)을 사용해 INSERT/DELETE로 생길 수 있는 팬텀을 적극 차단함. 결과적으로 MVCC + 갭 락 조합은 read committed보다 느릴 수 있지만 팬텀을 예방
    - 순수 2PL은 기본적으로 “이미 존재하는 키”만 잠그므로, 다른 트랜잭션이 조건에 맞는 새 행을 삽입하면 팬텀 발생. 이를 막으려면 predicate lock 또는 인덱스 범위 락이 필요하지만, 구현·성능·교착상태 관리가 까다로워 락 기반 DB마다 지원 수준이 다름

![image.png](%E1%84%80%E1%85%A9%E1%84%80%E1%85%B3%E1%86%B8%20%E1%84%87%E1%85%A2%E1%86%A8%E1%84%8B%E1%85%A6%E1%86%AB%E1%84%83%E1%85%B3%20%E1%84%89%E1%85%B3%E1%84%90%E1%85%A5%E1%84%83%E1%85%B5%209%E1%84%8C%E1%85%AE%E1%84%8E%E1%85%A1%20229998e1b70980e9bc1dc0a642271e7b/image%201.png)

의존성이 없는 트랜잭션들은 결과가 완전히 독립적이므로 어떤 순서로든 실행될 수 있습니다. 선형화 가능성(Linearizability)을 분산 시스템의 맥락에서 논의하는 것과는 달리, 직렬화 가능성(Serializability)은 임의의 순서로 실행되는 여러 연산의 속성입니다. 이는 실행 중인 트랜잭션에 특정한 순서를 의미하거나 강제하려 하지 않습니다. ACID 관점에서의 고립성(Isolation)은 직렬화 가능성을 뜻합니다 [BAILIS14a]. 불행히도 직렬화 가능성을 구현하려면 조정이 필요합니다. 다시 말해, 동시에 실행되는 트랜잭션들은 불변조건을 유지하고 충돌하는 실행에 직렬 순서를 부여하기 위해 조정해야 합니다 [BAILIS14b].

- “의존성이 없는 트랜잭션들은 결과가 완전히 독립적이므로 어떤 순서로든 실행될 수 있습니다.”
  - 두 트랜잭션이 접근·갱신하는 데이터가 겹치지 않으면 실행 순서가 결과에 영향을 주지 않음
  - 가령 서로 다른 고객 레코드를 갱신하는 주문 트랜잭션라면 어떻게 실행하든 상관 없을 것
- “선형화 가능성(Linearizability)을 분산 시스템의 맥락에서 논의하는 것과는 달리, 직렬화 가능성(Serializability)은 임의의 순서로 실행되는 여러 연산의 속성입니다.”
  - Linearizability: 단일 연산을 실시간 순서를 보존하며 하나의 전역 시점에 배치하는 분산 일관성 개념
    - 흔히 백엔드에서 생각하는 ‘동시성 문제’라고 하면 이걸 말함. [레퍼런스](https://systemdesignschool.io/blog/linearizability-vs-serializability?utm_source=chatgpt.com)
    - “선형성은 연산을 트랜잭션으로 묶지 않기때문에 쓰기 스큐 같은 문제를 막지 못함. 데이터베이스는 직렬성과 선형성을 모두 제공할 수 있으며, 이런 조합은 **엄격한 직렬성(strict serializability)**라고 함”
    - 선형화 가능성에 대하여 쉬운 정의가 있는데… 1) 모든 함수 호출은 함수 시작과 응답 사이의 어느 지점에 선형화 지점을 가진다. 2) 모든 함수 호출은 선형화 지점에서 즉시 효과를 내는걸로 보이며, 이는 순차 정의에 따른 동작을 한다.
    - 이러한 선형화 지점들을 선으로 이으면, 시간 순서에 따라서 하나의 연속된 선들로 나열할 수 있음. 이게 가능한지의 여부로 선형가능성을 정의하면 훨씬 더 간편.
    - 일단 강의 때 더 자세히 설명…
  - Serializability: 트랜잭션 내부의 다수 연산이 어떤 순서로 interleave 되어도 (즉 뒤섞여도) 직렬 실행과 동등하면 OK (앞에서 설명했던 내용)
- “이는 실행 중인 트랜잭션에 특정한 순서를 의미하거나 강제하려 하지 않습니다."
  - 직렬화 가능성은 “결과 동등성” 을 요구할 뿐, 실제 스케줄에서 정해진 선행·후행 순서를 지시하지 않음
  - DBMS는 성능을 위해 자유롭게 스케줄링 가능
- “ACID 관점에서의 고립성(Isolation)은 직렬화 가능성을 뜻합니다 [BAILIS14a]. 불행히도 직렬화 가능성을 구현하려면 조정이 필요합니다. 다시 말해, 동시에 실행되는 트랜잭션들은 불변조건을 유지하고 충돌하는 실행에 직렬 순서를 부여하기 위해 조정해야 합니다 [BAILIS14b].”
  - 동시성 + 직렬 동등성 ⇒ 충돌 탐지·순서화 로직 필수
  - 조정(coordination)이 없으면 충돌 시 위반 발생
  - 구현 기법
    - 2PL: 락을 걸어 직렬 순서 보장
    - OCC: 커밋 단계 검증·중단·재시도
    - Serializable Snapshot Isolation: 버전 + 검증 결합
  - 조정 비용: 추가 대기·교착상태 가능성·재시도 오버헤드

일부 데이터베이스는 스냅샷 격리(snapshot isolation)를 사용합니다. 스냅샷 격리 하에서는, 트랜잭션은 시작 시점까지 커밋된 모든 트랜잭션이 수행한 상태 변화를 관찰할 수 있습니다. 각 트랜잭션은 데이터의 스냅샷을 찍고 그 스냅샷에 대해 쿼리를 실행합니다. 이 스냅샷은 트랜잭션 실행 중에는 변경될 수 없습니다. 트랜잭션이 수정한 값이 실행 중에 변경되지 않은 경우에만 트랜잭션은 커밋합니다. 그렇지 않으면 트랜잭션은 중단되고 롤백됩니다.

- 스냅샷 격리를 사용하는 DB가 있음
  - MVCC 기반 시스템(PostgreSQL, CockroachDB 등)에서 널리 채택
  - 읽기 / 쓰기 충돌을 최소화하면서 높은 동시성 확보하려는 목적
- "스냅샷 격리 하에서는, 트랜잭션은 시작 시점까지 커밋된 모든 트랜잭션이 수행한 상태 변화를 관찰할 수 있습니다."
  - 트랜잭션 시작 순간을 기준으로 고정된 시점의 데이터만 계속해서 보게 됨
  - 이후 커밋된 다른 트랜잭션 결과는 현재 트랜잭션에 보이지 않음
- "각 트랜잭션은 데이터의 스냅샷을 찍고 그 스냅샷에 대해 쿼리를 실행합니다. 이 스냅샷은 트랜잭션 실행 중에는 변경될 수 없습니다."
  - 스냅샷 = 특정 타임스탬프 또는 버전 체계의 읽기 전용 뷰
  - 모든 SELECT가 이 스냅샷을 참조하므로 논리피터블 리드 뿐만 아니라 팬텀 리드 역시 방지함. 당연함. MVCC가 아닌 2PL은 지금 존재하는 키만 락을 걸어놓기 때문임. MVCC는 아예 전체 데이터를 스냅샷을 뜨고 (이 스냅샷은 트랜잭션 도중 변하지 않음) 이걸 참조하기 때문에, 추가 행이 인서트되더라도 상관없음.
- "트랜잭션이 수정한 값이 실행 중에 변경되지 않은 경우에만 트랜잭션은 커밋합니다. 그렇지 않으면 트랜잭션은 중단되고 롤백됩니다."
  - 대신 커밋 단계에서 검증 수행. 다른 트랜잭션이 동일 행을 수정·커밋했다면 충돌로 간주
  - 충돌 감지 시 Abort → Rollback → 재시도 패턴. 쓰기 충돌을 롤백으로 해결하므로 데드락 최소화 장점
  - but 반대로 쓰기 중심 워크로드에서는 충돌·재시도 비용이 증가할 수 있음

만약 두 트랜잭션이 동일한 값을 수정하려고 시도하면, 그중 하나만 커밋이 허용됩니다. 이는 손실된 갱신(Lost Update) 이상을 방지합니다. 예를 들어, 트랜잭션 T1과 T2가 모두 V를 수정하려고 합니다. 이들은 시작 전에 커밋된 모든 트랜잭션의 변경을 포함하는 스냅샷에서 V의 현재 값을 읽습니다. 먼저 커밋을 시도하는 트랜잭션이 커밋되고, 다른 하나는 중단되어야 합니다. 실패한 트랜잭션은 값을 덮어쓰는 대신 재시도합니다.

- 마지막 ‘커밋 단계 검증’과 관련하여 스냅샷 격리가 갱신 분실을 방지하는 원리도 보자.
  - 동일 행을 수정하려는 트랜잭션끼리 경쟁한다면, 검증(validation)에서 첫 승자만 커밋한다 했음
- “이는 손실된 갱신(Lost Update) 이상을 방지합니다.”
  - Lost Update: 마지막으로 커밋된 값이 이전 트랜잭션의 갱신을 덮어쓰는 현상
  - 스냅샷 격리에서는 오류 탐지 후 중단 → 덮어쓰기 자체가 일어나지 않음.
- 예시를 보자. T1, T2 모두 `UPDATE table SET V = …` 를 수행한다. 각 트랜잭션은 자기 스냅샷 기준값을 확보하기에 (트랜잭션이 끝나기 전까지) 후속 커밋은 스냅샷에 \*\*보이지 않는다. 그러면 먼저 커밋한 트랜잭션은 성공, 다른 하나는 abort되어 롤백된다. 그리고 다시 실행되어 새 스냅샷을 잡는다.
- 요약하자면 ‘암시적 덮어쓰기’ 대신 ‘명시적 거부 후 재시도’라고 할 수 있음. 비효율적이지만 갱신 분실을 막을 수 있으니…

스냅샷 격리 하에서는 쓰기 왜곡 이상이 발생할 수 있는데, 이는 두 트랜잭션이 로컬 상태를 읽고 서로 독립적인 레코드를 수정하며 로컬 불변조건을 유지할 경우 둘 다 커밋이 허용되기 때문입니다 [FEKETE04]. 스냅샷 격리에 대해서는 “Distributed Transactions with Percolator”에서 분산 트랜잭션의 맥락으로 더 자세히 논의합니다.

- 스냅샷 격리에서는 트랜잭션마다 고정된 스냅샷을 읽음
  - 각 트랜잭션이 “자신만의 과거 시점”을 참조함
  - 두 트랜잭션이 서로 다른 행을 수정하면 쓰기 충돌이 감지되지 않음
  - 행 단위 충돌 검사만 수행됨
- 각 트랜잭션 내부 검증에서는 불변조건이 만족됨
  - 예: A ≥ 0, B ≥ 0같이 개별 계좌 조건만 확인함
  - 동시에 커밋되면 전역 조건(A + B ≥ 0 등)이 깨질 수 있음
  - 이 현상이 쓰기 왜곡(write skew)
  - Lost update는 막지만 전역 불변조건 위반은 막지 못함
