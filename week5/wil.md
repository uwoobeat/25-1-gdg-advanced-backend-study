# 고급 백엔드 스터디 5주차

## General Principles

### General Principles (1)

대개 파일 포맷 설계는 주소 지정 방식을 결정하는 것에서 시작합니다. 즉, 파일을 동일한 크기의 페이지로 나눌지, 그리고 그 페이지를 하나의 블록으로 표현할지 아니면 여러 개의 연속된 블록으로 표현할지를 정합니다. 인-플레이스(in-place) 갱신을 지원하는 저장 구조는 페이지 크기를 동일하게 맞추는 경우가 많으며, 이는 읽기·쓰기 접근을 크게 단순화해 줍니다. 추가-전용(append-only) 구조 역시 페이지 단위로 데이터를 기록하는 경우가 일반적입니다. 레코드들은 차례로 메모리에 쌓이다가 페이지가 가득 차면 곧바로 디스크에 플러시됩니다.

- 파일 포맷 설계의 첫 걸음은 ‘주소 지정(addressing) 방식’ 결정
  - 페이지 단위로 고정 크기를 사용할지 여부가 관건
- “파일을 동일한 크기의 페이지로 나눌지, 그리고 그 페이지를 하나의 블록으로 표현할지 아니면 여러 개의 연속된 블록으로 표현할지를 정합니다.” → 무슨 말인가?
  - 일단 블록 vs 페이지 리마인드부터 하고 가자.

### (번외) 블록 vs 페이지

[https://www.geeksforgeeks.org/difference-between-page-and-block-in-operating-system/](https://www.geeksforgeeks.org/difference-between-page-and-block-in-operating-system/)

- 블록 (block)
  - 정의: 파일을 읽거나 데이터를 파일에 쓸 수 있는 가변 크기의 저장 단위
  - 구성: 섹터(sectors)로 구성되며, 하나 또는 여러 개의 섹터(2, 4, 6개 등)로 이루어짐
  - 특징:
    - 데이터 저장의 최소 단위
    - 물리적 레코드라고도 불림
    - 대부분의 OS에서 데이터 저장에 사용
    - 0바이트 파일도 최소 하나의 블록을 차지
    - 예시: NTFS의 기본 블록 크기는 4096바이트
  - 장점
    - 효율적인 저장 공간 사용
    - 여러 블록을 한 번에 읽어 성능 향상
  - 단점
    - 고정 블록 크기로 인한 저장 공간 낭비 가능
    - 가변 블록 크기 사용 시 추가 오버헤드 발생
- 페이지 (page)
  - 정의: 주 메모리에서 프로세서로 로드되는 고정 크기의 메모리 단위
  - 구성: 블록의 단위 또는 블록 그룹으로 구성
  - 특징:
    - 가상 페이지 또는 메모리 페이지라고도 불림
    - 일반적으로 2KB 또는 4KB의 고정 크기
    - RAM과 동등한 인메모리 저장의 최소 단위
    - 프로세서 아키텍처에 의해 크기가 결정됨
  - 장점
    - 요구에 따른 효율적 메모리 관리
    - 가상 메모리 사용 가능
    - 유연한 메모리 할당
  - 단점
    - 가상-물리 메모리 매핑 관리로 인한 오버헤드
    - 쓰래싱 발생 시 성능 저하

| **블록(Block)**                  | **페이지(Page)**                     |
| -------------------------------- | ------------------------------------ |
| 가변 크기 저장 단위              | 고정 크기 메모리 단위                |
| 파일 시스템에서 관리             | 운영체제의 메모리 관리 단위에서 관리 |
| 물리적 레코드                    | 가상 페이지/메모리 페이지            |
| 파일 읽기/쓰기용                 | 주 메모리-보조 메모리 간 전송용      |
| 다양한 저장 장치에서 처리가 복잡 | 고정 크기로 인해 처리가 간단         |

페이지와 블록은 모두 주 메모리와 보조 저장 장치 간의 데이터 전송 단위로 작동합니다. 운영체제는 일반적으로 정보 전송 목적으로 블록보다 페이지를 선호하는데, 이는 여러 저장 장치가 있을 때 페이지로 처리하는 것이 더 쉽고, 페이지 크기가 고정되어 있어 관리가 용이하기 때문입니다.

### General Principles (2)

- “파일을 동일한 크기의 페이지로 나눌지,
  그리고 그 페이지를 하나의 블록으로 표현할지
  아니면 여러 개의 연속된 블록으로 표현할지를 정합니다.” 의미 파악 1. “페이지 크기를 고정할 것인가?” - 고정 크기 - 페이지 ID → 파일 오프셋 계산이 offset = page_id \* page_size 로 단순화 - 페이징 캐시·버퍼 풀에서 메모리 관리가 편리 - 단점: 내부 파편화(internal fragmentation) 가능 - 가변 크기 - 큰 레코드를 붙여 쓰는 로그 구조 ColDB 등에서 채택 - 단점: 주소 계산 복잡, 페이지 헤더가 커짐 2. “한 페이지가 디스크 블록 몇 개를 차지할 것인가?” - 1 페이지 = 1 블록 - 페이지 크기를 4 KiB(블록 크기)로 맞추면 단일 I/O 요청으로 완전한 페이지를 읽고 쓸 수 있음 → 랜덤 I/O 효율 - 장애 복구(WAL) · 플러시 시 원자적(atomic) 쓰기 보장에 유리: 블록 하나만 손상돼도 CRC로 감지 가능 - 단점: 레코드가 크면 한 페이지에 못 들어가 추가 관리 필요(overflow page 등) - 1 페이지 = n 블록(연속) - 예: 8 KiB / 16 KiB 페이지. 내부적으로는 4KiB 블록 2개 / 4개를 연달아 배치 - 장점 - 동일 페이지 안에 더 많은 레코드 수용 ⇒ 검색(스캔) 시 히트율↑, 트리 높이↓ - 큰 레코드도 별도 오버플로 없이 저장 가능 - 고려 사항 - 연속 블록 할당이 파일시스템에서 항상 보장되지 않음 → extent allocator 활용, 프래그먼트 시 I/O 분산 - 복구·체크섬 범위 확대 ⇒ 손상 시 더 많은 데이터 영향 - SSD는 내부적으로 이미 16–32 KiB erase page 사용 → 물리 page size 고려해 정렬(alignment) 필요
- 저장 구조별 페이지 전략
  1. in-place update 저장 구조
     - 레코드를 기존 위치에서 덮어쓰는 방식
     - 페이지 크기를 통일해 두면
       - 오프셋 계산이 단순
       - 디스크 I/O가 예측 가능 (배수로 접근 가능하니)
  2. append-only 저장 구조
     - 새 데이터를 항상 파일 끝에 추가
     - 메모리 버퍼에 페이지 단위로 쌓다가 가득 차면 디스크로 플러시
       - 저저번주 배웠던 버퍼링 → 이거는 IO 횟수 줄어드니까 왜 하는지 이해되긴 함
       - 그런데 왜 하필 페이지 단위로? → 마찬가지로 3주차 때 배웠었다. 그래도 설명 안한 부분 있으니 추가로 알아보자
         - HDD
           - 순차 쓰기하면 빠른 것까진 알겠는데, 블럭 단위로도 쓸 수 있지 않나? 왜 하필 페이지 단위? 라는 생각이 들 수도 있음.
           - DBMS는 페이지마다 헤더를 둬서 LSN(last sequence number, 즉 마지막 로그 레코드 번호) 및 체크섬 값을 저장함. 그리고 페이지 엑세스 시 체크섬을 검증하기도 함.
           - 그래서 페이지 단위로 쓰는 게 좋은 것
         - SSD
           - 이건 쉽다. 3주차 때 언급한 쓰기 증폭 때문. SSD는 덮어쓰기가 안되므로 (플래시 메모리의) 페이지를 다시 쓰려면 (플래시 메모리의) 블록 (≠ OS의 블록) 전체를 지워야 한다고 했었다. 따라서 (OS의) 페이지 단위로 써야 한다는 것은 자명함

파일은 대개 고정 크기의 헤더로 시작하며 고정 크기의 트레일러로 끝날 수 있는데, 이들은 빠르게 접근해야 하거나 나머지 파일을 해독하는 데 필요한 부가 정보를 담습니다. 파일의 나머지 부분은 페이지로 분할됩니다. 그림 3-3은 이러한 파일 구성을 도식적으로 보여 줍니다.

![image.png](%E1%84%80%E1%85%A9%E1%84%80%E1%85%B3%E1%86%B8%20%E1%84%87%E1%85%A2%E1%86%A8%E1%84%8B%E1%85%A6%E1%86%AB%E1%84%83%E1%85%B3%20%E1%84%89%E1%85%B3%E1%84%90%E1%85%A5%E1%84%83%E1%85%B5%205%E1%84%8C%E1%85%AE%E1%84%8E%E1%85%A1%201fc998e1b7098050888adc497c384e14/image.png)

- 파일 구조
  - 헤더와 트레일러는 고정 크기로 배치되어 위치 계산이 단순함
    - 헤더: 버전, 매직 넘버, 체크섬 오프셋 등 빠른 판별용 정보 포함
    - 트레일러: 색인 테이블, 전체 체크섬 등 파일 끝에 두어 쓰기 완료 후 갱신하기 용이함
- 본문 페이지 분할
  - 균일한 페이지 크기 채택 → 디스크 블록과 정렬되어 I/O 효율 증가
  - 논리적 레코드 위치를 ‘페이지 번호 + 오프셋’으로 표현 가능하여 탐색‧버퍼 관리 단순화
- 장점
  - 헤더, 트레일러 덕분에 데이터 영역을 해석하기 전 필요한 메타정보를 O(1)로 확보함
  - 페이지 단위 접근은 캐시·버퍼 관리 정책(예: LRU)과 호환성이 좋고, 부분 손상 시 페이지 단위 복구가 가능함

대부분의 데이터 저장소는 테이블이 담을 수 있는 필드의 개수, 순서, 타입을 명시하는 고정 스키마를 갖습니다. 고정 스키마를 사용하면 디스크에 저장되는 데이터 양을 줄일 수 있습니다. 필드 이름을 반복해서 기록하는 대신 위치 기반 식별자를 사용할 수 있기 때문입니다.

회사 직원 디렉터리 형식을 설계해 이름, 생년월일, 세금 식별번호, 성별을 저장하려 한다면 여러 가지 방법을 취할 수 있습니다. 예를 들어 고정 크기 필드(생년월일, 세금 번호 등)를 구조체의 앞부분에 두고 그 뒤에 가변 크기 필드를 두는 방식이 있습니다: 고정 크기 필드: | (4 bytes) employee_id | | (4 bytes) tax_number | | (3 bytes) date | | (1 byte) gender | | (2 bytes) first_name_length | | (2 bytes) last_name_length | 가변 크기 필드: | (first_name_length bytes) first_name | | (last_name_length bytes) last_name | first_name에 접근하려면 고정 영역 뒤에서 first_name_length 바이트를 잘라내면 됩니다. last_name에 접근하려면 그 앞에 놓인 가변 필드들의 길이를 확인해 시작 위치를 찾을 수 있습니다. 여러 필드를 두 번 계산하지 않으려면 고정 영역에 각 가변 필드의 오프셋과 길이를 함께 기록할 수도 있습니다. 이렇게 하면 어느 가변 필드든 독립적으로 바로 찾아낼 수 있습니다.

- 고정 스키마 → RDBMS 테이블 생각하면 됨
  - 테이블 정의가 미리 고정되어 필드(컬럼)의 개수, 순서, 데이터 타입이 변하지 않음
  - 장점
    - 위치 기반 식별자
    - 저장 공간 아낄 수 있음 → 예전에 1장에서 암시적 식별자 생각나는지? 만약 스키마에 2자리 ID, 8자리 생년월일, 학번 순으로 나온다는 게 정의되어 있으면, 각 레코드를 해석할 때 9920001010C123456 → 99번 ID의 2000년 10월 10일 생일의 C123456 학번이라는 걸 알 수 있음. 해당 레코드에서 필드 이름을 안 주더라도…!
    - 이건 근데 가변 길이 데이터는 고려 안한 거잖아요 → 뒤에서 설명함…
- 만약 이름, 성, 생년월일, 세금번호, 성별 저장한다면
  - 고정 길이 필드 영역
    - 고정 길이 값(날짜, 번호 등)을 선두에 일렬 배치
    - 그리고 가변 길이의 필드의 길이 값(이름, 성)을 그 다음으로 배치
  - 가변 길이 필드 영역
    - 그 다음에 실제 가변 길이 문자열들을(이름, 성) 배치
  - 접근 방식
    - 이름 → 가변 길이 필드 영역 시작부부터 이름 필드 길이값만큼 잘라서 쓰면 됨
    - 성 → 가변 길이 필드 영역 시작부 + 이름 길이 값부터 성 길이 값만큼 잘라서 쓰면 됨
- 근데 가변 필드가 많아지면? 시작부 + 앞에 있는 가변 필드들 길이 다 더해야 하는 단점
  - 고정 길이 필드 영역에 ‘길이’만 저장하지 않고, (오프셋, 길이) 쌍으로 저장
  - 그러면 바로 오프셋 ~ 오프셋 + 길이만큼만 잘라서 쓰면 되므로 연속 계산 필요 X
- 하지만 역시 이 방식에도 단점 있음
  - 필드 추가/삭제되면 영향받는 오프셋 다시 계산해야함
  - 초기 시작 위치 + 길이 합만으로도 구할 수 있는 오프셋을 중복해서 저장하므로 고정 영역 커짐
- 이러한 trade-off 관계에서 둘 중 어떤 방식을 선택할까?
  - 오프셋을 미리 계산하는 방식 → 여러 컬럼이 필요한 경우에 유리
  - 따라서 (OLAP 방식의) 열 기반 DBMS는 일부 컬럼만 선택해서 조회하므로 길이 누적 스캔을 쓰더라도 괜찮음. 계산하는 오버헤드가 적으므로…
  - 반면 행 기반 DBMS는 오프셋을 미리 계산하는 오프셋 테이블 방식을 선택할 것 (아마도?) → 근데 OLTP도 항상 모두 조회한다는 보장은 없지 않나?
  - 실제로는?
    - [PostgreSQL](https://www.postgresql.org/docs/current/storage-page-layout.html)
      - “`ItemIdData`: 실제 아이템을 가리키는 아이템 식별자 배열입니다. 각 항목은 (오프셋, 길이) 쌍입니다. 항목당 4바이트입니다.”
    - [MySQL InnoDB](https://dev.mysql.com/doc/refman/8.4/en/innodb-row-format.html)
      - 두 가지 타입이 있음: REDUNDANT, COMPACT/DYNAMIC (둘을 묶었음)
      - REDUNDANT
        - “레코드는 각 필드에 대한 포인터를 포함합니다. 레코드 내 필드의 총 길이가 128바이트 미만이면 포인터는 1바이트이고, 그렇지 않으면 2바이트입니다. 포인터 배열을 레코드 디렉터리라고 합니다. 포인터가 가리키는 영역이 레코드의 데이터 부분입니다.”
        - 레코드 디렉터리라는 이름으로 포인터 배열을 쓴다. 즉 오프셋 테이블 방식이다
      - COMPACT/DYNAMIC
        - COMPACT 행 포맷은 REDUNDANT 행 형식에 비해 행 저장 공간을 약 20% 줄이지만, 일부 작업에서 CPU 사용량이 증가하는 대가를 치릅니다. 워크로드가 캐시 적중률과 디스크 속도에 의해 제한되는 일반적인 워크로드라면 COMPACT 포맷이 더 빠를 가능성이 높습니다. 워크로드가 CPU 속도에 의해 제한되는 경우 COMPACT 포맷이 더 느릴 수 있습니다.
          - 왜 저장 공간이 줄어들까? → 아래서 설명
      - 레코드 헤더의 가변 길이 부분은 NULL 컬럼을 나타내는 비트 벡터를 포함합니다. 인덱스에서 NULL이 될 수 있는 컬럼의 수가 N개라면, 비트 벡터는 CEILING(N/8) 바이트를 차지합니다. (예를 들어, NULL이 될 수 있는 컬럼이 9개에서 16개 사이라면, 비트 벡터는 2바이트를 사용합니다.)
        - nullable 컬럼이 1~8개면 1바이트, 9~16개면 2바이트, …
      - NULL인 컬럼들은 이 벡터의 비트를 제외하고는 별도의 공간을 차지하지 않습니다.
        - nullable 컬럼에 대하여 해당 레코드의 값이 null인 경우, 별도로 공간을 안먹고 null 벡터에서 딱 1비트만 차지함.
      - 헤더의 가변 길이 파트는 또한 가변 길이 컬럼들의 길이도 포함합니다. 각 길이는 컬럼의 최대 길이에 따라 1바이트 또는 2바이트를 차지합니다. 인덱스의 모든 컬럼이 NOT NULL이고 고정 길이를 가진다면, 레코드 헤더는 가변 길이 부분을 갖지 않습니다.”
        - 길이는 1바이트 아니면 2바이트 → 0 ~ 2^8-1, 2^8 ~ 2^16 - 1을 나타낼 수 있다. 즉 0 ~ 255, 256 이상으로 나뉨
        - 아니 2^16 - 1 = 65535인데, 그보다 긴 값은 어떻게?
        - 768바이트까지는 레코드 내부에 저장, 나머지는 별도의 오버플로 페이지에 저장 + 포인트로 외부 데이터 참조
          - 왜? → 이거까지 쓰기엔 귀찮다… [https://dev.mysql.com/blog-archive/externally-stored-fields-in-innodb/](https://dev.mysql.com/blog-archive/externally-stored-fields-in-innodb/)
          - InnoDB는 16KB의 페이지 크기를 가짐. 여기서 페이지 헤더 / 트레일러, 디렉토리 제외하면 실제 인덱스 레코드 공간은 ~158000
      - “각각의 non-NULL 가변 길이 필드에 대해, 레코드 헤더는 해당 컬럼의 길이를 1바이트 또는 2바이트로 포함합니다. 2바이트가 필요한 경우는 컬럼의 일부가 오버플로 페이지에 외부적으로 저장되거나, 최대 길이가 255바이트를 초과하면서 실제 길이가 127바이트를 초과하는 경우입니다. 외부적으로 저장된 컬럼의 경우, 2바이트 길이는 내부적으로 저장된 부분의 길이와 외부적으로 저장된 부분을 가리키는 20바이트 포인터의 길이를 합친 값을 나타냅니다. 내부 부분은 768바이트이므로, 길이는 768+20이 됩니다. 20바이트 포인터는 컬럼의 실제 길이를 저장합니다.”

더 복잡한 구조를 만들기 위해서는 일반적으로 계층 구조를 구성하게 됩니다. 즉, 필드는 원시 데이터로 구성되고, 셀은 필드로 구성되며, 페이지는 셀로, 섹션은 페이지로, 영역은 섹션으로 구성되는 식입니다. 이러한 구성 방식에는 반드시 따라야 할 엄격한 규칙이 있는 것은 아니며, 어떤 종류의 데이터를 위한 포맷을 만들고자 하는지에 따라 달라집니다.

계층 구조

- 가변 길이 데이터 타입에 대한 고려 → 길이 배열 or (오프셋, 길이) 배열 등장
- 실제로는 더 복잡 → ‘계층 구조' 의 필요성!
- 원시값 → 필드 → 셀 → 페이지 → 섹션 → 리전

데이터베이스 파일은 종종 여러 부분으로 구성되며, 탐색을 돕는 조회 테이블이 함께 사용됩니다. 이 테이블은 이러한 부분들의 시작 오프셋을 가리키며, 파일의 헤더나 트레일러, 혹은 별도의 파일에 기록될 수 있습니다.

Lookup Table

- 필요성
  - 복잡한 구조에서 빠르게 탐색하기 위해 시작 지점 알려줌
- 위치
  - 페이지 헤더 / 트레일러, 별도 파일 등 다양

데이터베이스 시스템은 데이터 레코드를 데이터 파일 및 인덱스 파일에 저장합니다. 이 파일들은 고정 크기의 단위인 페이지로 나뉘며, 이 페이지는 종종 여러 파일 시스템 블록 크기를 가집니다. 페이지 크기는 일반적으로 4KB에서 16KB 사이입니다.

온디스크 B-트리 노드의 예를 살펴보겠습니다. 구조적인 관점에서 B-트리는 키와 데이터 레코드 쌍을 저장하는 리프 노드와, 키와 다른 노드로 가는 포인터를 저장하는 비리프 노드를 구분합니다. 각 B-트리 노드는 하나의 페이지 또는 여러 개의 연결된 페이지를 차지하며, 이러한 맥락에서 B-트리에서는 노드, 페이지(심지어 블록)라는 용어들이 자주 혼용됩니다.

온디스크 B-Tree 구조

- 구분
  - 리프 노드 → 실제 데이터 (key, val) 저장
  - 비리프 노드 → 키, 다른 노드로의 포인터 저장
- 문제
  - 노드 / 페이지 / 블록 용어들이 혼용됨

원래의 B-트리 논문 [BAYER72]에서는 고정 크기 데이터 레코드에 대해 단순한 페이지 구성을 설명합니다. 각 페이지는 키(k), 관련 값(v), 자식 페이지로의 포인터(p)의 3항 조합(triplet)으로 단순히 이어 붙인(concatenation) 구조입니다(도표 3-4 참조).

이 방식은 구현이 쉽다는 장점이 있지만 다음과 같은 단점이 있습니다:

- 오른쪽 끝이 아닌 위치에 키를 추가하려면 기존 요소들을 재배치해야 함
- 가변 크기 레코드를 효율적으로 관리하거나 접근할 수 없음
- 고정 크기 데이터에만 적합한 구조임

온디스크 B-Tree 구조

- 일단 단순한 구현을 보자 (BAYER72)
  - 구성 요소 → (k, v, p) 배열
- 단점
  - 중간 삽입 시 모든 요소 재배치
  - 가변 크기 레코드에 대한 고려 X

가변 크기의 레코드를 저장할 때 가장 큰 문제는 제거된 레코드가 차지했던 공간을 어떻게 회수할 것인가 하는 **공간 관리** 문제입니다. 크기 n의 레코드를 크기 m의 레코드가 있었던 자리에 넣으려 할 경우, m == n이 아니고 m - n에 정확히 맞는 다른 레코드를 찾지 못한다면 그 공간은 사용되지 않은 채로 남게 됩니다. 마찬가지로, 크기 m인 구간은 k > m인 레코드를 저장할 수 없으므로 결국 해당 공간은 회수되지 않은 채 새로운 레코드가 다른 위치에 삽입됩니다.

이 문제를 단순화하기 위해, 페이지를 고정 크기 세그먼트로 나누는 방법도 있습니다. 그러나 이 방법 역시 공간 낭비를 초래합니다. 예를 들어, 세그먼트 크기를 64바이트로 정했을 때 삽입하는 레코드 크기가 64의 배수가 아니라면, 삽입 시 64 - (n mod 64) 바이트만큼 낭비가 발생합니다. 즉, 레코드 크기가 64의 배수가 아니라면 한 블록은 부분적으로만 채워지게 됩니다.

가변 크기 레코드 문제점 1: 파편화 (fragmentation)

- 삭제된 레코드의 공간 재사용이 어려움
- 왜? 정확하게 딱 맞는 레코드가 들어온다는 보장 없기 때문
- 묘수) 더 잘게 쪼갠다면?
  - 그래도 똑같음. 그보다 더 살짝 모자른 레코드가 들어온다면?
  - → 결국 ‘가변 크기’라는 본질적 한계 존재

공간 회수는 페이지를 다시 쓰고 레코드들을 재배치함으로써 수행할 수 있지만, 이 경우 페이지 외부에서 해당 레코드에 접근하는 포인터가 여전히 이전 오프셋을 사용할 수 있으므로 오프셋을 유지해야 합니다. 따라서 낭비 공간을 최소화하면서 이러한 재배치가 이루어지는 것이 바람직합니다.

가변 크기 레코드 문제점 2: 컴팩션 그리고 포인터

- 문제점 1은 해결할 방법이 있음 → 메모리 압축 (Compaction)
- 삭제된 빈 공간 없애기 위해 나머지 레코드를 앞으로 끌고오기
  - ex: [A][ ][C][D] → [A][C][D]
- 하지만 이 역시 문제점 있음
  - 위치가 변경된 레코드를 가리키는 포인터가 invalid 하게 됨

정리하자면, 우리가 필요한 페이지 포맷은 다음의 요건을 만족해야 합니다.

- 가변 크기 레코드를 최소한의 오버헤드로 저장할 수 있어야 함
- 제거된 레코드가 차지했던 공간을 회수할 수 있어야 함
- 레코드의 정확한 위치에 관계없이 참조가 가능해야 함

문자열, 바이너리 대용량 객체(BLOBs) 등의 가변 크기 레코드를 효율적으로 저장하기 위해, **슬롯 페이지(sotted page)** 또는 **슬롯 디렉토리(slot directory)** 라는 조직 기법을 사용할 수 있습니다. PostgreSQL을 포함한 많은 데이터베이스 시스템이 이 방식을 사용합니다.

페이지 포맷 요구사항 정리

- 가변 크기 레코드를 최소한의 (공간) 오버헤드로 저장할 수 있어야 함
- 제거된 레코드가 차지한 공간을 회수할 수 있어야 함 (컴팩션)
- 그러면서도 레코드의 위치를 정확하게 참조할 수 있어야 함 (포인터)
- → 해결책: 슬롯 페이지(slotted page) 혹은 슬롯 디렉토리(slot directory)

이 방식에서는 페이지를 여러 개의 **슬롯(또는 셀)** 로 구성하고, 이들을 가리키는 포인터들과 셀 자체를 페이지 양쪽 끝에서 독립적으로 관리합니다. 따라서 셀의 순서를 유지하려면 포인터 배열만 재조정하면 되고, 레코드를 삭제할 때는 해당 포인터를 무효화하거나 제거하면 됩니다.

슬롯 페이지는 고정 크기 헤더를 가지며, 이 헤더는 페이지와 셀들에 대한 중요한 정보를 담고 있습니다. 셀들은 크기가 다를 수 있으며, 키, 포인터, 데이터 레코드 등 다양한 데이터를 저장할 수 있습니다.

슬롯 페이지(slotted page)는 고정 크기의 헤더를 가지며, 이 헤더는 해당 페이지와 그 안의 셀들에 대한 중요한 정보를 포함합니다(자세한 내용은 “페이지 헤더” 참조). 셀(cell)은 크기가 서로 다를 수 있으며, 키(key), 포인터(pointer), 데이터 레코드 등 다양한 임의의 데이터를 담을 수 있습니다. 그림 3-5는 슬롯 페이지의 구성 예시를 보여주며, 각 페이지는 **유지 영역(헤더)**, **셀들**, 그리고 **셀들을 가리키는 포인터 배열**로 구성됩니다.

슬롯 페이지

- 페이지를 여러 개의 슬롯(혹은 셀)로 나눈다
  - 크기 자유 + 키 / 포인터 / 데이터 레코드 등 다양한 값 가능
- 구조
  - 헤더
  - 포인터 배열
    - 고정 크기 배열
    - 역순으로 채워짐
  - 데이터 레코드 배열 (실 데이터)

왜 슬롯 페이지가 문제를 해결하는가?

- 최소한의 오버헤드
  - 레코드 자체를 이동시키지 않기에 시간 오버헤드 낮음
  - (2~4바이트) 포인터 배열만 두기 때문에 공간 오버헤드 낮음
- 공간 회수
  - 레코드를 삭제하려면 포인터만 무효화하면 됨
  - 컴팩션 작업할 때도 살아있는 것들만 복사해주고 포인터 갱신
- 동적 레이아웃
  - 컴팩션 통해 물리적 위치 바뀌더라도 (심지어 슬롯 바깥으로 나가더라도)
  - 포인터는 유효한 상태이므로 정확하게 접근 가능

## Cell Layout

플래그, 열거형, 원시 값을 사용하여 셀 레이아웃을 설계할 수 있으며, 이후 셀을 페이지로 결합하고 이 페이지들로 트리를 구성할 수 있습니다. 셀 수준에서는 key 셀과 key-value 셀을 구분합니다. key 셀은 구분자 키와 두 인접한 포인터 사이의 페이지를 가리키는 포인터를 보유하고, key-value 셀은 키와 이에 연관된 데이터 레코드를 보유합니다.

- 앞서서 우리는 플래그 / 열거형 / 원시 값들에 대해 배웠었음 (4주차에서)
  - 고정 크기 원시 타입, 가변 크기 타입, 플래그 → 여러 개의 불리언 값을 하나의 정수로 표현
  - 이를 사용하여 셀 레이아웃을 설계할 수 있다고 함. 무엇을 어떻게?
- 어떻게? → 셀을 페이지로 결합하고, 페이지로 트리를 구성하는 방식
  - 페이지가 여러 개의 셀로 구성 → 이건 앞에서 이야기함
  - 페이지로 트리 구성 → 이것도 앞에서 이야기. 하나의 페이지는 B-Tree 상에서 하나의 노드에 대응됨 (”B-트리에서는 노드, 페이지(심지어 블록)라는 용어들이 자주 혼용됩니다.”)
- 셀의 종류 → 키 셀 / 키-값 셀
  - 키 셀 → 구분 키와 포인터
    - 구분 키 → 트리 탐색 시 비교를 위한 기준
    - 포인터 → ‘두 인접한 포인터 사이의 페이지를 가리키는’ 이라는 표현 나옴. 이해가 어려운데
      - p0 k1 p1 k2 p2 … kn pn 순서로 구성되어 있다고 하자.
      - 그러면 k는 구분 기준이 되며 / 포인터는 다음 페이지를 지시하고 있음
      - (-inf, k1) 인 값은? → p0이 가리키는 곳으로 이동
      - [k1, k2)인 값은? → p1가 가리키는 곳으로 가야 함
      - [k2, k3)인 값은? → p2가 가리키는 곳
      - p0이 가리키는 페이지는 (-inf, k1)이고 p2가 가리키는 페이지는 [k2, k3)이므로…
      - p0과 p2에 인접한 포인터 p1이 가리키는 페이지는 [k1, k2)인 것
  - 키-값 셀 → 실 데이터를 저장하는 키-값 쌍

하나의 페이지 안에 있는 모든 셀이 동일한 형식이라고 가정합니다 (예: 모든 셀이 키만 갖거나 키와 값을 모두 가짐, 또는 모든 셀이 고정 길이 데이터를 갖거나 가변 길이 데이터를 갖되 둘을 혼합하지 않음). 이렇게 하면, 셀마다 메타데이터를 중복 저장하지 않고 페이지 수준에서 한 번만 저장하면 됩니다.

- 페이지 안의 모든 셀이 동일한 포맷을 가정하는 이유 → “셀마다 메타데이터 중복 저장 X, 페이지 레벨에서 한 번만 저장”
  - 하나의 페이지에 대해서 키 셀만 존재 혹은 키-값 셀만 존재, 그리고 고정 길이 데이터만 가지거나 가변 길이 데이터만 가지는 식
  - 가령 (키-값, 가변 길이) 셀로만 구성하거나 / (키, 고정 길이) 셀로만 구성하는 식
  - 페이지 안의 각 셀이 다른 포맷이라면 → 각 셀에 대하여 메타데이터가 필요할 것. 공간 낭비
  - 같은 포맷이면 셀 레벨이 아니라 페이지 레벨에서 저장 가능
  - json와 rdb 테이블의 차이 생각하면 좋을 듯

key 셀을 구성하려면 다음 정보가 필요합니다:

- 셀 타입 (페이지 메타데이터에서 유추 가능)
- 키의 크기
- 이 셀이 가리키는 자식 페이지의 ID
- 키의 바이트 값

가변 크기 key 셀 레이아웃은 다음과 같을 수 있습니다 (고정 크기 셀은 셀 수준에 크기 지정자가 없음):

```markdown
0 4 8
+----------------+---------------+-------------+
| [int] key_size | [int] page_id | [bytes] key |
+----------------+---------------+-------------+
```

- 키 셀의 포맷
  - 셀 타입 → 페이지 메타데이터에서 알 수 있음
  - 키 크기
  - 셀이 가리키는 자식 페이지 ID
  - 키의 바이트 값
- (키, 가변 크기) 셀의 경우 아래와 같음
  ```markdown
  0 4 8
  +----------------+---------------+-------------+
  | [int] key_size | [int] page_id | [bytes] key |
  +----------------+---------------+-------------+
  ```
  - 고정 크기인 경우 키의 크기는 없어도 됨. 즉 [page_id][key] 구조
- 고정 크기 데이터 필드를 앞에다 묶고, key_size 바이트만큼의 데이터를 그 뒤에 배치함
  - 앞 주차에서 고정 필드 → 가변 필드 길이 → 가변 필드 데이터 순으로 배치한다고 했던 바 있음
  - 여기서도 이와 비슷하게 고정 길이인 키 크기, 페이지 ID를 먼저 두고 → 가변 길이인 키 데이터를 그 뒤에 배치함
  - 필수는 아니지만, 고정 크기 필드는 사전에 계산된 오프셋으로 접근 가능하므로 오프셋 계산이 간단함.
  - 그리고 가변 크기 데이터에 대해서만 오프셋 계산하면 됨

고정 크기 필드를 함께 묶고, 그 뒤에 key_size만큼의 바이트를 배치합니다. 이는 필수는 아니지만, 고정 크기 필드는 사전에 계산된 오프셋을 사용하여 접근할 수 있으므로 오프셋 계산을 단순화할 수 있습니다. 변수 크기 데이터에 대해서만 오프셋 계산이 필요합니다.

key-value 셀은 자식 페이지 ID 대신 데이터 레코드를 보유합니다. 그 외 구조는 유사합니다:

- 셀 타입 (페이지 메타데이터에서 유추 가능)
- 키의 크기
- 값의 크기
- 키의 바이트 값
- 데이터 레코드 바이트 값

```markdown
0 1 5 ...
+--------------+----------------+
| [byte] flags | [int] key_size |
+--------------+----------------+

5 9 .. + key_size
+------------------+--------------------+----------------------+
| [int] value_size | [bytes] key | [bytes] data_record |
+------------------+--------------------+----------------------+
```

여기서 offset과 page ID의 차이를 주목할 수 있습니다. 페이지는 고정 크기이며 페이지 캐시에 의해 관리되므로, page ID만 저장하면 됩니다. 이 값은 이후 조회 테이블을 통해 실제 파일 오프셋으로 변환됩니다. 셀 오프셋은 페이지 내에서만 유효한 값이며, 페이지 시작점으로부터의 상대 위치이므로 더 작은 크기의 정수로 표현할 수 있습니다.

- 키-값 셀 포맷
  - 셀 타입 (페이지 메타데이터에서 유추 가능)
  - 키의 크기
  - 값의 크기
  - 키의 바이트 값
  - 데이터 레코드 바이트 값
  ```markdown
  0 1 5 ...
  +--------------+----------------+
  | [byte] flags | [int] key_size |
  +--------------+----------------+

  5 9 .. + key_size
  +------------------+--------------------+----------------------+
  | [int] value_size | [bytes] key | [bytes] data_record |
  +------------------+--------------------+----------------------+
  ```
- 실제 예시 구조를 보면 플래그가 있음. 근데 왜 포맷 섹션에서는 소개를 안했을까.. 아무튼 이런 정보들이 들어감
  - 리프 노드 여부, 고정 크기 값 여부, 오버플로우 페이지 존재 여부, ..
- 키-값 셀의 경우 단말 노드이므로 자식 페이지로의 포인터를 가질 필요 없음. 대신 데이터 레코드를 가짐
- 한편 페이지 ID, 셀 오프셋 구분 중요
  - 페이지는 고정 크기(4KB)로 분할되어 있음. 오프셋은 페이지 ID \* 페이지 크기로 구할 수 있다 했었음
  - 따라서 페이지 ID만 저장하면 됨
  - 페이지 ID는 lookup table을 통해 실제 파일 오프셋으로 변환됨
  - ‘셀 오프셋’은 페이지 내부에서 셀이 어디에 저장되어 있는지 알기 위한 상대적 위치
  - ‘오프셋’과 다르게 ‘셀 오프셋’은 페이지 내부에서만 유효하므로 낮은 카디널리티 (작은 크기) 의 정수로 나타낼 수 있음 → 2바이트 정도만 충분
- 가변 크기 데이터
  - 키와 값 모두 가변 크기일 수 있음 (키가 가변 크기일 수 있다는 점은 좀 놀라울지도)
  - 가령 플래그 / 키 크기 / 값 크기 / 키 데이터 / 값 데이터 구조라면
  - 키를 읽으려면 → 헤더 (고정 길이 필드: 플래그, 키 크기, 값 크기) 부터 (헤더 + 키 크기)까지
  - 값을 읽으려면 → 헤더에서 키의 길이만큼 더 가야 시작, 여기서 값 크기 길이만큼 더 읽으면 됨
  - 초반부에 설명했으니 스킵
- 가변 크기 데이터를 읽는 다른 방법
  - 전체 크기를 저장하고 → 전체 크기 - 키 크기 = 값 크기로 역산해서 값 크기 구할 수 있음
  - 이러면 값 크기를 저장하지 않아도 되는 대신 빼기 연산 필요

## Combining Cells into Slotted Pages

셀들을 페이지에 구성하기 위해 앞서 “페이지 구조”에서 설명한 슬롯 페이지(slotted page) 기법을 사용할 수 있습니다. 셀은 페이지의 오른쪽 끝(끝부분)을 향해 추가되며, 셀의 오프셋/포인터는 페이지의 왼쪽 부분에 저장됩니다. 이는 그림 3-6에서 볼 수 있습니다.

키는 삽입 순서와 상관없이 추가될 수 있으며, 셀 오프셋 포인터들을 키 순서로 정렬함으로써 논리적 정렬 순서를 유지합니다. 이 설계는 셀을 페이지에 최소한의 노력으로 추가할 수 있게 해주며, 삽입, 수정, 삭제 연산 시 셀을 재배치할 필요가 없습니다.

이제 이름들을 저장하는 페이지 예시를 생각해보겠습니다. 두 개의 이름(Tom과 Leslie)이 페이지에 추가되었고, 이들의 삽입 순서는 Tom, Leslie입니다. 그림 3-7에서 볼 수 있듯이, 이들의 논리적 순서(알파벳 순)는 삽입 순서와 일치하지 않습니다. 셀은 삽입 순서대로 배치되지만, 이진 탐색을 사용할 수 있도록 오프셋은 재정렬됩니다.

이제 Ron이라는 이름을 이 페이지에 추가하려고 합니다. 새로운 데이터는 페이지의 남은 공간 상단에 추가되지만, 셀 오프셋은 렉시컬 키 순서를 유지해야 합니다: Leslie, Ron, Tom. 이를 위해, 오프셋을 재정렬해야 하며, 삽입 지점 이후의 포인터들을 오른쪽으로 이동시켜 Ron 셀에 대한 새로운 포인터가 들어갈 공간을 만들어야 합니다. 이는 그림 3-8에서 볼 수 있습니다.

- 페이지에 여러 개의 셀을 배치하기 위해서 ‘슬롯 페이지’ 기법을 쓴다고 했었음
  - 좌측에는 포인터 배열 (셀 오프셋), 우측에는 셀 데이터를 저장
  - 셀은 삽입 순서대로 우측에 쌓임
  - 포인터는 키 값 기준으로 정렬됨
- 삽입 순서와 정렬 순서는 다름
  ![image.png](attachment:b09412ba-b4e3-4d36-b212-1d2ba11b4cba:image.png)
  - 삽입 순서가 톰 → 레슬리라고 하자. 데이터는 위와 같이 들어가 있을 것
  - 포인터 배열의 경우 정렬되어 있어야 함 (이진 탐색의 전제 조건)
  ![image.png](attachment:fdbbc69f-039d-4d49-8628-920d69980d90:image.png)
  - 론을 삽입한다면 삽입한 가장 마지막에 삽입한 레슬리 앞에 론이 들어감
  - 포인터 배열는 정렬되어야 하므로 레슬리 → 론 → 톰으로 정렬됨
- 장점 → 데이터를 재배치하지 않고 포인터만 수정하므로 삽입/삭제 빠름. 정렬되어 있으므로 이진 탐색 가능

## Managing Variable-Size Data

가변 크기 데이터를 관리할 때, 페이지에서 항목을 제거하더라도 실제 셀을 삭제하거나 다른 셀들을 이동시켜 빈 공간을 재배치할 필요는 없습니다. 대신 해당 셀은 삭제된 것으로 표시하고, 메모리에 있는 가용 공간 리스트(availability list)를 업데이트하여 해제된 메모리 크기와 해당 위치의 포인터를 기록합니다. 가용 공간 리스트는 해제된 세그먼트들의 오프셋과 크기를 저장합니다. 새로운 셀을 삽입할 때는 우선 이 가용 공간 리스트를 확인하여, 삽입할 셀이 들어갈 수 있는 세그먼트가 있는지 찾습니다. 그림 3-9는 사용 가능한 세그먼트가 있는 단편화된 페이지의 예시를 보여줍니다.

![image.png](attachment:0a0a806d-29c8-423f-88f9-344cbfeb616e:image.png)

- 가변 크기 데이터에 대한 삭제
  - 셀을 실제로 지우지 않고, 삭제 표시만 함
  - 삭제된 셀의 오프셋과 크기를 availability list에 저장
  - 해당 리스트 참조하여 신규 셀 삽입 시 빈 세그먼트 있는지 체크

SQLite는 이러한 비어 있는 세그먼트를 freeblock이라 부르며, 페이지 헤더에 첫 번째 freeblock에 대한 포인터를 저장합니다. 또한, 페이지 내의 총 사용 가능 바이트 수도 저장하여, 페이지를 재정렬한 뒤 새로운 요소를 수용할 수 있는지를 빠르게 판단할 수 있도록 합니다.

**적합성(fit)은 다음과 같은 전략에 따라 계산됩니다:**

- _First fit_
  첫 번째로 적합한 세그먼트를 재사용한 후 남는 공간이 너무 작아 다른 셀이 들어갈 수 없는 경우가 있어, 오히려 공간 낭비가 발생할 수 있습니다.
- _Best fit_
  삽입 후 남는 공간이 가장 적은 세그먼트를 찾아 사용합니다.

만약 연속된 바이트를 충분히 찾지 못하더라도 단편화된 바이트의 총량이 충분하다면, 현재 존재하는 셀들을 읽어 다시 써서 페이지를 재정렬(defragmentation)하고 새로운 쓰기를 위한 공간을 회수할 수 있습니다. 만약 재정렬 후에도 여전히 충분한 공간이 없다면, 오버플로우 페이지(“Overflow Pages” 참조)를 생성해야 합니다.

- SQLite 구현
  - 비어있는
  - 페이지 헤더에 첫 freeblock 포인터 + 총 사용 가능한 바이트 수를 통해 빠르게 확인 가능
- 적합성(fit) 판단 전략
  - first fit → 가장 먼저 찾은 세그먼트를 사용. but 남는 공간이 크면 낭비 가능성 있음
  - best fit → 남는 공간이 최소화되는 세그먼트를 사용
  - 단편화와 관련있음

지역성(locality)을 향상시키기 위해(특히 키의 크기가 작을 경우), 일부 구현에서는 리프 수준에서 키와 값을 분리하여 저장합니다. 키들을 함께 보관하면 검색 시 지역성이 개선될 수 있습니다. 검색 대상 키를 찾고 나면, 해당 키에 대응하는 인덱스를 이용해 값을 저장한 value 셀에서 값을 찾을 수 있습니다. 키가 가변 크기인 경우, 추가적으로 value 셀에 대한 포인터를 계산하고 저장해야 합니다.

- 단말 노드에서 키와 값을 분리하여 저장하는 방식 (값 셀을 따로 두는 방식)
  - 지역성 개선이 가능함
  - 키는 값에 비해 크기가 작다는 가정 하에, 하나의 페이지가 더 많은 키를 저장할 수 있음 → 성능 향상
  - 키를 찾고 나면 → 값 셀로 이동하여 찾기
    - 이때 고정 키라면 인덱스를 타고 가는 것이 아니라 인덱스, 즉 n번째 키라면 → n번째 값을 찾아갈 수 있음.
      - 고정 크기 값이라면 오프셋 = 인덱스 \* 크기로 구할 수 있으니 문제 없음
      - 가변 크기 값이라면, 별도 포인터 배열의 ptr[n]와 같이 접근하여 접근 가능
    - 가변 크기 키 / 가변 크기 값이라면, 키 셀마다 ptr[i]를 저장하여 접근해야 함. 크기가 다 다르기 때문 → 이게 책에서 말하는 내용

요약하자면, B-트리 레이아웃을 단순화하기 위해 각 노드는 하나의 페이지를 차지한다고 가정합니다. 하나의 페이지는 고정 크기의 헤더, 셀 포인터 블록, 셀들로 구성됩니다. 셀은 키와, 자식 노드를 나타내는 페이지나 관련된 데이터 레코드를 가리키는 포인터를 담습니다. B-트리는 간단한 포인터 계층 구조를 사용합니다. 즉, 트리 파일 내에서 자식 노드를 찾기 위해 페이지 식별자를 사용하고, 페이지 내에서 셀을 찾기 위해 셀 오프셋을 사용합니다.

- 요약
  - 각 노드는 하나의 페이지를 차지한다고 가정
  - 하나의 페이지는 1) 고정 크기 헤더 2) 셀 포인터 블록 3) 셀로 구성됨
  - 셀 → 키 / 포인터를 가짐. 포인터는 자식 노드 페이지 혹은 데이터 레코드를 가리킬 수 있음
  - 자식 노드 페이지를 찾기 위해서는 페이지 ID를 사용하고 / 페이지 내부에서 셀을 찾기 위해서는 셀 오프셋을 사용

## Versioning

데이터베이스 시스템은 지속적으로 발전하며, 개발자들은 기능을 추가하고 버그 및 성능 문제를 해결하기 위해 노력합니다. 그 결과로 바이너리 파일 포맷이 변경될 수 있습니다. 대부분의 경우, 저장 엔진의 버전은 하나 이상의 직렬화 포맷(예: 현재 포맷 및 하나 이상의 이전 포맷)을 지원해야 합니다. 이를 지원하기 위해서는 어떤 버전의 파일을 다루고 있는지를 알아낼 수 있어야 합니다.

이 작업은 여러 방식으로 수행할 수 있습니다. 예를 들어, Apache Cassandra는 파일 이름에 버전 접두사를 사용합니다. 이 방식을 통해 파일을 열지 않고도 어떤 버전인지 알 수 있습니다. 버전 4.0부터는 데이터 파일 이름에 `na` 접두사가 붙으며, 예를 들어 `na-1-big-Data.db`와 같은 형식입니다. 이전 버전의 파일은 다른 접두사를 가지며, 예를 들어 버전 3.0에서 작성된 파일은 `ma` 접두사를 사용합니다.

또 다른 방법은 버전을 별도의 파일에 저장하는 것입니다. 예를 들어 PostgreSQL은 `PG_VERSION` 파일에 버전 정보를 저장합니다.

버전은 인덱스 파일 헤더에 직접 저장될 수도 있습니다. 이 경우, 헤더의 일부 또는 전체가 버전 간 변경되지 않는 형식으로 인코딩되어야 합니다. 파일이 어떤 버전으로 인코딩되었는지를 알아낸 후, 해당 버전에 맞는 리더(reader)를 생성하여 내용을 해석할 수 있습니다. 일부 파일 포맷은 버전을 식별하기 위해 매직 넘버를 사용하는데, 이에 대해서는 "Magic Numbers" 절에서 더 자세히 설명합니다.

- 버저닝을 쓰는 이유
  - DBMS는 계속 변경되기 때문에 파일 포맷도 변경될 수 있음
  - 변경으로 인한 여러 포맷들을 지원할 수 있어야 함
  - 이를 위해서 각 포맷을 구분할 수 있어야 함 → 버저닝
- 파일 이름 접두사 방식 → Apache Cassandra
  - na prefix는 4.0, ma prefix는 3.0
  - 파일을 열지 않아도 버전 알 수 있음
- 버전 파일 별도 저장 → PostgreSQL
  - PG_VERSION 파일에 저장
- 파일 헤더에 버전 저장
  - 인덱스 파일 헤더에 저장
  - 파일 헤더에 버전 정보가 내장되므로 헤더 영역의 전체 혹은 일부는 변경되지 말아야 함
    - 가령 헤더의 첫 4바이트를 정수형으로 버저닝하기로 정했는데, 나중에 뒤 4바이트로 바꾸는 건 불가능함
  - 여기서 버전 정보를 가져와서 해당 버전용 리더(파서)를 만들어서 내용을 해석

## Checksumming

디스크의 파일은 소프트웨어 버그나 하드웨어 고장으로 인해 손상되거나 오류가 발생할 수 있습니다. 이러한 문제를 사전에 식별하고 손상된 데이터를 다른 하위 시스템이나 심지어 다른 노드로 전파하는 것을 방지하기 위해 우리는 체크섬과 순환 중복 검사(CRC)를 사용할 수 있습니다.

일부 자료에서는 암호화 해시 함수와 비암호화 해시 함수, CRC, 체크섬을 구분하지 않지만 이들은 모두 큰 데이터를 작은 수로 축약한다는 공통점이 있을 뿐 용도와 목적, 보장 수준은 서로 다릅니다.

체크섬은 가장 약한 형태의 보장을 제공하며 여러 비트가 동시에 손상된 경우를 감지할 수 없습니다; 보통 XOR 기반 패리티 검사나 합산 방식으로 계산됩니다 [KOOPMAN15].

CRC는 여러 연속 비트가 손상되는 버스트 에러를 감지하는 데 도움이 되며 구현은 보통 룩업 테이블과 다항식 나눗셈을 사용합니다 [STONE98]. 통신 네트워크나 스토리지 장치 오류의 상당 부분이 이러한 다중 비트 오류 형태로 나타나므로 이를 감지하는 것이 중요합니다.

- 디스크는 SW/HW 이슈로 인해 손상될 수 있음. 문제를 식별하고, 손상된 데이터의 전파를 막기 위해 두 가지 방식 사용 → 체크섬과 CRC
  - 암호화 / 비암호화 해시, CRC, 체크섬을 구분하지 않는 자료도 있지만, 큰 데이터 → 작은 수로 축약한다는 공통점 외에는 용도 / 목적 / 보장 수준은 다 다름
- 체크섬
  - 가장 약한 수준의 보장
  - 여러 비트 동시 손상 감지 X
  - 두 가지 방식
    - XOR 기반 방식 → 모든 값을 비트 단위로 XOR 처리
    - 합산 방식 → 모든 바이트를 정수로 취급하여 더하기
  - 한계 → 단일 비트 / 바이트 / 누락 등은 검출 가능하지만, swap이나 상쇄 케이스(합산 방식에서 +- 1 오류 발생 케이스) 등 검출 불가한 케이스 있으므로 보장 수준 낮음. 하지만 빠르다
- CRC
  - 버스트 에러 (여러 비트의 연속 손상) 감지에 좋음
  - 다항식 나눗셈 방식 원→ 데이터를 2진수로 생각하고, 이걸 고정된 다항식 G(x) (제너레이터 다항식이라고도 부름) 으로 나눈 나머지를 CRC 코드로 붙여서 전송
  - 룩업 테이블 방식 → 미리 계산된 CRC 결과를 테이블로 저정해두고 활용
  - 연속된 다중 비트 오류 → 노이즈, 무선 전송 등에서 자주 발생
    - 한편 단일 비트 오류는 bit flip 같은 케이스에서 발생

경고: 비암호화 해시와 CRC는 데이터가 변조되었는지 확인하는 용도로 사용해서는 안 되며, 이를 위해서는 보안을 위해 설계된 강력한 암호화 해시를 사용해야 합니다. CRC의 주된 목적은 데이터에 의도치 않은 우발적인 변경이 없는지를 확인하는 것이며 이러한 알고리즘은 공격이나 의도적인 데이터 변경에 저항하도록 설계되지 않았습니다.

- CRC, 비암호화 해시 → 우발적 변경을 감지하기 위한 것이고, 보안 목적으로는 사용 X
  - 의도적인 데이터 위변조 방지 → 암호화 해시 사용 필요
  - CRC, 비암호화 해시 → 무결성 검증이 목적
  - 왜 의도적인 데이터 위변조는 아닌가? → 공격자가 해시, CRC 값도 맞춰서 조작할 수 있기 때문
  - 암호화 해시 → 여러 가지 보안 요구사항 고려 (충돌 회피성, 단방향성, 제 2 역상 저항성)

디스크에 데이터를 쓰기 전에 데이터의 체크섬을 계산하여 함께 기록하고, 읽어 올 때 다시 계산한 값과 비교하여 불일치가 있으면 손상이 발생했음을 인지하고 해당 데이터를 사용하지 않습니다.

전체 파일에 대해 체크섬을 계산하는 것은 비실용적이며 매번 접근할 때마다 전체 내용을 읽을 가능성도 낮으므로 페이지 단위로 체크섬을 계산해 페이지 헤더에 저장하는 것이 일반적입니다. 이렇게 하면 작은 부분집합에 대해 수행되므로 체크섬이 더 견고해지고 손상이 한 페이지에 국한된 경우 파일 전체를 폐기할 필요가 없습니다.

- 체크섬 활용
  - 데이터 쓰기 전에 미리 체크섬을 계산하여 같이 저장
  - 읽을 때 다시 계산하여 체크섬과 비교
  - 다르다면 손상된 것으로 판단, 사용하지 않음
- 전체 파일 단위 아닌, 페이지 단위 체크섬
  - 모든 파일 단위 체크섬 → 모든 내용을 다 읽어야 한다는 전제
  - 이렇게 큰 크기를 읽는 건 비싸고, 빈도도 드물다
  - DB는 전체 중 일부만을 접근하는 목적
  - 대신 페이지 단위로 체크섬 저장
    - 체크섬 ‘충돌’의 경우 데이터가 클 때 발생 (즉 데이터가 클 수록 같은 체크섬 가능성 커짐) → 데이터를 더 작은 단위로 나누므로 굿
    - 손상 발생 시 전체 파일이 아닌 페이지만 폐기하면 됨

## Summary

이 장에서는 바이너리 데이터 구성 방식에 대해 배웠습니다. 즉, 원시 데이터 타입을 직렬화하는 방법, 이들을 셀로 결합하는 방법, 셀로부터 슬롯 페이지를 구성하고 이러한 구조를 탐색하는 방법에 대해 배웠습니다.

문자열, 바이트 시퀀스, 배열과 같은 가변 크기 데이터 타입을 다루는 방법과, 포함된 값의 크기를 저장하는 특수 셀을 구성하는 방법을 학습했습니다.

또한, 셀 ID를 통해 페이지 외부에서 개별 셀을 참조할 수 있고, 삽입 순서대로 레코드를 저장하며, 셀 오프셋 정렬을 통해 키 순서를 유지할 수 있는 슬롯 페이지 형식에 대해서도 논의했습니다.

이러한 원칙들은 디스크 상 구조나 네트워크 프로토콜을 위한 바이너리 포맷을 구성하는 데 사용할 수 있습니다.

- 3장 요약
  - 이진 데이터를 구성하는 방식
    - 원시 데이터 타입 직렬화 방식
    - 셀과 슬롯 페이지 구조
  - 가변 크기 데이터 타입을 다루는 법 + 크기를 저장하는 법
  - 슬롯 페이지
    - 페이지 외부에서 셀 ID를 통해 셀을 참조 가능
      - 셀 위치에 대해 알 필요 없이 ID로 접근하고, 내부적으로 포인터를 통해 실제 위치에 참조
    - 삽입 순서대로 레코드 저장 (실제 데이터는 삽입 순서대로 쌓임)
    - 셀 오프셋 정렬을 통해 키 순서 유지 (포인터 배열만 정렬된 상태로 유지하여, 이진 탐색 가능케 함)
