# 고급 백엔드 스터디 5주차

## General Principles

### General Principles (1)

대개 파일 포맷 설계는 주소 지정 방식을 결정하는 것에서 시작합니다. 즉, 파일을 동일한 크기의 페이지로 나눌지, 그리고 그 페이지를 하나의 블록으로 표현할지 아니면 여러 개의 연속된 블록으로 표현할지를 정합니다. 인-플레이스(in-place) 갱신을 지원하는 저장 구조는 페이지 크기를 동일하게 맞추는 경우가 많으며, 이는 읽기·쓰기 접근을 크게 단순화해 줍니다. 추가-전용(append-only) 구조 역시 페이지 단위로 데이터를 기록하는 경우가 일반적입니다. 레코드들은 차례로 메모리에 쌓이다가 페이지가 가득 차면 곧바로 디스크에 플러시됩니다.

- 파일 포맷 설계의 첫 걸음은 ‘주소 지정(addressing) 방식’ 결정
  - 페이지 단위로 고정 크기를 사용할지 여부가 관건
- “파일을 동일한 크기의 페이지로 나눌지, 그리고 그 페이지를 하나의 블록으로 표현할지 아니면 여러 개의 연속된 블록으로 표현할지를 정합니다.” → 무슨 말인가?
  - 일단 블록 vs 페이지 리마인드부터 하고 가자.

### (번외) 블록 vs 페이지

[https://www.geeksforgeeks.org/difference-between-page-and-block-in-operating-system/](https://www.geeksforgeeks.org/difference-between-page-and-block-in-operating-system/)

- 블록 (block)
  - 정의: 파일을 읽거나 데이터를 파일에 쓸 수 있는 가변 크기의 저장 단위
  - 구성: 섹터(sectors)로 구성되며, 하나 또는 여러 개의 섹터(2, 4, 6개 등)로 이루어짐
  - 특징:
    - 데이터 저장의 최소 단위
    - 물리적 레코드라고도 불림
    - 대부분의 OS에서 데이터 저장에 사용
    - 0바이트 파일도 최소 하나의 블록을 차지
    - 예시: NTFS의 기본 블록 크기는 4096바이트
  - 장점
    - 효율적인 저장 공간 사용
    - 여러 블록을 한 번에 읽어 성능 향상
  - 단점
    - 고정 블록 크기로 인한 저장 공간 낭비 가능
    - 가변 블록 크기 사용 시 추가 오버헤드 발생
- 페이지 (page)
  - 정의: 주 메모리에서 프로세서로 로드되는 고정 크기의 메모리 단위
  - 구성: 블록의 단위 또는 블록 그룹으로 구성
  - 특징:
    - 가상 페이지 또는 메모리 페이지라고도 불림
    - 일반적으로 2KB 또는 4KB의 고정 크기
    - RAM과 동등한 인메모리 저장의 최소 단위
    - 프로세서 아키텍처에 의해 크기가 결정됨
  - 장점
    - 요구에 따른 효율적 메모리 관리
    - 가상 메모리 사용 가능
    - 유연한 메모리 할당
  - 단점
    - 가상-물리 메모리 매핑 관리로 인한 오버헤드
    - 쓰래싱 발생 시 성능 저하

| **블록(Block)**                  | **페이지(Page)**                     |
| -------------------------------- | ------------------------------------ |
| 가변 크기 저장 단위              | 고정 크기 메모리 단위                |
| 파일 시스템에서 관리             | 운영체제의 메모리 관리 단위에서 관리 |
| 물리적 레코드                    | 가상 페이지/메모리 페이지            |
| 파일 읽기/쓰기용                 | 주 메모리-보조 메모리 간 전송용      |
| 다양한 저장 장치에서 처리가 복잡 | 고정 크기로 인해 처리가 간단         |

페이지와 블록은 모두 주 메모리와 보조 저장 장치 간의 데이터 전송 단위로 작동합니다. 운영체제는 일반적으로 정보 전송 목적으로 블록보다 페이지를 선호하는데, 이는 여러 저장 장치가 있을 때 페이지로 처리하는 것이 더 쉽고, 페이지 크기가 고정되어 있어 관리가 용이하기 때문입니다.

### General Principles (2)

- “파일을 동일한 크기의 페이지로 나눌지,
  그리고 그 페이지를 하나의 블록으로 표현할지
  아니면 여러 개의 연속된 블록으로 표현할지를 정합니다.” 의미 파악 1. “페이지 크기를 고정할 것인가?” - 고정 크기 - 페이지 ID → 파일 오프셋 계산이 offset = page_id \* page_size 로 단순화 - 페이징 캐시·버퍼 풀에서 메모리 관리가 편리 - 단점: 내부 파편화(internal fragmentation) 가능 - 가변 크기 - 큰 레코드를 붙여 쓰는 로그 구조 ColDB 등에서 채택 - 단점: 주소 계산 복잡, 페이지 헤더가 커짐 2. “한 페이지가 디스크 블록 몇 개를 차지할 것인가?” - 1 페이지 = 1 블록 - 페이지 크기를 4 KiB(블록 크기)로 맞추면 단일 I/O 요청으로 완전한 페이지를 읽고 쓸 수 있음 → 랜덤 I/O 효율 - 장애 복구(WAL) · 플러시 시 원자적(atomic) 쓰기 보장에 유리: 블록 하나만 손상돼도 CRC로 감지 가능 - 단점: 레코드가 크면 한 페이지에 못 들어가 추가 관리 필요(overflow page 등) - 1 페이지 = n 블록(연속) - 예: 8 KiB / 16 KiB 페이지. 내부적으로는 4KiB 블록 2개 / 4개를 연달아 배치 - 장점 - 동일 페이지 안에 더 많은 레코드 수용 ⇒ 검색(스캔) 시 히트율↑, 트리 높이↓ - 큰 레코드도 별도 오버플로 없이 저장 가능 - 고려 사항 - 연속 블록 할당이 파일시스템에서 항상 보장되지 않음 → extent allocator 활용, 프래그먼트 시 I/O 분산 - 복구·체크섬 범위 확대 ⇒ 손상 시 더 많은 데이터 영향 - SSD는 내부적으로 이미 16–32 KiB erase page 사용 → 물리 page size 고려해 정렬(alignment) 필요
- 저장 구조별 페이지 전략
  1. in-place update 저장 구조
     - 레코드를 기존 위치에서 덮어쓰는 방식
     - 페이지 크기를 통일해 두면
       - 오프셋 계산이 단순
       - 디스크 I/O가 예측 가능 (배수로 접근 가능하니)
  2. append-only 저장 구조
     - 새 데이터를 항상 파일 끝에 추가
     - 메모리 버퍼에 페이지 단위로 쌓다가 가득 차면 디스크로 플러시
       - 저저번주 배웠던 버퍼링 → 이거는 IO 횟수 줄어드니까 왜 하는지 이해되긴 함
       - 그런데 왜 하필 페이지 단위로? → 마찬가지로 3주차 때 배웠었다. 그래도 설명 안한 부분 있으니 추가로 알아보자
         - HDD
           - 순차 쓰기하면 빠른 것까진 알겠는데, 블럭 단위로도 쓸 수 있지 않나? 왜 하필 페이지 단위? 라는 생각이 들 수도 있음.
           - DBMS는 페이지마다 헤더를 둬서 LSN(last sequence number, 즉 마지막 로그 레코드 번호) 및 체크섬 값을 저장함. 그리고 페이지 엑세스 시 체크섬을 검증하기도 함.
           - 그래서 페이지 단위로 쓰는 게 좋은 것
         - SSD
           - 이건 쉽다. 3주차 때 언급한 쓰기 증폭 때문. SSD는 덮어쓰기가 안되므로 (플래시 메모리의) 페이지를 다시 쓰려면 (플래시 메모리의) 블록 (≠ OS의 블록) 전체를 지워야 한다고 했었다. 따라서 (OS의) 페이지 단위로 써야 한다는 것은 자명함

파일은 대개 고정 크기의 헤더로 시작하며 고정 크기의 트레일러로 끝날 수 있는데, 이들은 빠르게 접근해야 하거나 나머지 파일을 해독하는 데 필요한 부가 정보를 담습니다. 파일의 나머지 부분은 페이지로 분할됩니다. 그림 3-3은 이러한 파일 구성을 도식적으로 보여 줍니다.

![image.png](%E1%84%80%E1%85%A9%E1%84%80%E1%85%B3%E1%86%B8%20%E1%84%87%E1%85%A2%E1%86%A8%E1%84%8B%E1%85%A6%E1%86%AB%E1%84%83%E1%85%B3%20%E1%84%89%E1%85%B3%E1%84%90%E1%85%A5%E1%84%83%E1%85%B5%205%E1%84%8C%E1%85%AE%E1%84%8E%E1%85%A1%201fc998e1b7098050888adc497c384e14/image.png)

- 파일 구조
  - 헤더와 트레일러는 고정 크기로 배치되어 위치 계산이 단순함
    - 헤더: 버전, 매직 넘버, 체크섬 오프셋 등 빠른 판별용 정보 포함
    - 트레일러: 색인 테이블, 전체 체크섬 등 파일 끝에 두어 쓰기 완료 후 갱신하기 용이함
- 본문 페이지 분할
  - 균일한 페이지 크기 채택 → 디스크 블록과 정렬되어 I/O 효율 증가
  - 논리적 레코드 위치를 ‘페이지 번호 + 오프셋’으로 표현 가능하여 탐색‧버퍼 관리 단순화
- 장점
  - 헤더, 트레일러 덕분에 데이터 영역을 해석하기 전 필요한 메타정보를 O(1)로 확보함
  - 페이지 단위 접근은 캐시·버퍼 관리 정책(예: LRU)과 호환성이 좋고, 부분 손상 시 페이지 단위 복구가 가능함

대부분의 데이터 저장소는 테이블이 담을 수 있는 필드의 개수, 순서, 타입을 명시하는 고정 스키마를 갖습니다. 고정 스키마를 사용하면 디스크에 저장되는 데이터 양을 줄일 수 있습니다. 필드 이름을 반복해서 기록하는 대신 위치 기반 식별자를 사용할 수 있기 때문입니다.

회사 직원 디렉터리 형식을 설계해 이름, 생년월일, 세금 식별번호, 성별을 저장하려 한다면 여러 가지 방법을 취할 수 있습니다. 예를 들어 고정 크기 필드(생년월일, 세금 번호 등)를 구조체의 앞부분에 두고 그 뒤에 가변 크기 필드를 두는 방식이 있습니다: 고정 크기 필드: | (4 bytes) employee_id | | (4 bytes) tax_number | | (3 bytes) date | | (1 byte) gender | | (2 bytes) first_name_length | | (2 bytes) last_name_length | 가변 크기 필드: | (first_name_length bytes) first_name | | (last_name_length bytes) last_name | first_name에 접근하려면 고정 영역 뒤에서 first_name_length 바이트를 잘라내면 됩니다. last_name에 접근하려면 그 앞에 놓인 가변 필드들의 길이를 확인해 시작 위치를 찾을 수 있습니다. 여러 필드를 두 번 계산하지 않으려면 고정 영역에 각 가변 필드의 오프셋과 길이를 함께 기록할 수도 있습니다. 이렇게 하면 어느 가변 필드든 독립적으로 바로 찾아낼 수 있습니다.

- 고정 스키마 → RDBMS 테이블 생각하면 됨
  - 테이블 정의가 미리 고정되어 필드(컬럼)의 개수, 순서, 데이터 타입이 변하지 않음
  - 장점
    - 위치 기반 식별자
    - 저장 공간 아낄 수 있음 → 예전에 1장에서 암시적 식별자 생각나는지? 만약 스키마에 2자리 ID, 8자리 생년월일, 학번 순으로 나온다는 게 정의되어 있으면, 각 레코드를 해석할 때 9920001010C123456 → 99번 ID의 2000년 10월 10일 생일의 C123456 학번이라는 걸 알 수 있음. 해당 레코드에서 필드 이름을 안 주더라도…!
    - 이건 근데 가변 길이 데이터는 고려 안한 거잖아요 → 뒤에서 설명함…
- 만약 이름, 성, 생년월일, 세금번호, 성별 저장한다면
  - 고정 길이 필드 영역
    - 고정 길이 값(날짜, 번호 등)을 선두에 일렬 배치
    - 그리고 가변 길이의 필드의 길이 값(이름, 성)을 그 다음으로 배치
  - 가변 길이 필드 영역
    - 그 다음에 실제 가변 길이 문자열들을(이름, 성) 배치
  - 접근 방식
    - 이름 → 가변 길이 필드 영역 시작부부터 이름 필드 길이값만큼 잘라서 쓰면 됨
    - 성 → 가변 길이 필드 영역 시작부 + 이름 길이 값부터 성 길이 값만큼 잘라서 쓰면 됨
- 근데 가변 필드가 많아지면? 시작부 + 앞에 있는 가변 필드들 길이 다 더해야 하는 단점
  - 고정 길이 필드 영역에 ‘길이’만 저장하지 않고, (오프셋, 길이) 쌍으로 저장
  - 그러면 바로 오프셋 ~ 오프셋 + 길이만큼만 잘라서 쓰면 되므로 연속 계산 필요 X
- 하지만 역시 이 방식에도 단점 있음
  - 필드 추가/삭제되면 영향받는 오프셋 다시 계산해야함
  - 초기 시작 위치 + 길이 합만으로도 구할 수 있는 오프셋을 중복해서 저장하므로 고정 영역 커짐
- 이러한 trade-off 관계에서 둘 중 어떤 방식을 선택할까?
  - 오프셋을 미리 계산하는 방식 → 여러 컬럼이 필요한 경우에 유리
  - 따라서 (OLAP 방식의) 열 기반 DBMS는 일부 컬럼만 선택해서 조회하므로 길이 누적 스캔을 쓰더라도 괜찮음. 계산하는 오버헤드가 적으므로…
  - 반면 행 기반 DBMS는 오프셋을 미리 계산하는 오프셋 테이블 방식을 선택할 것 (아마도?) → 근데 OLTP도 항상 모두 조회한다는 보장은 없지 않나?
  - 실제로는?
    - [PostgreSQL](https://www.postgresql.org/docs/current/storage-page-layout.html)
      - “`ItemIdData`: 실제 아이템을 가리키는 아이템 식별자 배열입니다. 각 항목은 (오프셋, 길이) 쌍입니다. 항목당 4바이트입니다.”
    - [MySQL InnoDB](https://dev.mysql.com/doc/refman/8.4/en/innodb-row-format.html)
      - 두 가지 타입이 있음: REDUNDANT, COMPACT/DYNAMIC (둘을 묶었음)
      - REDUNDANT
        - “레코드는 각 필드에 대한 포인터를 포함합니다. 레코드 내 필드의 총 길이가 128바이트 미만이면 포인터는 1바이트이고, 그렇지 않으면 2바이트입니다. 포인터 배열을 레코드 디렉터리라고 합니다. 포인터가 가리키는 영역이 레코드의 데이터 부분입니다.”
        - 레코드 디렉터리라는 이름으로 포인터 배열을 쓴다. 즉 오프셋 테이블 방식이다
      - COMPACT/DYNAMIC
        - COMPACT 행 포맷은 REDUNDANT 행 형식에 비해 행 저장 공간을 약 20% 줄이지만, 일부 작업에서 CPU 사용량이 증가하는 대가를 치릅니다. 워크로드가 캐시 적중률과 디스크 속도에 의해 제한되는 일반적인 워크로드라면 COMPACT 포맷이 더 빠를 가능성이 높습니다. 워크로드가 CPU 속도에 의해 제한되는 경우 COMPACT 포맷이 더 느릴 수 있습니다.
          - 왜 저장 공간이 줄어들까? → 아래서 설명
      - 레코드 헤더의 가변 길이 부분은 NULL 컬럼을 나타내는 비트 벡터를 포함합니다. 인덱스에서 NULL이 될 수 있는 컬럼의 수가 N개라면, 비트 벡터는 CEILING(N/8) 바이트를 차지합니다. (예를 들어, NULL이 될 수 있는 컬럼이 9개에서 16개 사이라면, 비트 벡터는 2바이트를 사용합니다.)
        - nullable 컬럼이 1~8개면 1바이트, 9~16개면 2바이트, …
      - NULL인 컬럼들은 이 벡터의 비트를 제외하고는 별도의 공간을 차지하지 않습니다.
        - nullable 컬럼에 대하여 해당 레코드의 값이 null인 경우, 별도로 공간을 안먹고 null 벡터에서 딱 1비트만 차지함.
      - 헤더의 가변 길이 파트는 또한 가변 길이 컬럼들의 길이도 포함합니다. 각 길이는 컬럼의 최대 길이에 따라 1바이트 또는 2바이트를 차지합니다. 인덱스의 모든 컬럼이 NOT NULL이고 고정 길이를 가진다면, 레코드 헤더는 가변 길이 부분을 갖지 않습니다.”
        - 길이는 1바이트 아니면 2바이트 → 0 ~ 2^8-1, 2^8 ~ 2^16 - 1을 나타낼 수 있다. 즉 0 ~ 255, 256 이상으로 나뉨
        - 아니 2^16 - 1 = 65535인데, 그보다 긴 값은 어떻게?
        - 768바이트까지는 레코드 내부에 저장, 나머지는 별도의 오버플로 페이지에 저장 + 포인트로 외부 데이터 참조
          - 왜? → 이거까지 쓰기엔 귀찮다… [https://dev.mysql.com/blog-archive/externally-stored-fields-in-innodb/](https://dev.mysql.com/blog-archive/externally-stored-fields-in-innodb/)
          - InnoDB는 16KB의 페이지 크기를 가짐. 여기서 페이지 헤더 / 트레일러, 디렉토리 제외하면 실제 인덱스 레코드 공간은 ~158000
      - “각각의 non-NULL 가변 길이 필드에 대해, 레코드 헤더는 해당 컬럼의 길이를 1바이트 또는 2바이트로 포함합니다. 2바이트가 필요한 경우는 컬럼의 일부가 오버플로 페이지에 외부적으로 저장되거나, 최대 길이가 255바이트를 초과하면서 실제 길이가 127바이트를 초과하는 경우입니다. 외부적으로 저장된 컬럼의 경우, 2바이트 길이는 내부적으로 저장된 부분의 길이와 외부적으로 저장된 부분을 가리키는 20바이트 포인터의 길이를 합친 값을 나타냅니다. 내부 부분은 768바이트이므로, 길이는 768+20이 됩니다. 20바이트 포인터는 컬럼의 실제 길이를 저장합니다.”

더 복잡한 구조를 만들기 위해서는 일반적으로 계층 구조를 구성하게 됩니다. 즉, 필드는 원시 데이터로 구성되고, 셀은 필드로 구성되며, 페이지는 셀로, 섹션은 페이지로, 영역은 섹션으로 구성되는 식입니다. 이러한 구성 방식에는 반드시 따라야 할 엄격한 규칙이 있는 것은 아니며, 어떤 종류의 데이터를 위한 포맷을 만들고자 하는지에 따라 달라집니다.

계층 구조

- 가변 길이 데이터 타입에 대한 고려 → 길이 배열 or (오프셋, 길이) 배열 등장
- 실제로는 더 복잡 → ‘계층 구조' 의 필요성!
- 원시값 → 필드 → 셀 → 페이지 → 섹션 → 리전

데이터베이스 파일은 종종 여러 부분으로 구성되며, 탐색을 돕는 조회 테이블이 함께 사용됩니다. 이 테이블은 이러한 부분들의 시작 오프셋을 가리키며, 파일의 헤더나 트레일러, 혹은 별도의 파일에 기록될 수 있습니다.

Lookup Table

- 필요성
  - 복잡한 구조에서 빠르게 탐색하기 위해 시작 지점 알려줌
- 위치
  - 페이지 헤더 / 트레일러, 별도 파일 등 다양

데이터베이스 시스템은 데이터 레코드를 데이터 파일 및 인덱스 파일에 저장합니다. 이 파일들은 고정 크기의 단위인 페이지로 나뉘며, 이 페이지는 종종 여러 파일 시스템 블록 크기를 가집니다. 페이지 크기는 일반적으로 4KB에서 16KB 사이입니다.

온디스크 B-트리 노드의 예를 살펴보겠습니다. 구조적인 관점에서 B-트리는 키와 데이터 레코드 쌍을 저장하는 리프 노드와, 키와 다른 노드로 가는 포인터를 저장하는 비리프 노드를 구분합니다. 각 B-트리 노드는 하나의 페이지 또는 여러 개의 연결된 페이지를 차지하며, 이러한 맥락에서 B-트리에서는 노드, 페이지(심지어 블록)라는 용어들이 자주 혼용됩니다.

온디스크 B-Tree 구조

- 구분
  - 리프 노드 → 실제 데이터 (key, val) 저장
  - 비리프 노드 → 키, 다른 노드로의 포인터 저장
- 문제
  - 노드 / 페이지 / 블록 용어들이 혼용됨

원래의 B-트리 논문 [BAYER72]에서는 고정 크기 데이터 레코드에 대해 단순한 페이지 구성을 설명합니다. 각 페이지는 키(k), 관련 값(v), 자식 페이지로의 포인터(p)의 3항 조합(triplet)으로 단순히 이어 붙인(concatenation) 구조입니다(도표 3-4 참조).

이 방식은 구현이 쉽다는 장점이 있지만 다음과 같은 단점이 있습니다:

- 오른쪽 끝이 아닌 위치에 키를 추가하려면 기존 요소들을 재배치해야 함
- 가변 크기 레코드를 효율적으로 관리하거나 접근할 수 없음
- 고정 크기 데이터에만 적합한 구조임

온디스크 B-Tree 구조

- 일단 단순한 구현을 보자 (BAYER72)
  - 구성 요소 → (k, v, p) 배열
- 단점
  - 중간 삽입 시 모든 요소 재배치
  - 가변 크기 레코드에 대한 고려 X

가변 크기의 레코드를 저장할 때 가장 큰 문제는 제거된 레코드가 차지했던 공간을 어떻게 회수할 것인가 하는 **공간 관리** 문제입니다. 크기 n의 레코드를 크기 m의 레코드가 있었던 자리에 넣으려 할 경우, m == n이 아니고 m - n에 정확히 맞는 다른 레코드를 찾지 못한다면 그 공간은 사용되지 않은 채로 남게 됩니다. 마찬가지로, 크기 m인 구간은 k > m인 레코드를 저장할 수 없으므로 결국 해당 공간은 회수되지 않은 채 새로운 레코드가 다른 위치에 삽입됩니다.

이 문제를 단순화하기 위해, 페이지를 고정 크기 세그먼트로 나누는 방법도 있습니다. 그러나 이 방법 역시 공간 낭비를 초래합니다. 예를 들어, 세그먼트 크기를 64바이트로 정했을 때 삽입하는 레코드 크기가 64의 배수가 아니라면, 삽입 시 64 - (n mod 64) 바이트만큼 낭비가 발생합니다. 즉, 레코드 크기가 64의 배수가 아니라면 한 블록은 부분적으로만 채워지게 됩니다.

가변 크기 레코드 문제점 1: 파편화 (fragmentation)

- 삭제된 레코드의 공간 재사용이 어려움
- 왜? 정확하게 딱 맞는 레코드가 들어온다는 보장 없기 때문
- 묘수) 더 잘게 쪼갠다면?
  - 그래도 똑같음. 그보다 더 살짝 모자른 레코드가 들어온다면?
  - → 결국 ‘가변 크기’라는 본질적 한계 존재

공간 회수는 페이지를 다시 쓰고 레코드들을 재배치함으로써 수행할 수 있지만, 이 경우 페이지 외부에서 해당 레코드에 접근하는 포인터가 여전히 이전 오프셋을 사용할 수 있으므로 오프셋을 유지해야 합니다. 따라서 낭비 공간을 최소화하면서 이러한 재배치가 이루어지는 것이 바람직합니다.

가변 크기 레코드 문제점 2: 컴팩션 그리고 포인터

- 문제점 1은 해결할 방법이 있음 → 메모리 압축 (Compaction)
- 삭제된 빈 공간 없애기 위해 나머지 레코드를 앞으로 끌고오기
  - ex: [A][ ][C][D] → [A][C][D]
- 하지만 이 역시 문제점 있음
  - 위치가 변경된 레코드를 가리키는 포인터가 invalid 하게 됨

정리하자면, 우리가 필요한 페이지 포맷은 다음의 요건을 만족해야 합니다.

- 가변 크기 레코드를 최소한의 오버헤드로 저장할 수 있어야 함
- 제거된 레코드가 차지했던 공간을 회수할 수 있어야 함
- 레코드의 정확한 위치에 관계없이 참조가 가능해야 함

문자열, 바이너리 대용량 객체(BLOBs) 등의 가변 크기 레코드를 효율적으로 저장하기 위해, **슬롯 페이지(sotted page)** 또는 **슬롯 디렉토리(slot directory)** 라는 조직 기법을 사용할 수 있습니다. PostgreSQL을 포함한 많은 데이터베이스 시스템이 이 방식을 사용합니다.

페이지 포맷 요구사항 정리

- 가변 크기 레코드를 최소한의 (공간) 오버헤드로 저장할 수 있어야 함
- 제거된 레코드가 차지한 공간을 회수할 수 있어야 함 (컴팩션)
- 그러면서도 레코드의 위치를 정확하게 참조할 수 있어야 함 (포인터)
- → 해결책: 슬롯 페이지(slotted page) 혹은 슬롯 디렉토리(slot directory)

이 방식에서는 페이지를 여러 개의 **슬롯(또는 셀)** 로 구성하고, 이들을 가리키는 포인터들과 셀 자체를 페이지 양쪽 끝에서 독립적으로 관리합니다. 따라서 셀의 순서를 유지하려면 포인터 배열만 재조정하면 되고, 레코드를 삭제할 때는 해당 포인터를 무효화하거나 제거하면 됩니다.

슬롯 페이지는 고정 크기 헤더를 가지며, 이 헤더는 페이지와 셀들에 대한 중요한 정보를 담고 있습니다. 셀들은 크기가 다를 수 있으며, 키, 포인터, 데이터 레코드 등 다양한 데이터를 저장할 수 있습니다.

슬롯 페이지(slotted page)는 고정 크기의 헤더를 가지며, 이 헤더는 해당 페이지와 그 안의 셀들에 대한 중요한 정보를 포함합니다(자세한 내용은 “페이지 헤더” 참조). 셀(cell)은 크기가 서로 다를 수 있으며, 키(key), 포인터(pointer), 데이터 레코드 등 다양한 임의의 데이터를 담을 수 있습니다. 그림 3-5는 슬롯 페이지의 구성 예시를 보여주며, 각 페이지는 **유지 영역(헤더)**, **셀들**, 그리고 **셀들을 가리키는 포인터 배열**로 구성됩니다.

슬롯 페이지

- 페이지를 여러 개의 슬롯(혹은 셀)로 나눈다
  - 크기 자유 + 키 / 포인터 / 데이터 레코드 등 다양한 값 가능
- 구조
  - 헤더
  - 포인터 배열
    - 고정 크기 배열
    - 역순으로 채워짐
  - 데이터 레코드 배열 (실 데이터)

왜 슬롯 페이지가 문제를 해결하는가?

- 최소한의 오버헤드
  - 레코드 자체를 이동시키지 않기에 시간 오버헤드 낮음
  - (2~4바이트) 포인터 배열만 두기 때문에 공간 오버헤드 낮음
- 공간 회수
  - 레코드를 삭제하려면 포인터만 무효화하면 됨
  - 컴팩션 작업할 때도 살아있는 것들만 복사해주고 포인터 갱신
- 동적 레이아웃
  - 컴팩션 통해 물리적 위치 바뀌더라도 (심지어 슬롯 바깥으로 나가더라도)
  - 포인터는 유효한 상태이므로 정확하게 접근 가능
