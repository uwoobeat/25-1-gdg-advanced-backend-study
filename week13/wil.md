# 고급 백엔드 스터디 13주차

회계사는 지우개를 사용하지 않습니다. 그랬다간 감옥에 가게 될 겁니다.
팻 헬렌드

회계사가 기록을 수정해야 할 때, 기존 값을 지우는 대신 수정 사항이 담긴 새로운 기록을 생성합니다. 분기별 보고서가 발표될 때, 이전 분기 결과를 바로잡는 사소한 수정 사항이 포함될 수 있습니다. 최종 결과를 도출하려면, 기록들을 살펴보고 소계를 계산해야 합니다 [HELLAND15].

- 불변 스토리지와 회계 업무는 비슷한 점이 많음. 회계 장부에서는 기존 기록을 없애거나 수정하는 대신에 항상 변경사항을 새로운 거래 기록으로 추가함.
- 그래서 특정 계좌의 최종 잔액을 알려면처 모든 거래기록을 처음부터 순서대로 계산해서 구해야 함.

마찬가지로, 불변(immutable) 스토리지 구조는 기존 파일의 수정을 허용하지 않습니다. 테이블은 한 번만 쓰이고 다시는 수정되지 않습니다. 대신, 새로운 레코드는 새 파일에 추가(append)되며, 최종 값을 찾거나 (혹은 값이 없음을 확인하려면), 여러 파일로부터 레코드를 재구성해야 합니다. 반면에, 가변(mutable) 스토리지 구조는 디스크 상의 레코드를 제자리에서(in place) 수정합니다.

- 불변 스토리지 구조도 이와 비슷함. 한 번 쓰인 파일은 절대 수정되지 않음. 모든 변경사항은 새로운 레코드로 새 파일에 추가됨. 현재 값을 알려면 여러 파일에 흩어진 기록들을 모아서 최종 상태를 만들어야 함.
- 한편 가변 구조는 그 데이터가 있는 자리에서 바로 수정하기 때문에 항상 그 자리를 가면 최종 상태 값을 알 수 있음

불변 데이터 구조는 함수형 프로그래밍 언어에서 자주 사용되며, 그 안전성 특징 때문에 점점 더 인기를 얻고 있습니다. 일단 생성되면 불변 구조는 변하지 않고, 모든 참조는 동시에 접근할 수 있으며, 수정될 수 없다는 사실에 의해 무결성이 보장됩니다.

- 불변성은 함수형 프로그래밍에서의 핵심 개념임. 함수형 프로그래밍에서는 부수 효과를 만들지 않는 것이 가장 중요함. 부수 효과를 만들지 않는 함수를 순수 함수라고 함. 그렇다면 이 순수 함수를 왜 쓰냐. 함수형이 떠오르게 된 배경에는 현대의 동시성 환경이 만들어낸 문제가 있음. 이 동시성 문제라고 하는 것은 결국 여러 스레드가 공유되는 값을 읽거나 수정하기 때문에 발생함. 이때 부수 효과를 만들지 않는다는 것은 외부 상태를 변경하지 않으므로 동시성을 안전하게 처리할 수 있다는 것을 의미함.

높은 수준에서 볼 때, 데이터가 스토리지 구조 내부에서 처리되는 방식과 외부에서 처리되는 방식 사이에는 엄격한 구분이 있습니다. 내부적으로, 불변 파일은 여러 복사본을 가질 수 있으며, 더 최신 버전이 이전 버전을 덮어씁니다. 반면 가변 파일은 일반적으로 최신 값만 보유합니다. 접근 시, 불변 파일은 처리되고, 중복된 복사본들은 조정(reconcile)되며, 가장 최신 버전이 클라이언트에게 반환됩니다.

- 데이터가 스토리지 구조 외내부에서 처리되는 방식이 다름 → 즉 중간에 추상화 계층이 있다는 걸 말함.
- 가령 외부에서 사용자는 특정 키에 대하여 오직 단일한 값이 존재한다고 생각함.
- 하지만 내부적으로 불변 파일인 경우 이 값을 표현하기 위해서 여러 스냅샷을 통해 관리하고 가장 최신 스냅샷이 기존 스냅샷을 덮어쓰는 구조를 가지게 될 수도 있음.
- 또는 가변 파일이라면 항상 최신 값을 가지고 기존 값 위치에 있는 데이터를 덮어쓰는 방식을 채택할 수 있을 것임
- 불변 파일에 접근하는 경우 우리는 여러 개의 복사본을 통해서 가장 최종 값을 확정(앞에서 이를 reconcile이라고 했었다)하고 클라이언트에게 리턴하게 됨

이 주제에 대한 다른 책들과 논문들처럼, 우리는 가변 구조의 대표적인 예로 B-Tree를, 불변 구조의 예로 로그 구조화 병합 트리(LSM Tree)를 사용합니다. 불변 LSM Tree는 추가 전용(append-only) 스토리지와 병합 조정(merge reconciliation)을 사용하며, B-Tree는 디스크에서 데이터 레코드를 찾아 파일 내의 원래 오프셋에서 페이지를 업데이트합니다.

- 이러한 가변 구조 대표적인 사례로 B-Tree를(물론 불변성을 가지는 B-Tree도 있었다) 뽑았으며 이제 불변 구조의 대표적인 예시로 LSM Tree를 알아보게 될 것임
- 불변 LSM 트리의 경우…
  - append-only 스토리지에서 → 즉 모든 변경사항을 파일의 끝에 순차적으로 기록하는 방식
  - 병합 조정을 수행 → 버전이 많아지는 경우 합치는 ‘병합’ + 최종 값을 결정하는 ‘조정(reconcile)’을 수행
- B-Tree의 경우
  - 그냥 디스크에서 그 데이터 위치를 찾아서 수정하는 in-place update 방식을 취함. 이러한 특징 때문에 읽기에서는 효율적이었지만 쓰기 시 랜덤 IO를 고려해야 한다는 비효율성이 있었음

제자리 업데이트(In-place update) 스토리지 구조는 읽기 성능에 최적화되어 있습니다 [GRAEFE04]. 디스크에서 데이터를 찾은 후, 레코드는 클라이언트에게 반환될 수 있습니다. 이는 쓰기 성능을 희생해서 얻어지는 것입니다. 데이터 레코드를 제자리에서 업데이트하기 위해서는, 먼저 디스크에서 해당 레코드를 찾아야 합니다. 반면에, 추가 전용(append-only) 스토리지는 쓰기 성능에 최적화되어 있습니다. 쓰기는 디스크에서 레코드를 찾아 덮어쓸 필요가 없습니다. 그러나 이는 읽기 성능을 희생해서 이루어지며, 읽기는 여러 버전의 데이터 레코드를 검색하고 이를 조정(reconcile)해야 합니다.

- 바로 이전 문단에서 봤듯이 제자리 갱신은 읽기 워크로드에 최적화되어 있음. 대신 쓰기 워크로드에는 별로임. 왜? 쓰기를 위해서는 어디에 쓸 것인지를 찾고 나서야 쓸 수 있기 때문임. 즉 항상 찾은 다음 수정이기 때문.
- 한편 추가 전용 스토리지는 쓰기 워크로드에 최적화 되어있음. 왜? 파일의 끝 위치에 모든 쓰기를 수행하면 되기 때문. 이는 순차 IO이므로 매우 빠름. 하지만 읽기 워크로드에는 별로임. 왜? 하나의 데이터를 읽을려면 그 데이터에 대해 존재하는 여러 스냅샷을 찾은 다음 최종적으로 확정(reconcile)해야 하기 때문임. 이는 스냅샷은 여러 위치에 존재하므로 랜덤 IO이므로 느림.

지금까지 우리는 주로 가변 스토리지 구조에 대해 이야기했습니다. 우리는 CoW(copy-on-write) B-Tree("Copy-on-Write" 참조), FD-Tree("FD-Trees" 참조), 그리고 Bw-Tree("Bw-Trees" 참조)를 논의하면서 불변성이라는 주제를 다루었습니다. 하지만 불변 구조를 구현하는 방법은 더 많이 있습니다.

- 지금까지 B-Tree 가변 구조 → B-Tree에서의 불변성 순으로 배웠음. 즉 B-Tree가 가지는 단점을 극복하기 위하여 이를 변형하여 불변성 개념을 도입하는 방식(FD-Tree, Bw-Tree). 하지만 B-Tree 외에도 불변성을 구현할 수 있는 구조는 더 많음

가변 B-Tree가 채택한 구조와 구축 방식 때문에, 읽기, 쓰기, 그리고 유지보수 중 발생하는 대부분의 I/O 작업은 랜덤(random)입니다. 각 쓰기 작업은 먼저 데이터 레코드를 담고 있는 페이지를 찾아야만 그 후에 수정할 수 있습니다. B-Tree는 이미 쓰여진 레코드를 재배치하는 노드 분할과 병합을 필요로 합니다. 시간이 지나면 B-Tree 페이지는 유지보수가 필요할 수 있습니다. 페이지는 크기가 고정되어 있으며, 일부 여유 공간은 미래의 쓰기를 위해 예약됩니다. 또 다른 문제는 페이지 내의 단 하나의 셀만 수정되더라도 전체 페이지를 다시 써야 한다는 것입니다.

- B-Tree에서 겪었던 문제들을 정리해보자
- 가변 B-Tree의 특성 상 우리는 데이터를 읽거나 쓰기 위해서 디스크 상에 물리적으로 흩어져있는 페이지에 접근해야 했었음. 즉 랜덤 IO를 수행했었음.
- 읽기 뿐만이 아니라 쓰기를 할 때도 그 페이지를 먼저 찾아야 했기 때문에 읽기 → 쓰기 순으로 수행해야 했었음
- B-Tree는 (자료구조 특성 상) 밸런싱을 위해서 분할 및 병합을 수행해야 했음. 이 과정에서 추가적인 쓰기 작업이 발생함.
  - 안하면 비트리가 아님…
- 또한 시간이 지나면서 삽입과 삭제가 반복되면 빈 공간이 생기는 단편화가 발생하는데, 이러한 낭비되는 공간을 회수하기 위해서 유지보수(메인터넌스) 작업, 가령 vacumm 등을 수행해야 했음. 이는 역시 추가적인 읽기 쓰기 작업임
- 우리는 페이지 단위로 읽고 썼는데, 이는 고정된 크기를 가지고 있었음. 한편 B-Tree의 분할 작업은 매우 비싸기 때문에 이 페이지를 전부 꽉 채워 쓰는 것보다 여유 공간을 남겨두는 것이 효율적임. 대신 실제 데이터보다 더 많은 공간을 필요로 하는 공간 증폭 문제를 감수해야 했었음.
- 또 페이지 단위로 읽고 쓰면서 발생하는 문제는, 우리가 페이지 안의 단 하나의 셀만 수정하더라도 전체 페이지를 다시 써야 하는 쓰기 증폭 문제가 발생한다는 것이었음 (이걸 줄이기 위해서 버퍼링을 하기도 했음)

이러한 문제들을 완화하고, 일부 I/O 작업을 순차적(sequential)으로 만들며, 수정 중 페이지 재작성을 피하는 데 도움이 될 수 있는 대안적인 접근법들이 있습니다. 이를 수행하는 방법 중 하나는 불변 구조를 사용하는 것입니다. 이번 장에서는 LSM Tree에 초점을 맞출 것입니다. 어떻게 만들어지는지, 어떤 속성을 가지는지, 그리고 B-Tree와 어떻게 다른지에 대해 다룰 것입니다.

- 앞에서 언급한 B-Tree가 가지는 문제(랜덤 IO, 공간 증폭, 쓰기 증폭)들을 어느 정도 해결하고 / 랜덤 IO를 순차 IO로 만들고 / 데이터 수정 시 페이지를 덮어쓰지 않는 그런 방법이 있음
- 바로 불변 구조를 쓰면 된다
- 이 불변 구조를 쓰는 방식 중 LSM Tree에 대해 알아볼 것

## LSM Trees

B-Tree에 대해 이야기할 때, 우리는 버퍼링을 사용하여 공간 오버헤드와 쓰기 증폭을 개선할 수 있다고 결론 내렸습니다. 일반적으로, 여러 스토리지 구조에 버퍼링을 적용하는 두 가지 방법이 있습니다: 디스크 상주 페이지로의 쓰기 전파를 지연시키는 것(“FD-Tree”와 “WiredTiger”에서 보았듯이)과 쓰기 작업을 순차적으로 만드는 것입니다.

- 이전 장에서 B-Tree의 공간 증폭 및 쓰기 증폭과 관련하여 버퍼링이 그 해결책이 될 수 있다는 점을 배웠었음
- 버퍼링을 구현하는 방법은 두 가지임
  - FD-Tree → ‘디스크 상주 페이지(disk-resident page)’로의 쓰기 전파 지연
    - 즉 WiredTiger처럼 B-Tree 노드에 대하여 각각 쓰기 버퍼를 관리하여 변경사항을 쌓아놨다가, 쓰기 버퍼가 꽉 차면 플러시하여 디스크에 반영함.
  - 순차 쓰기 작업 → 우리가 이제부터 배울 방법. LSM 트리가 이 쓰기 작업을 순차적으로 수행함

가장 널리 사용되는 불변의 디스크 기반 스토리지 구조 중 하나인 LSM Tree는 버퍼링과 추가 전용(append-only) 스토리지를 사용하여 순차 쓰기를 달성합니다. LSM Tree는 B-Tree와 유사한 디스크 상주 구조의 변형으로, 노드가 완전히 채워져 있으며 순차 디스크 접근에 최적화되어 있습니다. 이 개념은 Patrick O’Neil과 Edward Cheng의 논문[ONEIL96]에서 처음 소개되었습니다. 로그 구조화 병합 트리(Log-structured merge tree)라는 이름은 모든 수정을 로그와 같은 파일에 디스크에 쓰는 로그 구조화 파일 시스템에서 유래했습니다[ROSENBLUM92].

- LSM Tree는 어떻게 쓰기 작업을 순차적으로 수행할까? 두 가지가 필요함.
  - 버퍼링
  - 추가 전용 스토리지
- LSM 트리와 B 트리 차이
  - 노드가 항상 꽉 차있음 → 이것도 CoW 할 때 언급했었음. 불변성이 보장되면 중간 삽입으로 인한 오버플로를 걱정할 필요가 없으므로 꽉 채워서 저장해도 됨
  - 최적화 방향성 → B-Tree는 자료구조 특성 상 랜덤 IO에 최적화 되어있지만, LSM 트리는 (당연히 파일 끝에서 순차적으로 쓰기 때문에 ) 순차 IO에 최적화 되어있음
- 이러한 LSM 트리는 Patrick O’Neil 논문에서 처음 소개된 개념임.
  - 로그 구조화 병합 트리(log-structured merge tree, LSM Tree)라는 이름은 이 논문의 ‘로그 구조화 파일 시스템’이라는 데에서 유래했는데, 얘도 마찬가지로 변경사항을 로그처럼 순차적으로 기록하는 아이디어임.
  - ‘병합’ 이 들어간 이유 → 아래에서 설명

노트) LSM Tree는 불변 파일을 쓰고 시간이 지남에 따라 함께 병합합니다. 이 파일들은 보통 리더(reader)가 데이터를 효율적으로 찾는 데 도움이 되는 자체 인덱스를 포함합니다. LSM Tree는 종종 B-Tree의 대안으로 제시되지만, B-Tree가 LSM Tree의 불변 파일에 대한 내부 인덱싱 구조로 사용되는 것이 일반적입니다.

- 병합에 대해서 더 자세히 보자.
- reconcile 했던 것처럼 변경사항을 매번 따라가려면 읽기 성능이 좋지 않기 때문에 정기적으로 이 파일을 병합하여 히스토리 길이를 줄여야 함. 이게 병합임
- “이 파일들은 보통 리더(reader)가 데이터를 효율적으로 찾는 데 도움이 되는 자체 인덱스를 포함합니다.” → 하지만 이렇게 하더라도 기존 비트리에 비해 읽기가 느림. 앞에서 말했듯 제자리 갱신 방식은 특정 데이터에 대하여 하나의 페이지만 읽으면 되지만, 불변 구조에서는 여러 개의 버전을 확인한 다음 이를 합쳐야 함. 혹은 가장 최신 버전이 어디에 있는지 관리해야 함. 이 최신 버전이 어디에 있는지를 링크드 리스트를 타고 끝까지 갈 필요 없이, 최신 버전에 위치를 인덱스로 관리할 수도 있음.
- 그러면 B-Tree처럼 우리가 원하는 가장 최신 데이터 위치로 바로 이동 가능. 이 인덱스는 B-Tree 구조임

LSM 트리에서 '병합'이라는 단어는 불변성 때문에, 트리 내용이 병합 정렬과 유사한 접근 방식을 사용하여 병합된다는 것을 나타냅니다. 이 과정은 중복된 사본이 차지하는 공간을 회수하기 위한 유지보수 작업 중에 발생하며, 읽기 작업 시 사용자에게 내용을 반환하기 전에 발생합니다.

- 병합을 다시 정리하자면 하나의 키에 대하여 여러 개의 값이 존재하고, 이 중 최신 값을 얻으려면 이 여러 개의 값을 합쳐야 하는데, 이 과정이 병합 정렬처럼 이루어짐. 그래서 병합 트리라고 함
- 병합은 두 가지 경우에 발생
  - 메인터넌스 과정 → 시간이 지나면서 파일이 계속해서 쌓이는데, 이를 주기적으로 정리하는 컴팩션 과정에서 발생
  - 읽기 시 병합 → 특정 키에 대하여 가장 최신 값을 확정하기 위해서는 병합이 필요함

LSM 트리는 데이터 파일 쓰기를 지연시키고, 변경 사항을 메모리 상주 테이블에 버퍼링합니다. 이러한 변경 사항은 그 내용을 불변의 디스크 파일에 기록함으로써 전파됩니다. 파일이 완전히 영속화될 때까지 모든 데이터 레코드는 메모리에서 접근 가능한 상태로 유지됩니다.

- 이제 LSM 트리의 버퍼링에 대해 알아보자.
- 일단 변경사항을 메모리 상주 테이블(memory-resident table)에 버퍼링함. (memtable 이라 함)
- 일정 크기에 도달하면 디스크에 플러시한다. 아주 간단
- 그리고 이 디스크 파일은 불변이다. 이 불변 디스크 파일을 (SSTable, Sorted String Table이라고 함. 아주 뒤에서 나오지만 그냥 이런 구현체를 쓴다고 외우자)
- memtable을 플러시하는 도중에도 해당 데이터에 대한 읽기 요청이 메모리를 거칠 수 있음. 즉 플러시 작업을 한다고 해서 메모리 상에 있는 해당 데이터를 읽는 작업이 블로킹되지 않음

데이터 파일을 불변으로 유지하는 것은 순차 쓰기에 유리합니다. 데이터는 단일 패스로 디스크에 쓰여지고 파일은 추가 전용입니다. 가변 구조는 단일 패스로 블록을 미리 할당할 수 있지만(예를 들어, 인덱스 순차 접근 방법(ISAM) [RAMAKRISHNAN03] [LARSON81]), 후속 접근은 여전히 무작위 읽기와 쓰기를 요구합니다. 불변 구조는 단편화를 방지하기 위해 데이터 레코드를 순차적으로 배치할 수 있게 해줍니다.

- 이러한 불변성은 순차 쓰기가 가능하므로 성능 상 유리함 (왜 랜덤 쓰기보다 순차 쓰기가 유리한지는 계속 다뤘었음)
- 데이터는 싱글 패스(쭉 이어 붙여져서)로 쓰여지며 파일은 추가 전용(append-only), 즉 끝에 이어붙여지는 방식임.
- 물론 가변 구조더라도 싱글 패스, 즉 정렬된 데이터를 순서대로 채워나갈 수 있음. 그래서 초기에는 순차 쓰기가 가능하므로 빠름. 이 데이터에 대하여 인덱스를 만들 때도 정렬된 데이터가 순차적으로 들어오므로 (단조 증가 삽입에 대하여 기존에 논의했었음) 이것 역시 유리
- 하지만 이제 데이터 변경이 발생한다고 하자 (CUD 작업). 가령 처음에는 99, 100, 102 순으로 딱 붙여서 넣었는데 이제 101을 넣어야 한다는 가정. 그러면 물리적으로 공간이 없기 때문에, 새 데이터를 별도 공간에 저장하고 포인터로 이어붙여야 함. 그러면 순차적으로 읽을 때도 인접한 공간이 아니라 디스크 상에서 멀리 떨어진 공간을 읽어야 하므로 연속된 데이터가 물리적으로 인접해있지 않은 문제 발생.
- 즉 병합과 분할을 통해 동적으로 변하는 B-Tree와 다르게 ISAM은 정적이고 오버플로를 별도 페이지를 통해 관리하며, 이로 인해 읽기가 느리다는 단점
- 한편 불변 구조는 빈 공간이 생길 여지가 없으므로 단편화가 없음

추가적으로, 불변 파일은 더 높은 밀도를 가집니다. 우리는 나중에 쓰여질 데이터 레코드를 위해, 또는 업데이트된 레코드가 원래 쓰여진 레코드보다 더 많은 공간을 요구하는 경우를 위해 추가 공간을 예약하지 않습니다.

- 저장 밀도(density)가 높다는 장점도 있는데 이는 CoW에서 얘기했었음. 일반 비트리와 다르게 여유 공간을 두지 않으므로 저장 효율성이 더 높음.

파일이 불변이기 때문에, 삽입, 수정, 삭제 작업은 디스크에서 데이터 레코드를 찾을 필요가 없으며, 이는 쓰기 성능과 처리량을 크게 향상시킵니다. 대신, 중복된 내용이 허용되고, 충돌은 읽기 시점에 해결됩니다. LSM 트리는 읽기보다 쓰기가 훨씬 더 흔한 애플리케이션에 특히 유용한데, 이는 계속 증가하는 데이터 양과 수집 속도를 고려할 때 현대의 데이터 집약적인 시스템에서 흔히 볼 수 있는 경우입니다. 읽기와 쓰기는 설계상 서로 교차하지 않으므로, 세그먼트 잠금 없이 디스크의 데이터를 읽고 쓸 수 있으며, 이는 동시성을 크게 향상시킵니다.

- 가변에서는 디스크에서 찾은 다음 → 수정을 거쳤음. 하지만 불변은 어차피 찾아봤자 바꿀 수가 없기 떄문에 디스크에 찾을 필요가 없음. 그냥 메모리에 수정할 내용을 쌓아두면 됨. 그래서 쓰기 작업이 정말 빠르고 쓰로풋도 좋음.
- 대신 중복된 내용, 즉 같은 키에 대하여 여러 버전이 존재할 수 있음. 뭐가 가장 최종 값인지 판단하는 (즉 충돌을 해결하는) 오버헤드가 읽기 시점에 발생함. 즉 쓰기 성능을 위해 읽기 성능을 희생함
- 그래서 LSM 트리는 읽기보다 쓰기 중심 워크로드에서 좋음. 현대에는 로그 수집, 모니터링, 이벤트 리플레이 등 쓰기 중심인 경우가 많기 때문에 이런 요구사항을 잘 충족함
- 또한 읽기와 쓰기는 서로 다른 영역에서 발생함. 쓰기는 메모리 상주 구조, 즉 memtable에서 발생하지만 읽기 작업은 기존 디스크의 불변 파일, 즉 sstable을 대상으로 함. 그래서 읽기와 쓰기가 서로를 블로킹하지 않음. 따라서 락이 거의 혹은 아예 필요 없기 떄문에 동시성이 높아짐.

B-Tree와 LSM Tree 모두 성능 최적화를 위해 약간의 하우스키핑이 필요하지만, 그 이유는 서로 다릅니다. 할당된 파일의 수가 꾸준히 증가하기 때문에, LSM Tree는 요청된 데이터 레코드가 여러 파일에 흩어져 있을 수 있으므로 읽기 중에 최소한의 파일만 접근하도록 파일을 병합하고 다시 작성해야 합니다. 반면에, 변경 가능한 파일은 단편화를 줄이고 업데이트되거나 삭제된 레코드가 차지하는 공간을 회수하기 위해 부분적으로 또는 전체적으로 다시 작성해야 할 수 있습니다. 물론, 하우스키핑 프로세스에 의해 수행되는 작업의 정확한 범위는 구체적인 구현에 따라 크게 달라집니다.

- 비트리와 LSM 트리 모두 하우스키핑(즉 메인터넌스 작업)이 필요함. 하지만 하는 이유나 방식은 다름
- 이것도 앞에서 말헀는데… 특정 데이터를 읽으려면 해당 데이터의 최종 버전이 어디에 있는지 모르기 떄문에 모든 버전을 다 뒤져봐야 함. 이러면 읽기 성능이 낮아짐. 따라서 뒤지는 파일 개수를 줄이기 위해서 파일을 병합하여 새로운 파일로 만들어서 저장하는 작업이 필요하다고 했었음.
- 한편 비트리 같은 가변 구조에서는 페이지 단위 접근으로 인한 단편화(즉 삭제 후 다른 크기 데이터로 수정)로 빈 공간이 흩어져 낭비되는 문제가 있었음. 그래서 deframentation 혹은 compaction 작업을 통해 데이터를 모아서 빈 공간 없이 채우고 기존 페이지를 날려버리는 작업을 함.

### LSM Tree Structure

정렬된 LSM 트리 [ONEIL96]부터 시작해봅시다. 여기서는 파일이 정렬된 데이터 레코드를 보관합니다. 나중에 "비정렬 LSM 스토리지(Unordered LSM Storage)"에서, 삽입 순서대로 데이터 레코드를 저장하는 구조에 대해서도 논의할 것이며, 이는 쓰기 경로(write path)에서 몇 가지 명백한 이점을 가집니다.

- LSM 트리의 데이터 저장 방식은 크게 두 가지임
- 데이터가 키 순서대로 정렬되어 저장되는 방식
- 데이터가 삽입 순서대로 정렬 없이 저장되는 방식
  - 이 방식의 장점은 쓰기 경로에서의 성능임 → 당연히 정렬 과정이 없어지므로 들어오는 족족 파일 끝에 추가하기만 하면 됨.

방금 논의했듯이, LSM 트리는 더 작은 메모리 상주(memory-resident) 컴포넌트와 더 큰 디스크 상주(disk-resident) 컴포넌트로 구성됩니다. 불변(immutable) 파일 내용을 디스크에 쓰기 위해서는 먼저 메모리에서 버퍼링하고 그 내용을 정렬해야 합니다.

- LSM 트리의 구성 요소
  - 메모리 상주 컴포넌트 (memtable)
  - 디스크 상주 컴포넌트 (SSTable)
- SSTable은 정렬된 데이터를 모은 불변 파일임
- 이러한 정렬된 불변 파일을 만들기 위해서는 랜덤한 순서로 들어오는 쓰기 요청을 일단 메모리에 모은 다음 (버퍼링) 정렬하여 한 번에 디스크에 순차 쓰기하는 과정이 필요함 → 이것이 메모리 상주 컴포넌트가 필요한 이유

메모리 상주 컴포넌트(종종 memtable이라고 불림)는 가변적(mutable)입니다: 이것은 데이터 레코드를 버퍼링하고 읽기 및 쓰기 작업의 대상 역할을 합니다. Memtable의 내용은 크기가 설정 가능한 임계값까지 커지면 디스크에 영속화됩니다. Memtable 업데이트는 디스크 접근을 유발하지 않으며 관련된 I/O 비용이 없습니다. "복구(Recovery)" 장에서 논의했던 것과 유사한 별도의 쓰기 전용 로그(write-ahead log) 파일이 데이터 레코드의 영속성(durability)을 보장하기 위해 필요합니다. 데이터 레코드는 로그에 추가되고 메모리에 커밋된 후에 클라이언트에게 작업이 확인(acknowledged)됩니다.

- 메모리 상주 컴포넌트(memtable)의 주요 특징 및 동작
- 가변적 → 불변 파일인 SSTable과 다르게 새로운 데이터를 CUD 할 수 있음 (정렬이 필요하다고 했으니… 당연히…)
- 버퍼 역할 → 정렬하기 위해서는 일단 쓰기 요청들을 임시로 모아둬야 함
- 읽기/쓰기 대상 → 앞에서 페이지 캐시가 읽기 캐시 역할 뿐만이 아니라 쓰기를 버퍼링했던 것처럼… memtable 역시 읽기 요청에 대한 캐시 역할을 수행함. 즉 읽기 요청은 항상 memtable을 거쳐야 함.
- 플러시 → SSTable에 비해 memtable은 상대적으로 작음. 따라서 꽉 차면 해당 내용을 SSTable로 (즉 디스크로) 기록하여 영속화해야 함.
- 빠른 쓰기 → 먼저 클라이언트의 쓰기 요청은 memtable에 반영됨. 마치 B-Tree에서 쓰기 작업 시 바로 수정하지 않고 페이지 캐시를 변경하는 것과 비슷.
- WAL → 단 B-Tree 역시 그랬던 것처럼 휘발성 메모리라는 특성 때문에 이러한 변경사항이 유실될 수 있음. 그래서 WAL을 두어서 (WAL은 디스크에 있음) RAM의 memtable에 변경사항을 반영하기 전에 WAL에 먼저 기록하여 지속성을 보장함. WAL에 쓰기 요청을 추가하고 memtable에 변경사항을 반영한 이후에야 클리아언트에게 ack, 즉 쓰기 작업이 성공했음을 응답할 수 있음.

버퍼링은 메모리에서 수행됩니다. 모든 읽기 및 쓰기 작업은 동시성 접근을 허용하는 정렬된 데이터 구조를 유지하는 메모리 상주 테이블에 적용되는데, 이는 보통 어떤 형태의 메모리 상주 정렬 트리 또는 유사한 성능 특성을 제공할 수 있는 모든 데이터 구조입니다.

- 모든 읽기 작업 및 쓰기 작업은 항상 memtable을 거침.
- memtable은 항상 데이터를 정렬된 상태로 유지함 → 동시성 읽기 / 쓰기를 효율적으로 처리하기 위함
- sorted tree를 쓰지만 그 외에도 앞에서 다룬 skiplist나 red-black tree 같은 정렬을 유지할 수 있는 자료구조를 사용

디스크 상주 구성 요소는 메모리에 버퍼링된 내용을 디스크로 플러시하여 구축됩니다. 디스크 상주 구성 요소는 읽기에만 사용됩니다. 즉, 버퍼링된 내용이 영속화되고 파일은 절대 수정되지 않습니다. 이는 우리가 메모리 상주 테이블에 대한 쓰기, 디스크 및 메모리 기반 테이블에 대한 읽기, 병합, 그리고 파일 제거라는 간단한 연산의 관점에서 생각할 수 있게 해줍니다.

- memtable이 일정 크기에 도달하면 플러시되어 디스크 파일로 기록됨
- 이렇게 기록된 디스크 파일을 디스크 상주 구성요소라고 하며 앞에서 SSTable(Sorted String Table)이라고 불렀었음
- SSTable은 불변이기에 오직 읽기에만 활용됨. (당연한 말임. 변경이 불가능하니까)
- 이로 인해 LSM 트리의 연산은 아래와 같이 세 가지로 단순화될 수 있음
  - 쓰기 : memtable에 변경사항 반영
  - 읽기 : memtable 및 SSTable 읽기 → 병합 (최종 값 결정)
  - 파일 제거 : 읽기 성능을 위해 여러 SSTable 병합하는 메인터넌스 작업

이 챕터 전반에 걸쳐, 우리는 디스크 상주 테이블(disk-resident table)의 축약어로 '테이블'이라는 단어를 사용할 것입니다. 우리는 스토리지 엔진의 의미론(semantics)을 논하고 있으므로, 이 용어는 데이터베이스 관리 시스템의 더 넓은 맥락에서 테이블 개념과 모호하지 않습니다.

- 디스크 상주 테이블 → 그냥 테이블이라고 부를 것 (우리는 SSTable이라고 부를 듯, 근데 이건 정렬된 것 한정이니…)
- 아니 DBMS SQL에서 쓰는 그 테이블이랑 헷갈리지 않나요? 싶을 수 있겠지만 우리는 지금 하위 레벨 중에서도 스토리지 엔진에만 한정해서 이야기하고 있음. 스토리지 엔진에서의 테이블은 추상적인 테이블 개념보다는 조금 더 물리적인 구조에 가까운 의미를 가짐.
- 그래서 후자 관점에서는 테이블이라는 워딩을 물리적인 저장 단위인 디스크 상주 테이블로 축약해서 써도 이해하는 데 문제 없을 거라고 생각했다 함. 아무튼 헷갈리지 마시라

### Two-component LSM Tree

우리는 2-컴포넌트와 다중-컴포넌트 LSM 트리를 구별합니다. 2-컴포넌트 LSM 트리는 불변 세그먼트로 구성된 단 하나의 디스크 컴포넌트만을 가집니다. 여기서 디스크 컴포넌트는 100% 노드 점유율과 읽기 전용 페이지를 가진 B-트리로 구성됩니다.

- LSM 트리의 경우 두 가지로 분류 가능
  - 2 컴포넌트→ 메모리 컴포넌트 1개, 디스크 컴포넌트 1개
  - 다중 컴포넌트 → 메모리 컴포넌트 1개, 디스크 컴포넌트 여러 개
- 디스크 컴포넌트
  - 비트리 구조임
  - 노드 점유율 100 → 불변이므로…
  - 읽기 전용 페이지 → 불변이므로….

메모리-상주 트리의 내용은 부분적으로 디스크에 플러시됩니다. 플러시 동안, 플러시되는 각 메모리-상주 서브트리에 대해, 디스크에서 해당 서브트리를 찾아 메모리-상주 세그먼트와 디스크-상주 서브트리의 병합된 내용을 디스크의 새 세그먼트에 기록합니다. 그림 7-1은 병합 전의 메모리-상주 및 디스크-상주 트리를 보여줍니다.

![image.png](%E1%84%80%E1%85%A9%E1%84%80%E1%85%B3%E1%86%B8%20%E1%84%87%E1%85%A2%E1%86%A8%E1%84%8B%E1%85%A6%E1%86%AB%E1%84%83%E1%85%B3%20%E1%84%89%E1%85%B3%E1%84%90%E1%85%A5%E1%84%83%E1%85%B5%2013%E1%84%8C%E1%85%AE%E1%84%8E%E1%85%A1%20244998e1b70980a7ba15f441b6290d10/image.png)

- memtable의 모든 내용을 한 번에 디스크로 플러시하는 것 아님.
- 특정 조건에 따라 (크기나 시간…) memetable의 서브트리만을 플러시함
- 플러시는 아래 단계로 이루어짐
  - 메모리 상주 트리에서 플러시 대상 서브트리 선택
  - 디스크 상주 트리에서 대상 서브트리에 대응되는 서브트리를 탐색
  - 메모리 상주 트리에서 온 서브트리와 디스크 상주 트리에서 온 서브트리를 병합 (회색 부분)
    - 이때 메모리 상주 트리는 정렬되어 있고, 플러시되어 저장된 디스크 상주 트리 역시 정렬되어 있으므로 순서대로 합치면 됨
  - 병합된 내용을 디스크의 새로운 위치에 기록 (불변이므로)

서브트리가 플러시된 후, 대체된 메모리-상주 및 디스크-상주 서브트리는 폐기되고 병합 결과로 교체되며, 이 결과는 디스크-상주 트리의 기존 섹션에서 주소 지정이 가능하게 됩니다. 그림 7-2는 병합 프로세스의 결과를 보여주며, 이는 이미 디스크의 새 위치에 기록되어 트리의 나머지 부분에 연결된 상태입니다.

![image.png](%E1%84%80%E1%85%A9%E1%84%80%E1%85%B3%E1%86%B8%20%E1%84%87%E1%85%A2%E1%86%A8%E1%84%8B%E1%85%A6%E1%86%AB%E1%84%83%E1%85%B3%20%E1%84%89%E1%85%B3%E1%84%90%E1%85%A5%E1%84%83%E1%85%B5%2013%E1%84%8C%E1%85%AE%E1%84%8E%E1%85%A1%20244998e1b70980a7ba15f441b6290d10/image%201.png)

- 플러시 이후 상태를 보자
  - 플러시 과정에서 사용된 두 서브트리는 이제 outdated된 상태이므로 폐기됨
  - 그리고 이 빈 공간은 merge된 신규 서브트리가 차지하게 됨
- “이 결과는 디스크-상주 트리의 기존 섹션에서 addressable 됩니다” → 즉 병합된 서브트리는 기존 서브트리와 교체되어 접근 가능한 상태가 됨. 어떻게? 이것도 CoW 할 때 배웠음. 서브트리의 최상위 포인터를 원자적으로 교체함으로써 접근 가능해짐

병합은 디스크 기반 리프 노드와 메모리 내 트리의 내용을 읽는 이터레이터(iterator)를 록스텝(lockstep)으로 진행시켜 구현할 수 있습니다. 두 소스가 모두 정렬되어 있으므로, 정렬된 병합 결과를 생성하기 위해서는 병합 과정의 각 단계에서 두 이터레이터의 현재 값만 알면 됩니다.

- 이터레이터?? 락스텝??

```markdown
### 1. 초기 상태

메모리: [ B, D, E ]
↑
디스크: [ A, B, C ]
↑
결과 : [ ]

### 2. 'A' 처리

메모리: [ B, D, E ]
↑
디스크: [ A, B, C ]
↑
결과 : [ A ]

### 3. 'B' 처리

메모리: [ B, D, E ]
↑
디스크: [ A, B, C ]
↑
결과 : [ A, B ]

### 4. 'C' 처리

메모리: [ B, D, E ]
↑
디스크: [ A, B, C ] (끝)
↑
결과 : [ A, B, C ]

### 5. 남은 데이터 처리

결과 : [ A, B, C, D, E]
```

- 1
  - 각 이터레이터는 B, A를 가리킴
- 2
  - 두 이터레이터의 키(`A`와 `B`)를 비교합니다. `A`가 더 작습니다.
  - `A`를 결과에 추가하고, `디스크 이터레이터`만 한 칸 앞으로 이동시킵니다.
  - **결과:** `{ A: v1 }`
- 3
  - 두 이터레이터가 가리키는 키가 모두 `B`로 동일합니다.
  - 이 경우, **최신 데이터인 메모리 컴포넌트의 값이 우선**합니다. `{ B: v2_new }`를 결과에 추가합니다.
  - 오래된 값인 디스크의 `{ B: v1_old }`는 버립니다.
  - 키가 동일했으므로, **두 이터레이터를 모두** 한 칸씩 앞으로 이동시킵니다.
  - **결과:** `{ A: v1 }, { B: v2_new }`
- 4
  - 현재 키는 `D`(메모리)와 `C`(디스크)입니다. `C`가 더 작습니다.
  - `C`를 결과에 추가하고, `디스크 이터레이터`를 이동시킵니다. 이제 디스크 이터레이터는 끝에 도달했습니다.
  - **결과:** `{ A: v1 }, { B: v2_new }, { C: v1 }`
- 5
  - `디스크 이터레이터`가 끝났으므로, `메모리 이터레이터`에 남은 모든 데이터를 순서대로 결과에 추가합니다.
  - `D`와 `E`가 결과에 추가됩니다.
  - **최종 결과:** `{ A: v1 }, { B: v2_new }, { C: v1 }, { D: v1_new }, { E: v1 }`
- 이제 다시 원문을 보자. “병합은 디스크 기반 리프 노드와 메모리 내 트리의 내용을 읽는 이터레이터(iterator)를 록스텝(lockstep)으로 진행시켜 구현할 수 있습니다. 두 소스가 모두 정렬되어 있으므로, 정렬된 병합 결과를 생성하기 위해서는 병합 과정의 각 단계에서 두 이터레이터의 현재 값만 알면 됩니다.”
  - 락스텝 → 직역하면 잠근 걸음. 즉 발맞춰 걷는 걸 락스텝이라고 함. 정확하게는 아주 좁게 서서 다리를 움직이되, 앞사람이 다리를 앞으로 뻗어서 빈 그 자리에 뒷사람의 다리가 뻗어지도록 움직이는 방식.
    ![image.png](%E1%84%80%E1%85%A9%E1%84%80%E1%85%B3%E1%86%B8%20%E1%84%87%E1%85%A2%E1%86%A8%E1%84%8B%E1%85%A6%E1%86%AB%E1%84%83%E1%85%B3%20%E1%84%89%E1%85%B3%E1%84%90%E1%85%A5%E1%84%83%E1%85%B5%2013%E1%84%8C%E1%85%AE%E1%84%8E%E1%85%A1%20244998e1b70980a7ba15f441b6290d10/image%202.png)
    - 리듬세상에 이 ‘그림자스텝’이라는 게임. 영문판에서는 ‘락스텝’이라고 부른다. 왜 락스텝이는 비유를 썼는지 조금 이해가 가시는지?
  - 이터레이터 → 앞으로만 갈 수 있는 현재 위치를 나타내는 순회 포인터.
  - memtable과 sstable은 정렬되어있으므로 이렇게 비교가 가능함
  - 또한 이러한 과정을 앞에서 병합 정렬과 비슷하다 라는 표현을 했는데, 정렬된 두 리스트를 합치는 과정을 보면 비슷한 것 같기도 하고… 아무튼 그럼

이 접근 방식은 불변(immutable) B-Tree에 대한 우리의 논의의 논리적 확장이며 연속입니다. Copy-on-write B-Tree("Copy-on-Write" 참조)는 B-Tree 구조를 사용하지만, 노드가 완전히 채워지지 않으며, 루트-리프 경로의 페이지를 복사하고 병렬 트리 구조를 생성해야 합니다. 여기서 우리는 비슷한 작업을 수행하지만, 쓰기를 메모리에 버퍼링하므로 디스크 기반 트리 업데이트 비용을 상각(amortize)합니다.

- 역시 책에서도 CoW에서 했던 방식과 비슷하다고 말함. 어떤 점에서 비슷하냐? 비트리 구조에서 불변성을 유지하고, 트리 최상단 포인터를 스왑한다는 점에서 비슷.
- 하지만 노드가 항상 꽉 차있음이 보장되지 않음.
  - 아니 CoW에서는 공간 오버헤드가 없다면서요? 그건 일반적인 비트리 계열이 추가 삽입으로 인한 분할을 막기 위해 일부 여유 공간을 남기는 걸 CoW에서는 하지 않아도 된다는 의미. 얘도 결국 B-Tree 계열이기에 분할 병합 발생 가능. 그러면 노드 점유율이 항상 100인게 보장 안됨.
  - 이게 LSM Tree와 CoW 비트리와 다른 점
- 뿐만 아니라 스왑하는 포인터도 다름. CoW는 항상 루트 포인터. 하지만 LSM Tree는 서브트리의 루트 포인터도 가능. 항상 루트 포인터여야 한다는 점 때문에 변경하려는 페이지까지의 경로에 있는 모든 페이지를 복사해주고 포인터를 갱신해줘야 했음. 이 과정에서 트리를 항상 2개 버전으로 관리해야 했음 (병렬 트리 구조)
- 하지만 LSM 트리 역시 비슷한 작업이 필요하지만, 이 작업들은 전부 인메모리에서 발생함. 즉 memtable에 버퍼링함 → 이게 핵심임. 이 덕분에 루트부터 수정 리프 페이지까지의 페이지를 모두 수정해줘야 하는 비용조차 없어져버림 (나름 이게 줄인 거인데도 불구하고…)

서브트리 병합 및 플러시를 구현할 때 세 가지를 확인해야 합니다.

1. 플러시 프로세스가 시작되자마자 모든 새로운 쓰기는 새로운 memtable로 가야 합니다.
2. 서브트리 플러시 중에는 디스크 기반 서브트리와 플러시 중인 메모리 기반 서브트리 모두 읽기 접근이 가능해야 합니다.
3. 플러시 후에는 병합된 내용을 게시하고, 병합되지 않은 디스크 및 메모리 기반 내용을 폐기하는 작업이 원자적으로 수행되어야 합니다.

2-컴포넌트 LSM 트리가 인덱스 파일을 유지하는 데 유용할 수 있지만, 저자가 글을 쓰는 시점에는 알려진 구현체가 없습니다. 이 접근 방식의 쓰기 증폭 특성으로 설명될 수 있는데, 병합은 memtable 플러시에 의해 트리거되므로 비교적 빈번하게 발생하기 때문입니다.

- 병합 및 플러시에서 체크해야 할 점 세 가지
  - 플러시가 시작되자마자 새로운 쓰기는 새로운 memtable로 가야 함 → 즉 특정 시점을 기준으로 플러시하기로 결정했다면 그 이후 변경사항은 새로운 memtable에 쌓여야 함…. ‘쌓이는 게 가능해야’ 함
    - 일관성 보장 목적
  - 서브트리 플러시 중에도 memtable 및 sstable 모두 읽을 수 있어야 함 → ‘플러시 중’ 조건 건 이유가 있음. 플러시 중에도 특정 키에 대한 최신 데이터는 sstable 혹은 memtable 비교하는 작업 통해 결정되어야 함. CoW에서는 여전히 기존 트리를 읽게 함으로써 해결했었음. LSM은? 플러시 도중에도 여전히 기존 sstable은 그대로임. 병합 내용은 신규 파일에 쓰여지고 있기 때문임. 병합된 서브트리를 기존 서브트리와 원자적으로 교체하는 것으로 해결
    - 동시성 보장
  - 플러시 후 병합된 내용 게시와 기존 내용 폐기가 원자적으로 이루어저야 함
    - 즉 새로운 내용에 접근 가능해지고 기존 내용은 접근 불가능해지는 과정이 원자적 → 원자적 포인터 스왑.
    - 이 폐기는 CoW처럼 물리적 폐기가 아니라 ‘접근 불가’로 해석하는 게 맞음. 물리적 폐기의 경우 CoW와 마찬가지로 기존 읽는 트랜잭션이 끝날 때까지 기다린 후 폐기…
- 2컴포넌트 방식 한계
  - 2-컴포넌트 모델에서는 memtable이 꽉 차서 플러시될 때마다 디스크에 있는 기존 데이터와 병합해야 함. 이는 디스크의 데이터를 읽어서 새로운 데이터와 합친 후, 다시 디스크에 쓰는 과정을 수반함.
  - memtable 플러시는 자주 발생하는 작업이므로, 이 과정이 반복되면 실제 변경된 데이터 양에 비해 엄청난 양의 디스크 쓰기(쓰기 증폭)가 발생하여 비효율적임.
  - 이것이 바로 이 모델이 널리 쓰이지 않는 핵심적인 이유임. (현대의 LSM 트리들은 보통 다수의 디스크 컴포넌트(SSTable)와 계층적 압축(leveled compaction) 같은 더 정교한 방식을 사용해 쓰기 증폭을 완화함)

### Multicomponent LSM Trees

하나 이상의 디스크 상주 테이블을 갖는 다중 컴포넌트 LSM 트리라는 대안적인 설계를 고려해 봅시다. 이 경우, 전체 멤테이블(memtable) 내용은 단일 실행으로 플러시(flush)됩니다.

- 기존 2컴포넌트 모델은 메모리 컴포넌트 하나 디스크 컴포넌트 하나였음.
- 여기서는 memtable의 서브트리를 플러시하여 sstable의 서브트리와 병합하는 방식을 취했음
- 하지만 다중 디스크 컴포넌트 모델에서는, 굳이 이렇게 할 필요 없음. 그냥 memtable이 가득 차면 플러시하면 됨.

여러 번의 플러시 이후에는 여러 개의 디스크 상주 테이블이 생기고 시간이 지남에 따라 그 수가 증가할 것이라는 점은 금방 명백해집니다. 어떤 테이블이 필요한 데이터 레코드를 가지고 있는지 항상 정확히 알 수 없기 때문에, 검색된 데이터를 찾기 위해 여러 파일에 접근해야 할 수도 있습니다. 단 하나의 소스가 아닌 여러 소스에서 읽어야 하는 것은 비용이 많이 들 수 있습니다. 이 문제를 완화하고 테이블 수를 최소한으로 유지하기 위해, 압축(compaction)이라고 불리는 주기적인 병합 프로세스가 트리거됩니다(“LSM 트리에서의 유지보수” 참조). 압축은 여러 테이블을 선택하여 그 내용을 읽고, 병합한 다음, 병합된 결과를 새로운 결합된 파일에 씁니다. 오래된 테이블들은 새로운 병합된 테이블이 나타남과 동시에 폐기됩니다.

- 쓰기 요청이 계속 들어온다면 멤테이블이 계속해서 플러시될 거고, 그러면 sstable은 계속해서 새롭게 만들어질 거임. 하지만 이러면 읽기 성능이 저하됨.
- 왜 저하되냐? 어떤 sstable이 우리가 원하는 최신 데이터를 가지고 있는지 모르기 때문임. 현재 memtable과 여러 sstable 중 한 곳에 위치할 것. 그런데 sstable이 많아지면 찾아야 할 곳도 많아지기 때문에 성능이 저하됨
- 이걸 앞에서 읽기 증폭이라고 했었음
- 읽기 증폭을 해결하기 위해서는 컴팩션을 수행해야 함. 컴팩션은 메인터넌스 작업이고, 다른 메인터넌스 작업이 다 그랬듯이 비동기적인 백그라운드 프로세스 형태로 스케쥴링되어 동작함.
- 컴팩션 과정은 간단함.
  - 여러 개의 테이블(sstable)을 고름
  - 병합 (병합 방식은 앞에서 설명)
    - 중복된 키를 가졌다면 가장 최신 값만 남기고, 오래된 값은 폐기
  - 병합된 내용을 새로운 파일로 저장
- 압축된 내용과 기존 내용을 원자적으로 교체해야 정합성이 보장됨.

![image.png](%E1%84%80%E1%85%A9%E1%84%80%E1%85%B3%E1%86%B8%20%E1%84%87%E1%85%A2%E1%86%A8%E1%84%8B%E1%85%A6%E1%86%AB%E1%84%83%E1%85%B3%20%E1%84%89%E1%85%B3%E1%84%90%E1%85%A5%E1%84%83%E1%85%B5%2013%E1%84%8C%E1%85%AE%E1%84%8E%E1%85%A1%20244998e1b70980a7ba15f441b6290d10/image%203.png)

그림 7-3은 다중 컴포넌트 LSM 트리의 데이터 생명 주기를 보여줍니다. 데이터는 먼저 메모리 상주 컴포넌트에 버퍼링됩니다. 그것이 너무 커지면, 그 내용은 디스크 상주 테이블을 생성하기 위해 디스크에 플러시됩니다. 나중에 여러 테이블이 함께 병합되어 더 큰 테이블을 만듭니다.

- 앞에서 봤던 것과 비슷. memtable에 쓰기 요청을 버퍼링
- memtable이 일정 크기에 도달하면 플러시. 매번 새로운 sstable로 저장 (서브트리 교체 X)
- 여러 개의 sstable을 주기적으로 병합

이 챕터의 나머지 부분은 멀티 컴포넌트 LSM 트리, 블록 생성, 메인터넌스 과정에 대해서 다룰 예정

### In-memory tables

멤테이블(Memtable) 플러시는 주기적으로, 또는 크기 임계값을 사용하여 트리거될 수 있습니다. 플러시되기 전에 멤테이블은 스위치(switch)되어야 합니다: 새로운 멤테이블이 할당되어 모든 새로운 쓰기의 대상이 되고, 기존의 것은 플러싱 상태로 이동합니다. 이 두 단계는 원자적으로 수행되어야 합니다. 플러싱 중인 멤테이블은 그 내용이 완전히 플러시될 때까지 읽기용으로 계속 사용할 수 있습니다. 이후, 기존 멤테이블은 새로 작성된 디스크 상주 테이블을 위해 폐기되고, 이 새 테이블은 읽기용으로 사용 가능해집니다.

- 멤테이블은 두 가지 조건 하에 플러시됨
  - 특정 주기에 따라서 → 항상 크기 기반으로 하게 되면 너무 오랫동안 메모리에 머물게 되는 문제 생김
  - 특정 크기 임계값에 따라서
- 스위치 동작 → 플러시를 시작하기 전에 스위치라는 걸 수행함
  - 먼저 플러시 도중에 들어오는 쓰기 요청을 받기 위해 새로운 memtable을 생성함
  - 기존 memtable은 flushing 상태가 됨
- 이 스위치를 구성하는 두 동작은 원자적으로 수행돼야 함 → 그렇지 않으면 새로운 쓰기 요청이 유실될 수도 있음
- flushing 중인 기존 memtable은 아예 안 쓰이냐? 아님. 읽기에도 쓰임
  - 왜? 특정한 데이터에 대한 읽기 요청에 대하여, 최신 데이터는 flushing memtable 혹은 current memtable 둘 다에 존재할 수 있음
  - 따라서 flushing과 current 둘 다 조회 후 비교하여 최신 값을 결정해야 함
  - 이를 통해 플러싱 중에도 동시성 읽기 요청을 처리할 수 있음
- 플러시 이후 새로운 테이블이 생성되면 flushing table은 더 이상 읽기 요청에도 쓰이지 않게 되며 그 역할은 새로운 sstable이 대체하게 됨. 그리고 기존 flushing memtable은 폐기됨

그림 7-4에서는 LSM 트리의 구성 요소, 그들 사이의 관계, 그리고 그들 사이의 전환을 수행하는 작업들을 볼 수 있습니다:

현재 멤테이블

쓰기를 수신하고 읽기를 처리합니다.

플러싱 멤테이블

읽기용으로 사용 가능합니다.

디스크 상의 플러시 대상

내용이 불완전하므로 읽기에 참여하지 않습니다.

플러시된 테이블

플러시된 멤테이블이 폐기되자마자 읽기용으로 사용 가능해집니다.

압축 중인 테이블

현재 디스크 상주 테이블들을 병합하고 있습니다.

압축된 테이블

플러시된 테이블이나 다른 압축된 테이블로부터 생성됩니다.

![image.png](%E1%84%80%E1%85%A9%E1%84%80%E1%85%B3%E1%86%B8%20%E1%84%87%E1%85%A2%E1%86%A8%E1%84%8B%E1%85%A6%E1%86%AB%E1%84%83%E1%85%B3%20%E1%84%89%E1%85%B3%E1%84%90%E1%85%A5%E1%84%83%E1%85%B5%2013%E1%84%8C%E1%85%AE%E1%84%8E%E1%85%A1%20244998e1b70980a7ba15f441b6290d10/image%204.png)

- 쓰기 요청이 들어오면 현재 멤테이블에 쌓임.
- 그러다가 두 조건 중 하나 만족하면 플러시를 해야 함
- 스위치를 준비함
  - 기존 멤테이블을 플러싱 멤테이블로 바꿈
    - 읽기 시에도 플러싱 멤테이블 참조함
  - 새로운 현재 멤테이블 (새로운 쓰기 요청을 받을) 을 추가
- 스위치 완료되면 플러시 수행
  - 플러시 타깃에 쓰기 수행됨
  - 플러시 타깃은 아직까지 읽기 대상이 아님. 불완전한 상태
- 플러시 완료되면 플러시드 테이블이 됨. 이제 읽기 가능
- 플러시드 테이블 많아지면 컴팩팅 수행
- 컴팩팅 완료되면 하나의 테이블로 바뀜

데이터는 이미 메모리에서 정렬되어 있으므로, 메모리 상주 내용을 디스크에 순차적으로 써서 디스크 상주 테이블을 생성할 수 있습니다. 플러시 중에는 플러싱 중인 멤테이블과 현재 멤테이블 모두 읽기용으로 사용할 수 있습니다.
멤테이블이 완전히 플러시될 때까지, 그 내용의 유일한 디스크 상주 버전은 쓰기 전용 로그(write-ahead log)에 저장됩니다. 멤테이블 내용이 디스크에 완전히 플러시되면, 로그를 트리밍(trim)할 수 있으며, 플러시된 멤테이블에 적용된 작업을 담고 있는 로그 섹션은 폐기될 수 있습니다.

- 멤테이블은 skiplist b-tree 같은 정렬된 구조. 그래서 키 순서 정렬되어있음.
- 정렬된 데이터 특징 덕분에 순차 쓰기가 가능함
- 플러시 중에도 읽기가 가능하다 (이 얘기를 몇 번째 하는 건지…)
- 멤테이블 플러시 될 때까지 신규 멤테이블의 쓰기 작업은 WAL에 저장됨
- 멤테이블 플러시가 끝나면 영속화된 것이므로 굳이 WAL을 유지할 필요 없음. WAL을 작게 유지하기 위해 트리밍, 즉 영속화된 부분에 해당하는 로그를 삭제함
