# 고급 백엔드 스터디 4주차

### Counting Keys

- B-Tree 구조에서 한 노드에 얼마나 많은 키와 자식 포인터를 저장할 수 있는지는 매우 중요
- 이때 사용되는 수식이나 표기 방식은 문헌마다 다름:
  - BAYER72
    - 디바이스마다 달라지는, 최적의 페이지 크기 k를 정의
    - 페이지는 최소 k, 최대 2k개의 키를 담을 수 있음
    - 페이지는 최소 k+1, 최대 2k+1개의 자식 노드 포인터를 담을 수 있음 (포인터 수 = 키 수 + 1)
    - 루트 페이지는 최소 1개, 최대 2k개의 키를 담을 수 있음
    - 이후 I이라는 값이 나옴. 비단말(nonleaf, 내부 노드) 페이지의 키는 l+1개의 키 가짐
      - 왜? → ‘모든 내부(비단말) 노드는 최소 l개의 키를 가져야 한다’ 라는 불변식에 쓰기 위해
  - GRAEFE11
    - 최대 N개의 키와 N+1개의 포인터로 설명
- 하지만 결국 얘기하고자 하는 바는 같음. 이 책에서는 더 명확하게 표현하기 위해 키의 개수를 N으로 표기
- 번외
  - 노드라고 해놓고 페이지라는 말 쓰는 이유?
    - 결국 논리적 단위(트리 자료구조, 노드)와 물리적 단위(디스크 기반 저장소, 페이지) 일치시키기 위함.
    - 디스크 기반 B 트리에서는 결국 둘 다 고려해야 함 → 사실상 같은 대상을 뜻함.

### B-Tree Node Splits

- 삽입 / 갱신 방법
  - 리프 노드를 찾아 삽입할 위치를 결정함
  - 키와 값을 해당 리프에 삽입 시도
  - 갱신의 경우 조회 알고리즘 따라서 키에 새로운 값 연결
- 노드가 가득 찬 경우(오버플로우):
  - 리프 노드: 키-값 쌍이 N개일 때, 하나 더 넣으면 N+1로 초과 → 분할 필요
  - 비리프 노드: 포인터가 N+1개일 때, 하나 더 넣으면 N+2로 초과 → 분할 필요
- 분할 방식
  - 새 노드 할당
  - 기존 노드의 절반 데이터를 새 노드로 이동
  - 중간값을 부모 노드로 승격(promote)시켜 삽입
  - 이때 “분할 지점(split point)“은 기준이 되는 중간 인덱스

재귀적 전파로 인한 루트 노드 분할 예시

- 단계 1: 초기 상태

```
                [40]
               /     \\
         [10, 20]   [50, 60]
```

- 단계 2: [10, 20] 리프 노드에 30 삽입 (오버플로우 발생)

```
                [40]
               /     \\
      [10, 20, 30]   [50, 60]
```

- 단계 3: [10, 20, 30] 분할 → 20 승격

```
                [20, 40]
               /    |    \\
           [10] [20, 30] [50, 60]
```

- 단계 4: [50, 60]에 70 삽입 → [50, 60, 70] 오버플로우 발생

```
                [20, 40]
               /    |     \\
          [10] [20, 30] [50, 60, 70]
```

- 단계 5: [50, 60, 70] 분할 → 60 승격, 부모 [20, 40] → [20, 40, 60] 오버플로우 발생

```
                [20, 40, 60]
             /    |     |     \\
        [10] [20, 30] [50] [60, 70]
```

- 단계 6: 내부 노드 [20, 40, 60] 분할 → 40 승격, 루트 변경

```
                   [40]
                  /     \\
              [20]       [60]
             /    \\     /    \\
         [10] [20, 30] [50] [60, 70]
```

- 설명 해설
  - 책 설명
    - "트리가 전체 용량에 도달하면 (즉, 분할이 루트까지 전파되면), 루트 노드도 분할해야 합니다."
    - "루트 노드가 분할되면, 분할 지점 키를 가진 새로운 루트가 할당되고, 이전 루트는 절반만 항목을 가진 상태로 강등되어 새로 생성된 형제 노드와 함께 하위 레벨로 내려갑니다."
    - "이로 인해 트리의 높이가 1 증가하게 됩니다."
    - "루트 노드가 분할되어 새로운 루트가 생성되거나, 두 노드가 병합되어 새 루트를 형성할 때 트리의 높이가 변경됩니다. 리프 및 내부 노드 레벨에서는 트리는 수평 방향으로만 확장됩니다."
  - 예시
    - 단계 6에서 루트 노드 [20, 40, 60] 이 오버플로우 되어 분할이 발생함
    - 가운데 키 40이 새로운 루트가 되어 위로 올라감
    - 기존 루트는 [20], [60] 내부 노드로 강등되어 루트 아래 자식이 됨
    - 루트 노드 분할 → 트리 높이 1 증가. 수직 방향 확장
    - 그 외 노드 (리프, 내부) 분할 → 수평 방향 확장

![image.png](%E1%84%80%E1%85%A9%E1%84%80%E1%85%B3%E1%86%B8%20%E1%84%87%E1%85%A2%E1%86%A8%E1%84%8B%E1%85%A6%E1%86%AB%E1%84%83%E1%85%B3%20%E1%84%89%E1%85%B3%E1%84%90%E1%85%A5%E1%84%83%E1%85%B5%204%E1%84%8C%E1%85%AE%E1%84%8E%E1%85%A1%201f7998e1b70980899901fb73fae94ed5/image.png)

노드 분할 4단계

1. 새 노드를 할당합니다.
2. 분할되는 노드에서 절반의 요소를 새 노드로 복사합니다.
   - 여기서 오른쪽 부분의 첫 번째 키가 분할 키가 됨
3. 분할된 노드의 부모 노드에 구분 키와 새 노드에 대한 포인터를 추가합니다.
4. 새 요소를 알맞은 노드에 삽입합니다.
   - 분할 이후에는 부모 노드와 복사된 서브트리를 연결해야 함
   - 어떻게? → 분할 키를 부모 노드로 승격시켜서 분할 키의 오른쪽 포인터와 연결
   - 만약 부모 노드가 꽉 차있다면?
     - 일단 지금 하는 작업은 다 끝냄 → 오버플로 상태
     - 이후 부모 노드 오버플로 해소 위해 부모 노드에서도 분할 수행

### B-Tree Node Merges

- 삭제 / 언더플로우 발생
  - 삭제는 리프 노드에서 키-값을 제거하는 것으로 시작됨
  - 삭제 후 노드 점유율이 너무 낮으면 언더플로우 발생
  - 언더플로우가 발생하면 병합 또는 재분배 필요
- 병합 조건 (underflow)
  - 노드 하나 당 최대 키 or 키-값 쌍 개수 N에 대하여
  - 리프 노드: 인접한 두 노드의 키-값 쌍 합이 N 이하
  - 내부 노드: 인접한 두 노드의 포인터 합이 N+1 이하
  - 조건 만족 시 두 노드를 병합하고 부모로부터 분할 키를 하향시킴
  - 예시
    - 리프 노드 병합
      - 조건: 두 노드의 키-값 쌍 총합 ≤ N
      - 만족하는 경우 (N = 4)
        - A: [10] (1개)
        - B: [15, 20] (2개)
        - 총합 3 ≤ 4 → 병합 가능
        - 결과: [10, 15, 20]
      - 만족하지 않는 경우 (N = 4)
        - A: [10, 12] (2개)
        - B: [14, 16, 18] (3개)
        - 총합 5 > 4 → 병합 불가 → 리밸런싱 필요
    - 내부 노드 병합
      - 조건: 두 노드의 포인터 수 총합 ≤ N + 1
      - 만족하는 경우 (N = 4 → N+1 = 5)
        - A: [10] → 포인터 2개
        - B: [20, 30] → 포인터 3개
        - 총합 5 ≤ 5 → 병합 가능
        - 결과: [10, 20, 30] + 5 포인터
      - 만족하지 않는 경우 (N = 4 → N+1 = 5)
        - A: [5, 10] → 포인터 3개
        - B: [15, 20, 25] → 포인터 4개
        - 총합 7 > 5 → 병합 불가 → 리밸런싱 필요
- 병합 방식
  - 오른쪽 노드들을 왼쪽으로 몰아넣기 (반대도 가능, 정렬만 유지하면 됨)
  - separator key를 부모로부터 가져와 병합된 노드에 삽입 (내부 노드의 경우)
    - 이미 있다면 스킵
  - 부모 노드에서 오른쪽 노드에 대한 포인터 제거
  - 오른쪽 노드 제거
- 만약 부모 노드가 언더플로우에 빠진다면?
  - 병합 전파: 부모 노드도 병합 대상이 될 수 있음
  - 루트 노드가 병합되면 트리 높이가 1 감소함
  - 자식 하나만 남은 루트는 제거되고 그 자식이 새 루트가 됨
- 단계별 병합 예시
  - 단계 1: 리프 노드 [16, 18], [20, 25] 존재
  - 단계 2: 16 삭제 → [18], [20, 25]
  - 단계 3: 병합 조건 만족 → 왼쪽으로 병합하여 [18, 20, 25]
  - 단계 4: 부모 노드에서 20 아래로 내리기 → 이미 있으므로 스킵
  - 단계 5: 부모 노드도 언더플로우 → 병합 전파 가능

### Summary

- 배경 문제점
  - 이진 탐색 트리(BST)는 O(log N)의 탐색 복잡도를 제공하지만, 디스크에서는 실용적이지 않음
    - 이유:
      - 낮은 fanout (자식 수가 2)
      - 잦은 구조 변경(재배치, 포인터 갱신)
      - 디스크 I/O 관점에서 locality가 낮음
- B-Tree의 해결책
  - 높은 fanout을 통해 디스크 접근 횟수를 줄임 (많은 키/포인터를 한 페이지에 저장 가능)
  - 구조 변경(분할/병합)을 줄여 균형 유지 비용을 줄임
- B-Tree 알고리즘 개요
  - 탐색, 삽입, 삭제 시 루트에서 리프까지 단일 경로 탐색
  - 노드가 가득 찼을 때는 분할(split), 너무 비었을 때는 병합(merge) 수행
  - 삽입/삭제는 대부분 리프 수준에서 일어나며, 구조 변화는 필요한 경우에만 상위로 전파됨
- 실전 적용
  - 메모리 내 B-Tree 구성은 이 개념만으로도 가능
  - 디스크 기반 B-Tree는 다음 챕터에서 나올 페이지 배치, 포인터 계산, 인코딩 방식 등을 고려해야 함

# Chapter 3. File Formats

## File Formats

- 챕터 소개
  - 이전 장까지는 B-트리의 추상적인 작동 방식(분할, 병합 등)을 다루었음
  - 이제는 디스크에 실제로 어떻게 구현되는지를 살펴볼 예정
- 메모리 vs 디스크 접근 차이
  - 메모리는 OS가 가상 메모리로 관리하기 때문에 개발자가 직접 오프셋을 관리할 필요 없음
  - 반면 디스크는 시스템 콜을 통해 접근하고, 파일 내부의 오프셋을 명시적으로 지정해야 함
- 디스크 구조 설계의 요구사항
  - 디스크는 위와 같이 오프셋 지정 접근 + 해석 과정이 필요하므로, 효율적 파일 포맷이 필요
  - 어떻게? → 생성 / 수정 / 메모리 해석 쉬워야 함
- 단순한 이해와 실제 구현의 차이
  - B-트리의 동작 원리(예: 분할, 병합)를 이해하는 것은 이론적 영역
  - 실제 구현에는 페이지 구성, 포인터 관리, 데이터 재배치 등 다양한 요소가 함께 고려되어야 함
- 포인터 관리 시멘틱스
  - 디스크 상에서는 포인터가 메모리 주소가 아니라 파일 내 오프셋임
  - 따라서 B-트리는 ‘페이지 집합’으로 구성된 구조로 이해해야 함
    - 사실 앞에서도 노드와 페이지 표현을 혼용해서 사용했었음
- 앞으로의 방향성
  - B-Tree의 복잡성은 대개 가변성(mutability) 때문
  - 페이지 레이아웃, 분할, 재배치, 가변 데이터 구조에 대한 구현 세부사항 논의
  - 변경 가능한 구조를 대상으로 슬롯 페이지 레이아웃, 페이지 분할 등 구현 세부사항 설명할 것
  - (뒤에서 등장할) LSM Tree의 복잡성은 정렬성 및 유지보수성 때문 → 이것도 소개 예정

## Motivation

- 파일 포맷 만들기 vs 비관리형 메모리 모델 언어(C가 대표적. 앞으로는 해당 표현을 C로 대체해서 사용)에서 자료구조 만들기 예시 비유
- 어떻게 하나?
  - malloc 같은 걸로 메모리 블록을 확보하고
  - 이걸 `int`, `char[10]`, `float` 등의 고정 크기 원시 타입과 구조체를 사용하여 분할함
  - 만약 더 큰 메모리 덩어리나 가변 크기 구조체 사용한다면 → 포인터 사용하여 참조
- 차이점 1 - GC, 단편화
  - C에서는 개발자가 메모리를 직접 할당하지만, OS나 런타임이 단편화, 연속성 등은 어느 정도 자동으로 관리해주기 때문에, 할당 / 해제에만 집중하면 됨.
  - 하지만 디스크에서는 GC나 단편화 문제를 직접 처리해야 함
- 차이점 2 - 데이터 레이아웃 중요도
  - 메모리는 랜덤 엑세스 빠름 → 데이터 배치 무관하게 거의 같은 시간에 접근 가능
  - 디스크는 순차 엑세스가 랜덤 엑세스 대비 매우 빠름 → 데이터 배치가 중요 (이전 장의 로컬리티 개념)
  - HDD vs SSD 특성, 직렬화/역직렬화 (엔디안니스, 고정 / 가변 타입) 고려
- 주기억장치 (메인 메모리) 에서의 차이
  - 메모리 단에서는 레이아웃 문제 심각 X → 즉시 접근 가능하기 때문
  - 가변 길이 필드 (문자열) / 초과 크기 데이터 (BLOB 같이 한 페이지에 안 들어가는 것들) → 메모리 할당 + 포인터로 해결 가능
  - 특수한 경우에는 메모리 레이아웃 최적화 필요
    - CPU 캐시 라인 → 캐시는 메모리 주소를 태그, 인덱스, 오프셋 순서로 나눠서 해석함. 따라서 연속된 데이터를 인접하게 배치하면 같은 캐시 라인에 위치하므로 캐시 히트율 향상
    - 프리페칭 → 다음에 접근할 메모리를 미리 캐시에 가져옴. 따라서 순차적 배치 하면 굿
- 고려사항
  - 운영 체제/파일 시스템이 처리하는 일
    - 파일 I/O 제공 (read, write), 버퍼 캐시 관리, 오프셋 추상화
  - 개발자가 직접 신경 써야 하는 부분
    - 데이터 레이아웃 설계: 페이지 구조, 고정/가변 필드 배치
    - 오프셋 관리: 포인터 대신 바이트 위치 계산
    - 공간 회수: 삭제된 영역 추적, 단편화(defragmentation) 처리
    - 디스크 성능 고려: 순차 vs 랜덤 접근, 지역성 확보
    - 버전 및 무결성 처리: 파일 버전 정보, 체크섬(CRC) 적용
  - 자주 발생하는 함정
    - 오프셋 계산 오류, 엔디안 불일치, 동시성 충돌
    - 공간 낭비(삭제 후 미재사용), 무결성 검사 누락

### (번외) 캐시 라인 + 태그가 메모리 주소 상위 비트인 이유 by chatgpt deep research

- 캐시에 접근하기 위해 메모리 주소를 tag + index + offset으로 나눔
- 가령 32비트 주소 공간에, 캐시 라인의 크기는 64B이고 이게 1024개 존재한다면
  - 태그 → 16비트 (32 - 10 - 6 = 16) → 어떤 메모리 블럭인지
    - 캐시 인덱스가 같더라도 다른 메모리 블럭일 수 있음
  - 인덱스 → 10비트 (1024개 = 2^10) → 몇 번째 캐시 라인인지
  - 오프셋 → 6비트 (64B = 2^8B) → 하나의 라인에서 몇 번째 바이트인지

태그를 주소의 상위 비트에 두고 인덱스를 그 아래, 중간 비트에 배치하는 이유는 캐시 매핑 충돌을 줄여 성능을 향상시키기 위해서입니다. 주소를 태그-인덱스-오프셋 순으로 해석하는 설계는 해시 테이블에서 좋은 해시 함수를 설계하는 방식과 유사합니다. 연속된 메모리 접근 시에도 캐시 인덱스들이 고르게 분포되도록 하여, 동일 인덱스에 여러 블록이 몰려 발생하는 충돌(cache collision)을 최소화하려는 목적이 있습니다. 사용자의 가설대로, 태그를 상위 비트에 두는 설계는 같은 인덱스로 매핑되는 블록들의 주소 분포 다양성을 높여 충돌을 완화하려는 의도와 맞닿아 있습니다.

일반적인 프로그램은 시간적·공간적 지역성을 가지므로, 메모리 상에서 연속된 주소 영역을 순차적으로 접근하는 경우가 많습니다. 이러한 순차 접근에서는 메모리 주소의 최상위 비트들이 잘 변하지 않는 경향이 있습니다. 만약 인덱스에 상위 비트를 사용하고 태그에 중간 비트를 사용한다면, 큰 범위 내의 많은 주소들이 동일한 인덱스로 매핑될 위험이 있습니다. 예컨대 연속된 여러 메모리 블록이 모두 같은 캐시 세트에 몰리게 되어, 캐시에 새로운 블록이 들어올 때 기존 블록을 밀어내는 충돌 미스(conflict miss)가 자주 발생할 수 있습니다.

반대로, 인덱스를 주소의 중간 비트로 설계하면 연속된 주소들이 캐시의 서로 다른 세트들로 분산될 가능성이 높아집니다. 메모리 주소가 블록 크기 경계를 넘어설 때 인덱스 비트가 하나 증가하면서 다음 세트로 넘어가게 되므로, 이웃한 메모리 블록들이 서로 다른 인덱스를 갖게 됩니다. 이는 해시 함수가 입력의 하위 비트 변화에도 해시 값이 고르게 분산되도록 설계된 것과 비슷합니다. 결과적으로 연속된 블록 접근 시에도 캐시 세트들이 고르게 사용되어 특정 세트에 데이터가 몰리는 현상을 막을 수 있습니다.

예를 들어, 12비트 주소 공간에서 오프셋 4비트, 인덱스 4비트로 구성된 캐시를 생각해 보면, 주소 0x248과 0x250을 연속 접근할 경우 일반적인 태그-인덱스 구조에서는 인덱스가 각각 0x4와 0x5로 서로 다른 세트에 매핑되어 충돌을 피할 수 있습니다. 그러나 인덱스를 상위 비트로 사용하는 가상의 구조에서는 두 주소가 같은 인덱스 0x2로 매핑되어 충돌이 발생할 수 있습니다. 이처럼 태그와 인덱스 필드의 위치를 바꾸면 연속된 주소들이 캐시에서 충돌을 일으키기 쉬워져 전체 성능이 저하될 수 있습니다.

요약하자면, 태그를 상위 비트에 두는 설계는 캐시 충돌을 줄여 효율을 높이기 위한 핵심적인 전략입니다. 실제로 캐시 인덱싱에 중간 또는 하위 비트를 사용하는 것이 연속된 메모리 블록들을 여러 세트로 골고루 분산시켜 캐시 활용도를 높이고 성능을 개선하는 데 효과적입니다. 따라서 인덱스→오프셋→태그 순서가 더 직관적으로 보이더라도, 실제 성능 면에서는 태그를 상위 비트로 두는 것이 훨씬 유리합니다.

## Binary Encoding

- 디스크에 데이터를 저장하려면 어떻게 해야 할까?
  - 그냥 메모리에 저장하듯 하면 안 됨
    - 디스크는 메모리처럼 동적으로 공간을 할당하거나 해제할 수 없음
    - 오직 “읽기(read)“와 “쓰기(write)“만 가능함
- 그래서 필요한 게 바로 데이터 레이아웃
  - 데이터를 어떻게 저장할지 미리 정해둔 구조
  - 바이너리 포맷 혹은 레이아웃(layout)이라고 부름
- 이런 레이아웃은 왜 중요할까?
  - 저장 공간을 아낄 수 있음 (컴팩트함)
  - 데이터를 빠르고 쉽게 읽고 쓸 수 있음 (직렬화/역직렬화 쉬움)
- 본격적으로 페이지 구조를 만들기 전에 알아야 할 것들
  - 키와 값을 바이너리로 어떻게 표현할지
  - 여러 값을 묶어서 복합 구조로 어떻게 만들지
  - 길이가 다른 데이터(문자열, 배열 등)는 어떻게 표현하고 읽을지

### Primitive Types

엔디안

- 키와 값은 타입을 가진다
  - 예: 정수, 날짜, 문자열
  - 이 타입에 맞게 바이너리로 직렬화하고, 다시 역직렬화해서 원래 값으로 복원할 수 있음
- 숫자 타입은 일반적으로 고정된 크기로 저장됨
  - 예: int는 4바이트, long은 8바이트 등
- 여러 바이트를 가진 수는 엔디안(endianness)을 고려해야 함
  - 같은 숫자도 바이트 순서에 따라 디스크에 다른 방식으로 저장됨
  - 인코딩(저장)과 디코딩(읽기) 시 같은 순서를 써야 정확한 값 복원 가능
- 엔디안의 두 종류
  - 빅 엔디안 (big-endian)
    - 가장 큰 단위 바이트(MSB)가 먼저, 즉 앞쪽 주소에 저장됨
    - 사람의 읽기 순서와 비슷 (큰 자리부터)
  - 리틀 엔디안 (little-endian)
    - 가장 작은 단위 바이트(LSB)가 먼저, 즉 앞쪽 주소에 저장됨
    - x86, ARM 등 현대 CPU에서 널리 사용
- 예시 - 64비트 정수 바이트 순서
  - RocksDB 같은 시스템은 플랫폼마다 엔디안 방식이 다를 수 있으므로, 이 플랫폼이 리틀 엔디안인지 아닌지를 먼저 판단함
  - EncodeFixed64WithEndian 함수가 kLittleEndian 값을 참조
    - 이를 기준으로 현재 데이터의 엔디안과 플랫폼의 엔디안이 일치하는지 확인
  - 불일치하는 경우
    - 바이트 순서를 EndianTransform이라는 로직으로 뒤집음 → 데이터를 바이트 단위로 역순으로 읽어서 하나씩 결과에 이어붙임

직렬화 / 역직렬화 고려

- 필요성
  - 메모리에서는 다양한 타입으로 데이터를 표현할 수 있으나, 디스크나 네트워크로 전송할 때는 반드시 바이트 배열(byte sequence)로 변환해야 함
  - 데이터를 저장하거나 전송하려면 직렬화 필요, 다시 사용하려면 역직렬화 필요
- 원시 숫자 타입의 바이트 크기
  - byte: 8비트 (1바이트)
  - short: 16비트 (2바이트)
  - int: 32비트 (4바이트)
  - long: 64비트 (8바이트)
- 부동소수점 표현 방식
  - IEEE 754 표준 기반
  - float (32비트): 1비트 부호 + 8비트 지수 + 23비트 분수
  - double (64비트): 더 높은 정밀도를 제공하는 배정도 표현
  - 계산된 값은 정확한 수치가 아니라 근사값
- 프로그래밍 언어와 표준 라이브러리
  - 대부분의 언어에서 IEEE 표준을 따르며, 해당 표준에 맞는 부동소수점 인코딩/디코딩 함수를 라이브러리로 제공

### Strings and Variable-Size Data

- 고정 크기 원시 타입 (primitive numeric types)
  - int, float 같은 원시 숫자 타입은 크기가 고정되어 있음 (예: int는 4바이트)
  - 이런 값들은 메모리상에서도 동일한 크기를 차지하므로 직렬화가 단순함
- 복합 데이터 구성 (struct 등)
  - 여러 개의 원시 값을 조합해서 구조체처럼 사용할 수 있음
  - 포인터나 고정 크기 배열을 이용해서 더 큰 구조를 구성함
- 문자열 직렬화 방식
  - 문자열은 고정 크기가 아니므로, 길이 + 실제 데이터로 표현함
    - 예: size(2바이트) + data(byte[size])
  - 이를 Pascal 문자열 또는 UCSD 문자열이라고 부름
- Pascal String vs Null-Terminated String
  - Pascal 방식:
    - 처음에 길이를 써두므로 문자열 길이 파악이 O(1) (빠름)
    - 데이터가 중간에 null 문자(0x00)를 포함해도 문제가 없음
  - Null 종료 방식:
    - C 언어에서 흔히 사용하는 방식 ("hello\0")
    - 끝나는 지점을 찾기 위해 전체 문자열을 순회해야 함 → 느릴 수 있음
- 왜 Pascal 방식이 좋나?
  - 데이터 조작 및 검색 시 빠름
  - 바이트 배열에서 슬라이스만으로 문자열 생성 가능 → 성능 굿, 쉬움

### Bit-Packed Data: Booleans, Enums, and Flags

- 불리언 → 1비트이지만, 1바이트 단위로 묶어서 효율적으로 저장
- 열거형 → 값 집합을 정수로 매핑. 낮은 카디널리티(== 가능한 값의 수)에서 유용
- 플래그
  - 여러 불리언 상태를 하나의 정수로 표현하는 기법
  - 각 비트(bit)에 상태 하나씩 할당
  - packed booleans와 enums의 혼합 개념
  - 이때 각 상태는 상호배타적이지 않음 → 즉 동시에 여러 개의 상태 가져도 됨 (1번 비트가 A, 2번 비트가 B이면 A이면서 not B인 상태를 가지는 것 등이 가능)
  - 이때 비트 마스크를 사용하여 특정 위치의 의미를 나타냄
    - `int IS_LEAF_MASK= 0x01h;`
    - 즉 `IS_LEAF_MASK` 는 1번째 비트를 담당
    - 0x01 = 0000 0001 → 1번째 비트의 의미는 리프 노드인지 여부를 보겠다는 뜻
  - 비트 설정
    - 위의 비트 마스크에 대하여 OR 연산 적용
    - `flags |= HAS_OVERFLOW_PAGES;` → flags에 대하여 해당 비트마스크가 담당하는 비트를 1로 만들겠다는 뜻. 즉 이 플래그의 HAS_OVERFLOW_PAGES를 참으로 만들겠다
    - `flags |= (1 << 2);` → `1 << 2`는 1을 왼쪽으로 2칸 쉬프트. 0000 0100 = 0x04. 즉 2번째 인덱스의 비트를 1로 설정하겠다 라는 뜻이며 위의 명령어와 동작은 동일
  - 비트 해제
    - `flags &= ~HAS_OVERFLOW_PAGES;` → 해당 비트마스크를 반전시킨 뒤 &= 적용하여 0인 자리만 0으로 초기화, 1인 자리는, 그대로 두겠다. 즉 해당 비트마스크에서 담당하는 위치만 0으로 두고 나머지는 유지하겠다
    - `flags &= ~(1 << 2);` → `(1 << 2)`는 0000 0100 이고, `~(1 << 2)` 는 1111 1011 이므로 &= 적용하면 위와 동일한 이야기
  - 비트 검사
    - `is_set = (flags & HAS_OVERFLOW_PAGES) != 0;` → 플래그와 비트마스크의 & 연산 통해서 해당 비트마스크에서 담당하는 부분, 즉 단일한 1의 위치에 대하여 & 연산 수행. 그러면 비트마스크의 위치에 해당하는 flags의 비트 값만 남는다. 이게 1이면 1 ≠ 0 이므로 is_set은 참, 아니라면 false
