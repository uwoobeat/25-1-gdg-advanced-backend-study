# 고급 백엔드 스터디 3주차

# Chapter 2. B-Tree Basics

- 이전 장에서 우리는 저장 구조를 두 가지로 분류함 → 가변(mutable) 구조 vs 불변(immutable) 구조
  - 불변성은 이러한 두 구조의 설계 및 구현의 핵심 개념임
  - 대부분의 가변 저장 구조는 ‘제자리 갱신(in-place update)’ 메커니즘을 사용 → 데이터의 원래 위치에서 직접 수정하는 방식
- 스토리지 엔진은 동일한 데이터 레코드의 여러 버전이 존재하도록 허용
  - MVCC → 트랜잭션마다 자신만의 데이터 버전을 읽게 하여, 락 없이 동시성 제어를 허용 (이런 게 있다, 나중에 등장)
  - 슬롯 기반 페이지 구조 (slotted page organization) → 데이터 레코드 CUD 시 그 자리가 아닌 페이지 내 다른 위치에서 수행하면서, 과거 버전도 일시적으로 존재
  - 하지만 이 장에서는 간단한 설명을 위해서 1) 각 키는 오직 하나의 레코드만 가지며 2) 하나의 고정된 위치에 저장된다고 가정
- B-Tree
  - 가장 널리 사용되는 저장 구조 (MySQL InnoDB, PostgreSQL, SQLite)
  - 오래된 역사를 가지고 있음 → 1971년 처음 도입, 1979년까지 B-Tree 변형(B+- Tree, B\*-Tree) 등장
  - B-Tree를 알아보기 전에, 기존 트리(BST, 2-3 트리, AVL 트리)들이 가지는 한계점들을 알아볼 것임

## Binary Search Tree

- BST(Binary Search Tree)란?
  - 메모리 내에서 정렬된 구조로 데이터를 보관하는 트리 자료구조
  - 노드 구성
    - 키 (key): 검색 기준
    - 값 (value): 키에 매핑되는 데이터
    - 좌우 자식 노드에 대한 포인터 2개 → 그래서 binary(이진)
  - 루트 노드는 트리의 진입점이며, 반드시 하나만 존재
  - 데이터 탐색 시, 루트부터 시작해 왼쪽/오른쪽 자식 노드를 따라 내려감
- BST의 특징
  - 왼쪽 서브트리의 모든 키 < 현재 노드의 키 < 오른쪽 서브트리의 모든 키
  - 이 특징으로 탐색 시에 키의 크기 비교만으로 어느 방향으로 내려갈지 결정 가능
  - 이진 탐색 트리의 정렬 특성과 탐색 성능은 이 특징에 의존함
  - 실질적으로 이 구조는 검색뿐 아니라 삽입·삭제 시에도 기준이 됨
- 값의 탐색
  - 최솟값 찾기
    - 루트에서 왼쪽 포인터만 따라가면 가장 작은 키를 가진 노드 도달
  - 최댓값 찾기
    - 루트에서 오른쪽 포인터만 따라가면 가장 큰 키를 가진 노드 도달
  - 값 저장 위치
    - BST에서는 모든 노드에 값 저장 가능 (루트, 내부 노드, 리프 모두 포함)
  - 탐색 종료 시점
    - 원하는 키를 상위 노드에서 찾으면 그 즉시 탐색이 종료되며, 항상 리프까지 갈 필요는 없음

### Tree Balancing

![image.png](%E1%84%80%E1%85%A9%E1%84%80%E1%85%B3%E1%86%B8%20%E1%84%87%E1%85%A2%E1%86%A8%E1%84%8B%E1%85%A6%E1%86%AB%E1%84%83%E1%85%B3%20%E1%84%89%E1%85%B3%E1%84%90%E1%85%A5%E1%84%83%E1%85%B5%203%E1%84%8C%E1%85%AE%E1%84%8E%E1%85%A1%201ee998e1b7098083848dd6744cb723e3/image.png)

- 삽입의 불균형성
  - 삽입 순서에 따라 트리 형태가 달라짐
  - 예를 들어, 오름차순 정렬된 값을 순서대로 삽입하면 한쪽으로만 길게 늘어진 트리가 만들어짐
- 편향 트리(Pathological tree)
  - 트리인데도 실제로는 연결 리스트처럼 작동하는 비정상적 구조
- 성능 저하
  - 일반적으로 BST는 O(log N) 탐색 성능을 기대하지만… (a)
  - 편향 트리는 O(N) 으로 성능 저하 발생 (b)
- 트리 균형의 중요성
  - 현실적으로는 모든 엔트리가 한 쪽으로만 쏠릴 가능성은 낮음
  - 하지만 일부 노드가 쏠리는 현상은 빈번
  - 검색 속도를 위해 트리를 균형있게 유지해야 함
- 균형 이진 트리
  - 정의
    - 전체 노드 수 N에 대하여 트리 높이가 $log_{2}{N}$ 이고
    - 좌우 서브트리의 높이 차이 ≤ 1
  - 예시 - balanced
    ```
            4
          /   \
         2     6
        / \   / \
       1   3 5   7
    ```
    - N = 7이고 가능한 log₂ N ≈ 2.8 → 높이 3 이하이면 이상적
    - 루트 노트 4의 왼쪽/오른쪽 서브트리 높이 모두 2
    - 전체 높이 3 = log₂ 7 ≈ 2.8
    - 왼쪽/오른쪽 트리 높이 차이 ≤ 1 → 균형 만족
  - 밸런싱 하지 않으면?
    - BST의 성능 상 이점 잃게 됨
    - 삽입 / 삭제에 따라 트리 구조 결정됨
  - 균형 이진 트리의 성능
    - 균형 트리는 각 노드를 따라갈 때마다 탐색 공간이 반으로 줄어듦 → 탐색 성능이 O(log N)으로 보장됨.
    - 불균형 트리에서는 일부 경로가 너무 길어질 수 있음 → 최악의 경우 선형 탐색 시간(O(N))과 같아짐. 마치 링크드 리스트처럼

![image.png](%E1%84%80%E1%85%A9%E1%84%80%E1%85%B3%E1%86%B8%20%E1%84%87%E1%85%A2%E1%86%A8%E1%84%8B%E1%85%A6%E1%86%AB%E1%84%83%E1%85%B3%20%E1%84%89%E1%85%B3%E1%84%90%E1%85%A5%E1%84%83%E1%85%B5%203%E1%84%8C%E1%85%AE%E1%84%8E%E1%85%A1%201ee998e1b7098083848dd6744cb723e3/image%201.png)

- 균형 트리를 유지하려면?
  - 각 연산 후에 트리 구조를 점검하고 조정
  - 대표적 방법 중 하나 → 노드 추가 / 삭제 시 마다 회전(rotation)
  - 목표 → 트리 높이 최소화, 양쪽 가지의 노드 수 적절히 유지
- 회전(rotation) 예시
  - 연속된 두 노드가 각각 하나의 자식만 갖는 경우
  - 중간 노드를 중심으로 회전시켜 높이 차를 줄임
  - 예시의 중간 노드인 3을 회전 기준(rotation pivot)으로 설정
  - 피벗 노드는 한 단계 높은 트리 레벨로 승격
  - 원래 부모 노드는 오른쪽 자식이 됨

### Trees for Disk-Based Storage

- BST(Binary Search Tree)는 디스크 기반 저장소와 잘 맞지 않음
- 세 가지 이유 있음
  - 낮은 fanout으로 인한 잦은 변경
    - 낮은 fanout (노드 당 최대 자식 수) → 노드당 자식이 2개뿐임
    - 그로 인한 잦은 변경. 팬아웃이 낮으면 → 균형 유지, 노드 재배치, 포인터 업데이트 자주 수행
    - 잦은 변경은 디스크 환경에서 불리. 메모리에서는 포인터 조작이 빠르지만, 디스크에서는 데이터 접근이 느리고 단위가 큼(블록 단위).
  - 지역성(locality) 문제
    - 지역성이란? 관련된 데이터가 물리적으로 가까운 위치에 저장되는 것
    - 왜?
      - BST는 요소들을 임의의 순서로 추가함
      - 새로 생성된 노드가 부모 근처에 저장된다는 보장 X
      - 자식 노드에 대한 포인터가 여러 디스크 페이지에 걸쳐 분산됨 → 한 번의 탐색에서 여러 번의 디스크 페이지 로딩 발생
    - 대안
      - Paged Binary Tree: 여러 노드를 하나의 디스크 페이지에 그룹핑하여 저장
      - 이렇게 하면 자식 노드를 따라가는 포인터가 동일 페이지 내에 존재할 가능성 증가 → 디스크 접근 최소화
  - 낮은 fanout으로 인한 트리의 높이
    - 이진 트리의 fanout(각 노드가 가질 수 있는 자식 노드 수)은 2이므로, 높이가 커짐 (N개 요소에 대해 높이 $log_{2}{N}$)
    - 이떄 원하는 요소를 찾기 위해서는 $O(log_{2}{N})$ 회의 seek 필요
      - 예를 들어 1,000개의 노드를 가진다면 최악의 경우 log₂(1000) ≈ 10번의 seek가 필요함
    - 이때 문제는 디스크에서 각 seek마다 디스크 접근이 발생하므로 성능이 저하됨 (각 노드의 포인터를 따라 자식 노드의 물리적 위치로 이동해야 하기 때문)
    - 메모리에서는 포인터 접근이 빠르므로 fanout이 작아도 상관 없지만, 디스크에서는 seek 비용이 높아서 fanout이 작으면 불리함
    - 2-3 트리 및 다른 낮은 fanout을 가진 트리들도 마찬가지임
- 결론
  - 단순한 방식의 BST(== Paged Binary Tree 같은 것들 제외한 BST)는 지역성(locality)을 고려 X → (키의) 비교 횟수만큼의 디스크 접근 발생
  - 따라서 지역성을 고려한 자료구조를 찾아야 함
  - 디스크에 더 적합한 트리 자료구조의 특징
    - 높은 팬아웃: 한 노드가 많은 자식을 가질수록 같은 디스크 페이지 내에 더 많은 노드가 저장되어 지역성이 향상됨
    - 낮은 트리 높이: 트리의 높이가 작아지면 디스크 탐색 횟수도 줄어들어 성능 개선됨
  - 둘은 사실 같은 말
    - 같은 데이터에 대하여, 팬아웃이 크면 → 하나의 노드에 더 많은 자식 노드를 담을 수 있기 때문에 전체 노드 수가 줄고 → 트리의 높이도 낮아짐
    - Q. 같은 데이터인데 fanout 값만 바꾼다고 전체 노드 수가 줄어드는 건 아니지 않나? 같은 데이터면 전체 노드 수는 항상 같아야 하는 건 아닌가?→ ㄴㄴ. 가정이 틀렸음. 하나의 노드가 가지고 있는 키 데이터 개수가 더 많아지기 때문. 자세한 건 강의에서 설명 예정

## Disk-Based Structures

- 디스크 기반 저장소
  - week1 메모리 기반 vs 디스크 기반 저장소 섹션에서 언급한 바 있음
  - 저장 매체(메모리 vs 디스크)의 차이에 따른 DBMS의 차이에 대해 다루었음
  - 마찬가지로 저장 매체에 따른 자료구조의 적합성 차이에 대해서도 다룰 수 있음
- 저장매체별 자료구조 적합성
  - 위 섹션에서 봤듯이, 모든 자료구조가 디스크 기반 저장소에 적합한 것 아님
  - 영속적 저장 매체 (디스크, 비휘발성 메모리) 한계 (블록 단위 IO, 느린 랜덤 엑세스, 상대적으로 느린 IO) 를 고려하여 자료구조 조정 필요 → 어떻게?
- 온디스크 자료구조에 대해서는…
  - 데이터 양이 커지면 모든 데이터를 메모리에 적재 불가
  - 메모리에는 전체 데이터 일부만 올라갈 수 있음 (~= 캐시될 수 있음)
  - 나머지 데이터는 디스크에 존재 → 디스크 IO 효율성을 고려한 설계 필요

### Hard Disk Drives

- 스토리지의 하드웨어 변화에 따른 알고리즘 변화
  - 대부분의 전통적 알고리즘은 HDD 환경에 최적화됨
    - HDD 환경 → 느린 랜덤 엑세스, 빠른 순차 엑세스
  - 이후 플래시 메모리(SSD)가 발전하면서 알고리즘에도 변화 발생
    - SDD 환경 → 빠른 랜덤 엑세스
    - 이 알고리즘은 해당 하드웨어의 내장 기능을 활용 (SSD 내부의 채널 / 다이 구조 및 병렬 IO)
  - 최근에는 NVM 같은 바이트 주소 지정 가능(byte-addressable) 저장장치 등장
    - 기존의 블록 기반이 아닌, 완전히 새로운 자료구조 등장 (ex: FPTree, BzTree)
- HDD의 특징
  - HDD 구조
    - 자기 디스크가 회전하고, 그 위를 움직이는 읽기/쓰기 헤드로 구성되어 있음
  - 섹터란?
    - HDD의 최소 전송(transfer) 단위
    - 즉 특정 바이트만 필요하더라도 HDD는 섹터 단위로 IO를 수행해야 함
    - 전통적으로는 512B, 최근에는 4KB
  - access time
    - 원하는 데이터가 있는 트랙의 위치로 헤드를 이동시키고 (seek time)
    - 디스크를 회전시켜 대상 섹터 시작 위치에 도달한 뒤 (rotational delay)
    - 대상 섹터를 읽음 (transfer time)
  - 이중 seek time + rotational delay가 access time에서 dominant함
    - 연속된 섹터에 위치한 바이트를 읽는다면 transfer time만 걸림 → 낮은 비용
    - 따라서 HDD에서는 순차 엑세스(sequential access)가 훨씬 좋다
- [읽어보면 좋은 자료 1](https://www.reddit.com/r/hardware/comments/5bp2rt/dohddsreadsimultaneouslyfrommultipleplatters)
- [읽어보면 좋은 자료 2](https://electronics.stackexchange.com/questions/643792/why-do-hard-disks-use-only-one-head-at-a-time)

### Solid State Drive

- SSD는 기계적 부품이 없음
  HDD와 달리 디스크 회전, 암(arm) 이동, 헤드 배치 과정이 없음 → 랜덤 접근 속도가 매우 빠름
- SSD의 물리적 구성 계층
  1. Cell: 데이터를 저장하는 최소 단위 (1셀 = 1~4bit 저장 가능, SLC/MLC/TLC 등)
  2. String: 여러 개의 셀을 직렬로 연결한 구조
  3. Array: 여러 개의 스트링을 병렬로 연결한 구조
  4. Page: 읽고 쓸 수 있는 최소 단위 (보통 4~16KB)
  5. Block: 삭제 가능한 최소 단위, 여러 페이지로 구성됨 (보통 64~512 페이지)
- 이 계층 구조는 나중에 설명될 Flash Translation Layer (FTL) 및 Garbage Collection의 핵심이 됨

![image.png](%E1%84%80%E1%85%A9%E1%84%80%E1%85%B3%E1%86%B8%20%E1%84%87%E1%85%A2%E1%86%A8%E1%84%8B%E1%85%A6%E1%86%AB%E1%84%83%E1%85%B3%20%E1%84%89%E1%85%B3%E1%84%90%E1%85%A5%E1%84%83%E1%85%B5%203%E1%84%8C%E1%85%AE%E1%84%8E%E1%85%A1%201ee998e1b7098083848dd6744cb723e3/image%202.png)

- 셀의 비트 수 (SLC/MLC/TLC)
  - SLC (Single-Level Cell): 1비트 저장 → 빠르고 안정적이지만 용량 적음
  - MLC (Multi-Level Cell): 2비트 저장 → 용량 증가, 성능은 감소
  - TLC (Triple-Level Cell): 3비트 저장 → 더 저렴하지만 속도와 내구성은 낮음
- 페이지(Page): SSD에서 데이터를 읽고 쓰는 최소 단위
  → 일반적으로 4KB가 많지만, 장치에 따라 2~16KB까지 존재
- 블록(Block): SSD에서 삭제(erase)할 수 있는 최소 단위
  → 보통 64~512개의 페이지를 포함. 즉, 하나의 블록 ≈ 수백 KB ~ 수 MB
- 플레인(Plane): 블록들을 묶은 단위. 병렬처리 가능
- 다이(Die): 하나의 실리콘 칩 내부에 존재하는 독립적인 저장 유닛
  → SSD 하나가 여러 개의 다이를 가질 수 있음 → 병렬성 향상
- 이 계층 구조는 쓰기 성능, GC 효율, 웨어 레벨링(Wear Leveling) 등에 큰 영향을 줌
- 읽기/쓰기 최소 단위 = 페이지
  SSD는 단일 페이지 단위로 데이터를 읽고 쓸 수 있음
- 쓰기 제약 – 셀은 ‘빈 상태여야’ 쓸 수 있음
  - NAND 플래시는 기존 데이터를 덮어쓸 수 없음
  - 이미 쓰인 셀을 수정하려면 먼저 블록 전체를 삭제해야 함
    → SSD 쓰기 동작은 사실상 “삭제 후 새로 쓰기”의 반복
- 삭제 단위 = 블록 (Erase Block)
  - 하나의 블록에는 수십~수백 개의 페이지가 들어 있음
  - 블록 단위로만 지울 수 있으므로, 불필요한 데이터까지 같이 삭제될 수 있음
- 빈 블록의 페이지는 순차적으로만 쓰기 가능
  - SSD의 내부 제약으로 인해 빈 블록을 쓸 때는 페이지 번호 순서대로만 가능
  - 중간 페이지를 건너뛰고 쓰는 건 허용되지 않음 \\\* 매우 중요
  - 이 순차성은 SSD 내부 병렬성과 쓰기 증폭(write amplification)에도 영향
- 플래시 메모리 컨트롤러 (Flash Memory Controller)
  - SSD 내부에서 CPU와 플래시 메모리 사이의 I/O 요청을 처리하는 중앙 제어 장치
  - 주요 기능
    - 주소 매핑 (FTL: Flash Translation Layer)
      - 논리 주소를 실제 물리 주소로 매핑
      - 쓰기/삭제 제약을 극복하기 위한 주소 재매핑 수행
    - 가비지 컬렉션 (Garbage Collection)
      - 삭제된 페이지가 포함된 블록에서 유효 데이터만 복사
      - 기존 블록 삭제 후 재사용 가능하게 만듦
    - 웨어 레벨링 (Wear Leveling)
      - 플래시 셀의 수명 한계를 고려하여 쓰기 위치를 균등하게 분산
      - 특정 셀의 조기 마모를 방지
    - ECC (Error Correction Code)
      - 데이터 오류를 검출 및 복구
      - 셀 밀도가 높아질수록 중요도 증가
    - 캐시 및 병렬 처리 제어
      - DRAM 캐시로 매핑 테이블 및 자주 쓰는 데이터 가속
      - 여러 채널, 다이, 플레인 병렬 제어로 속도 향상
- FTL (Flash Translation Layer)
  SSD의 핵심 컴포넌트 중 하나로, 논리 주소 ↔ 물리 주소 매핑을 수행
  → 사용자는 단순히 “페이지 1234”를 요청하지만, 실제로는 FTL이 그것을 SSD 내부 블록/페이지로 찾아줌
- 추적 기능
  - 비어 있는 페이지
  - 이미 쓰인 페이지
  - 폐기(discarded)된 페이지 → 나중에 삭제할 수 있는 후보
- Garbage Collection (GC)
  - 삭제 가능한 블록을 선택함
  - 아직 살아있는(live) 데이터가 있다면 복사 → 재매핑(remap)
  - 이후 전체 블록 삭제 (Erase)
  - 삭제된 블록은 새로운 쓰기용 공간으로 재활용됨
- HDD와 SSD는 모두 ‘블록 단위’로 데이터를 읽고 씀
  - 개별 바이트 단위가 아니라, ‘최소 읽기/쓰기 단위’인 블록(block) 이 기본 단위임
  - 예: HDD의 섹터, SSD의 페이지
- 운영체제의 블록 장치 추상화(block device abstraction)
  - 내부 하드웨어의 복잡성을 감추고, 일관된 I/O 인터페이스를 제공
  - 예를 들어, read() 요청이 4바이트만 필요하더라도 실제로는 해당 바이트가 포함된 전체 블록(보통 4KB 등)이 읽힘
- 이는 디스크 기반 데이터 구조 설계 시 반드시 고려해야 할 요소
- SSD는 랜덤 I/O와 시퀀셜 I/O의 성능 차이가 크지 않음
  - HDD는 기계적 움직임 때문에 차이가 크지만, SSD는 반도체 기반이라 접근 시간이 거의 일정함
  - 하지만 완전히 같지는 않고, 연속된 페이지를 읽을 때 프리페치와 병렬 읽기 덕분에 더 빠를 수 있음
- GC는 기본적으로 백그라운드에서 실행되지만, 상황에 따라 foreground 쓰기와 경합이 발생
  - 특히 다음과 같은 경우에 쓰기 지연(latency spike) 이 발생할 수 있음
    - 랜덤하고 비정렬된 쓰기가 자주 발생할 때
    - 여유 블록이 부족한 상황에서 강제 GC가 수행될 때
  - 결과적으로 GC는 쓰기 성능을 불안정하게 만들 수 있음
- GC 완화 전략
  - 쓰기를 최대한 연속적이고 정렬된 형태로 수행 (Sequential Write) → 불변성
  - 한 번에 전체 블록 단위로 쓰기를 유도 (Write Amplification 감소) → 버퍼링
- 성능 최적화 전략
  - “전체 블록 단위로 쓰기” = 쓰기 I/O의 단위 비용을 낮춤
  - “같은 블록에 대한 쓰기를 모아서 한 번에 수행” = SSD 내부 구조와 GC 비용을 고려한 효율화
- 이후 장에서 소개할 버퍼링(Buffering), 불변성(Immutability) 은 이러한 쓰기 비용 문제를 해결하는 핵심 전략임

## On-Disk Structure

- 디스크 기반 구조(on-disk structures) 를 설계할 때 고려해야 할 핵심 제약 조건
- 가장 중요한 사실: 디스크는 바이트 단위가 아니라 블록 단위로 접근함
  - 예: 특정 위치의 값만 필요한 경우라도, 전체 블록을 읽어야 함
- 따라서 설계자는 이 특성을 활용할 수 있는 방향으로 데이터 구조를 배치해야 함
- 온디스크 포인터는 메모리에서 사용하는 포인터와는 다름
  - 메모리에서는 주소값 자체가 직접적인 참조이지만
  - 디스크에서는 파일 오프셋 등을 수동 계산해서 참조해야 함
- 포인터 체인이 길어지면 유지 관리가 복잡해지고 성능에도 부정적
  - 예: A가 B를 가리키고, B가 C를 가리키고, C가 D를 가리키는 구조는 느리고 복잡
- 따라서 설계 목표는 다음과 같음
  - 디스크 접근 횟수를 줄이는 것
  - 인접한 데이터끼리 묶어서 배치하는 것 (locality 향상)
  - 페이지 간 이동이 적도록 포인터의 수나 범위를 최소화하는 것

---

- 포인터의 일반적 의미
  - 어떤 데이터 위치를 참조하기 위한 수단
  - 일반적으로 다음 동작 흐름을 연결하기 위해 사용
- 메모리 포인터
  - 실제 RAM 주소를 직접 참조함
  - CPU가 해당 주소를 직접 디코딩해 접근
  - 매우 빠르고 직접적인 접근
    - 예: C/C++의 int\* ptr = &x;
  - 운영체제가 주소 공간을 관리하므로, 프로그래머는 복잡한 계산 없이 사용 가능
- 온디스크 포인터
  - 실제 주소가 아닌 논리적 위치 정보를 표현
    - 페이지 번호, 오프셋, 파일 내 바이트 위치 등
  - 직접 참조가 불가능하며, 명시적인 연산과 I/O 동작이 필요
    - 예: seek(fd, offset) → read(...)
  - 데이터 접근까지의 과정
    - 포인터 값 기반으로 디스크 오프셋 계산
    - 해당 블록을 전체 읽기
    - 블록 내 원하는 위치 파싱
  - 보통 다음 형식 중 하나로 구현됨
    - 페이지 번호 + 블록 내 오프셋
    - 파일 내 절대 위치 오프셋
- 의미상의 차이
  - 메모리 포인터
    - 즉시 참조 가능
    - OS와 CPU가 주소 변환 및 접근을 자동 처리
  - 온디스크 포인터
    - 지시된 위치까지 명시적 I/O 연산 필요
    - 애플리케이션 코드에서 직접 계산 및 파일 접근 필요
- 성능 및 구현 차이
  - 메모리 포인터
    - 수 ns 단위로 빠름
    - dereferencing은 한 번에 끝남
  - 온디스크 포인터
    - 수 ms 단위까지 걸릴 수 있음 (seek + read)
    - 전체 블록을 읽고 내부 파싱해야 함
- 관리상의 어려움
  - 메모리 포인터
    - 비교적 단순, 시스템에 의해 자동 유지
  - 온디스크 포인터
    - 포인터 수가 많거나 의존성 체인이 길어지면
      - 코드가 복잡해지고 유지보수가 어려워짐
      - 포인터 갱신 시 디스크 내 다른 영역도 변경 필요
    - 따라서
      - 포인터 수를 줄이고
      - 동일 블록 안에 필요한 정보를 최대한 함께 배치하는 것이 중요
- 설계적 시사점
  - 온디스크 구조 설계 시
    - 디스크의 블록 단위 접근 제약을 고려해야 함
    - 지역성(locality) 을 높이는 방향으로 구조를 배열
    - 페이지 간 포인터 수를 최소화 하여 구조 단순화 및 성능 최적화

---

- 온디스크 오프셋이란?
  - 디스크 상에서 특정 데이터가 저장된 위치를 나타내는 값
  - 바이트 오프셋, 페이지 번호, 블록 내 위치 등의 형태로 존재
- “사전에 계산된다”는 의미
  - 포인터를 디스크에 먼저 기록해야 하는 상황에서
    - 나중에 어떤 데이터를 어떤 위치에 저장할지를 미리 계획해야 함
    - 예: 인덱스 노드에서 자식 노드의 위치를 가리키는 포인터를 먼저 써야 하는 경우
  - 따라서
    - 파일 내 구조나 배치 순서를 사전에 정하고
    - 그 순서를 기반으로 오프셋 값을 계산
    - 예: 자식 노드는 항상 부모 뒤 4096바이트에 위치시킴 → offset = parent_offset + 4096
- “메모리에 캐시되었다가 플러시된다”는 의미
  - 구조를 한 번에 디스크에 쓰는 것이 효율적이기 때문에,
    - 포인터나 노드들을 먼저 메모리 내에 임시 저장(캐싱) 함
    - 그 후 적절한 시점에 한꺼번에 디스크로 기록(플러시) 함
  - 장점
    - 디스크 쓰기 횟수 감소
    - 디스크 정합성 관리가 용이함
  - 관련 개념
    - write buffer / write-ahead log
    - dirty page tracking → flush
- 상황에 따른 전략 선택
  - 포인터가 먼저 기록되어야 한다면
    - 오프셋을 사전 계산해서 저장
    - 구조적 계획이 필요함
  - 데이터가 먼저 생성되었다면
    - 실제 위치를 기록한 뒤, 포인터는 메모리에 임시 저장 후
    - 위치 정보가 확정된 후 디스크에 기록
- 왜 이런 방식이 필요한가?
  - 디스크는 메모리처럼 자유롭게 쓰고 지우는 것이 어려움
    - 특히 overwrite보다 append가 쉬움 (SSD의 경우 erase 블록 단위)
  - 또한 디스크 접근은 느리므로
    - 가능하면 구조 전체를 메모리에서 구성한 후 일괄 쓰기가 유리함
- 예시: B-Tree 노드 쓰기 시나리오
  - 자식 노드를 먼저 디스크에 쓰고 그 위치를 부모 포인터에 기록하거나
  - 부모와 자식을 메모리에서 모두 구성한 후, 위치 계산을 통해 오프셋을 채움
  - 이후 전체 구조를 한 번에 플러시

---

- “의존성 체인(dependency chain)“이란?
  - 하나의 데이터를 찾기 위해 여러 개의 포인터를 순차적으로 따라가야 하는 구조
    - 예: A → B → C → D → 값
  - 각 노드 또는 블록이 다음 위치를 가리키며, 데이터를 얻기 위해 중간 단계들을 반드시 통과해야 함
- 왜 온디스크에서는 의존성 체인이 문제인가?
  - 디스크는 랜덤 접근 비용이 매우 크기 때문
    - 중간 노드 하나하나 접근할 때마다 디스크 seek + I/O latency 발생
  - 체인이 길어질수록
    - 디스크 접근 횟수가 선형적으로 증가
    - 성능은 심각하게 저하
  - 예: 트리 높이가 5인데 각 레벨마다 포인터를 따라가야 한다면, 최대 5번의 디스크 접근이 필요
- 코드 및 구조의 복잡성 증가
  - 포인터가 많아질수록
    - 포인터 업데이트 시 처리할 대상도 많아짐 (삽입/삭제 시 재배치 필요)
    - 구조 내 consistency 보장이 어려워짐
  - 예: 중간 블록이 손상되면 전체 경로가 단절됨 → 복구 어려움
  - 유지 보수 시 고려사항
    - 포인터 위치 계산
    - 구조 재정렬
    - 포인터 갱신 시 디스크 상의 다른 영역도 수정
- 포인터의 범위를 줄인다는 의미
  - 포인터가 가리키는 대상이 가까운 블록 안에 있도록 설계
    - 예: 동일 페이지 내에서 참조 → 디스크 접근 불필요
    - 페이지 간 이동을 최소화
  - 로컬리티(locality) 확보
    - 관련 데이터들을 같은 블록에 배치해 포인터 수와 이동 비용을 줄임
- 이상적인 설계 방향
  - 구조 내 포인터 수 자체를 최소화
  - 포인터가 가리키는 범위를 좁게 제한
  - 가능한 경우, 계층적 구조보다 평면적(flat) 구조 사용
    - 예: 페이징된 배열, offset 테이블 등
- 실제 적용 예시
  - B-Tree
    - 높은 fanout을 통해 트리 높이(= 의존 경로 길이)를 줄임
    - 각 노드 내 여러 키/포인터를 한 페이지에 저장 → 디스크 접근 1회당 많은 탐색 가능
  - SSTable (LSM 트리)
    - 테이블 자체는 정렬된 파일이므로 포인터 없음
    - 별도 index 구조 (sparse index)로 접근 최적화
  - inode 구조 (파일 시스템)
    - direct block 포인터 몇 개 + indirect block 1단계/2단계 제한
- 온디스크 저장에 적합한 데이터 구조의 조건
  - 핵심 조건
    - 높은 fanout: 하나의 노드가 많은 자식 노드를 가지면, 트리의 전체 높이를 줄일 수 있음
    - 낮은 height: 트리의 레벨 수가 적을수록 디스크 접근 횟수(= 성능 저하 요인)가 줄어듦
  - 추가로 고려해야 할 요소들
    - 포인터 자체가 공간을 차지하고
    - 트리 균형 유지 작업 시 포인터를 다시 계산해서 갱신하는 비용이 발생
  - B-Tree는 다음을 통해 이 문제들을 해결
    - 높은 fanout으로 트리의 레벨 수를 줄이고
    - 노드 포인터 수를 줄여 공간 오버헤드를 완화
    - 균형 유지가 드물게 발생하도록 설계

### Note: Paged Binary Trees

![image.png](%E1%84%80%E1%85%A9%E1%84%80%E1%85%B3%E1%86%B8%20%E1%84%87%E1%85%A2%E1%86%A8%E1%84%8B%E1%85%A6%E1%86%AB%E1%84%83%E1%85%B3%20%E1%84%89%E1%85%B3%E1%84%90%E1%85%A5%E1%84%83%E1%85%B5%203%E1%84%8C%E1%85%AE%E1%84%8E%E1%85%A1%201ee998e1b7098083848dd6744cb723e3/image%203.png)

- Paged Binary Trees는 일반적인 이진 트리를 디스크 환경에 맞게 최적화하기 위한 시도임
  - 여러 노드를 하나의 디스크 페이지에 함께 저장함으로써, 디스크 접근 횟수를 줄이려는 전략
- 이점
  - 다음 노드가 같은 페이지 내에 있다면 디스크 I/O 불필요
  - locality가 향상되어 성능에 긍정적인 영향
- 한계 및 문제점
  - 페이지 안에 노드를 정렬하는 것이 어렵고 유지비용이 큼
  - 무작위 삽입의 경우
    - 페이지가 자주 재조직됨 → 포인터 재계산 필요 → 복잡도 증가
  - 포인터 자체도 디스크에 공간을 차지하고 업데이트 시 비용 발생
- 요약
  - 지역성은 개선되지만 여전히 포인터 오버헤드와 유지관리 문제가 큼
  - Paged Binary Trees도 디스크 구조로는 비효율적일 수 있음

## Ubiquitous B-Trees

- B 트리 -> 균형 탐색 트리 기반 + 더 높은 fanout + 낮은 높이라는 점에서 BST와 다름

![image.png](%E1%84%80%E1%85%A9%E1%84%80%E1%85%B3%E1%86%B8%20%E1%84%87%E1%85%A2%E1%86%A8%E1%84%8B%E1%85%A6%E1%86%AB%E1%84%83%E1%85%B3%20%E1%84%89%E1%85%B3%E1%84%90%E1%85%A5%E1%84%83%E1%85%B5%203%E1%84%8C%E1%85%AE%E1%84%8E%E1%85%A1%201ee998e1b7098083848dd6744cb723e3/image%204.png)

- 시각적 표현 방식의 차이
  - BST 노드는 일반적으로 원형으로, B-Tree 노드는 사각형으로 표현.
- 그 이유는 노드의 구조적 복잡성에 있음
  - 이진 트리는 각 노드가 하나의 키, 두 개의 자식 → 단순 → 원으로 표현해도 충분
  - B-트리는 하나의 노드가 여러 개의 키와 포인터를 가짐 → 포인터와 키의 관계를 명확히 하기 위해 사각형 + 포인터 블록 형태로 그림

![image.png](%E1%84%80%E1%85%A9%E1%84%80%E1%85%B3%E1%86%B8%20%E1%84%87%E1%85%A2%E1%86%A8%E1%84%8B%E1%85%A6%E1%86%AB%E1%84%83%E1%85%B3%20%E1%84%89%E1%85%B3%E1%84%90%E1%85%A5%E1%84%83%E1%85%B5%203%E1%84%8C%E1%85%AE%E1%84%8E%E1%85%A1%201ee998e1b7098083848dd6744cb723e3/image%205.png)

- BST와 B-Tree의 공통/차이점
  - 포인터 탐색 구조는 둘 다 유사
    - 부모 노드에서 키 값을 기준으로 왼쪽 또는 오른쪽(또는 그 이상)의 자식 노드로 포인터를 따라 내려감
  - 주요 차이점은 균형 유지 방법에 있음
    - BST는 노드 단위로 균형 유지 (AVL, Red-Black 등)
    - B-Tree는 노드 내 다수의 키를 통해 fanout을 확보하고, split/merge로 균형을 유지
- B-트리의 정렬된 구조, 검색 효율성, 디스크 접근 최소화
  - 정렬된 키 배열 덕분에 각 노드 내에서는 이진 탐색이 가능 → log₂ n 복잡도
  - 전체 B-트리의 조회는 두 부분으로 나뉨
    - 노드 내부에서의 비교 횟수: log₂ N
    - 디스크 접근 횟수: 트리의 높이 (logₖ N, k = fanout)
  - 핵심 성능 최적화 포인트는
    - 한 노드당 수십~수백 개 항목 저장 → 트리 높이 작아짐 → 디스크 탐색 최소화
  - 예시에서 40억 개 항목 중 키 하나 찾는 데 32번 비교만 필요하다고 언급함 → B-트리의 스케일 효율성 강조
- B-트리의 주요 활용 예시 두 가지
  - 포인트 쿼리 (Point Query): 정확히 하나의 값을 찾는 쿼리
    - 예: SELECT \* FROM users WHERE id = 42
    - B-트리는 루트부터 리프까지 경로를 따라 정확한 키 위치를 찾음
  - 범위 쿼리 (Range Query): 조건에 부합하는 여러 값을 조회
    - 예: SELECT \* FROM orders WHERE amount >= 100 AND amount < 500
    - B-트리는 리프 노드들이 정렬된 상태이며, 일부는 형제 노드 포인터를 통해 연결되어 있기 때문에 효율적인 범위 스캔이 가능함
  - 이 두 가지 쿼리 유형을 모두 잘 처리할 수 있다는 점은 B-트리가 인덱스 구조로 널리 채택되는 이유

### B-Tree Hierarchy

![image.png](%E1%84%80%E1%85%A9%E1%84%80%E1%85%B3%E1%86%B8%20%E1%84%87%E1%85%A2%E1%86%A8%E1%84%8B%E1%85%A6%E1%86%AB%E1%84%83%E1%85%B3%20%E1%84%89%E1%85%B3%E1%84%90%E1%85%A5%E1%84%83%E1%85%B5%203%E1%84%8C%E1%85%AE%E1%84%8E%E1%85%A1%201ee998e1b7098083848dd6744cb723e3/image%206.png)

- 노드와 페이지의 개념이 동일하게 사용됨
  - B-트리는 디스크 페이지 단위로 구성되므로 노드를 페이지처럼 다룸
  - 실제 구현에서는 하나의 노드가 디스크 상의 하나의 페이지가 됨
- 점유율(Occupancy)
  - 노드가 수용할 수 있는 최대 키 수와 실제 포함된 키 수의 비율
  - 예: 최대 100개의 키를 저장할 수 있는데 현재 60개가 있다면 점유율은 60%
- 팬아웃(Fanout)
  - 팬아웃이 크면 트리 높이가 낮아지고, 디스크 탐색 횟수 줄어듦
  - 디스크 I/O에서 성능의 핵심은 탐색 횟수 줄이기
- 분할(split)과 병합(merge) 은 트리의 균형을 유지하기 위한 연산
  - 노드가 가득 차거나(overflow) 너무 비면(underflow) 구조 조정 발생
  - 높은 팬아웃은 이러한 구조 변경의 빈도를 줄여줌
- B-Tree vs B+-Tree의 주요 차이
  - B-Tree는 모든 노드에 값 저장 가능
  - B+-Tree는 값은 리프 노드에만 저장, 내부 노드는 검색을 위한 키만 포함
- B+-Tree의 장점
  - 리프 노드에만 값이 있어 구조가 균일함
  - 범위 검색(range scan) 시 리프 노드를 선형으로 탐색 가능 → 매우 효율적
  - 디스크 기반 구조에 적합 (리프 노드에만 I/O 발생)
- 실제 구현에서는 B+-Tree를 “B-Tree”라고 부르는 경우 많음
  - 예: MySQL InnoDB의 B-Tree 인덱스는 사실 B+-Tree임
  - 즉, 실무에서 “B-Tree”라는 말이 나오면 B+-Tree를 지칭하는 경우가 일반적
- multiway tree는 팬아웃(fanout)이 높은 트리를 설명하는 다른 용어로 사용됨

### Separator Keys

![image.png](%E1%84%80%E1%85%A9%E1%84%80%E1%85%B3%E1%86%B8%20%E1%84%87%E1%85%A2%E1%86%A8%E1%84%8B%E1%85%A6%E1%86%AB%E1%84%83%E1%85%B3%20%E1%84%89%E1%85%B3%E1%84%90%E1%85%A5%E1%84%83%E1%85%B5%203%E1%84%8C%E1%85%AE%E1%84%8E%E1%85%A1%201ee998e1b7098083848dd6744cb723e3/image%207.png)

- 구분 키(separator key)란?
  - B-트리에서 각 노드는 여러 개의 키를 가지며, 이 키들은 자식 노드들이 담당할 키 범위를 분할하는 역할을 함
  - 이 키들을 기준으로 어떤 자식 노드를 탐색할지 결정할 수 있음
- 각 포인터의 의미
  - 포인터는 자식 노드를 가리킴
  - 포인터와 키 사이의 관계
    - 포인터 0 → 첫 번째 키보다 작은 값들
    - 포인터 1 → 첫 번째 키 이상 두 번째 키 미만
    - …
    - 마지막 포인터 → 마지막 키 이상
- 불변식(Ki-1 ≤ Ks < Ki) 설명
  - 특정 서브트리에 속한 키는 항상 해당 범위를 만족해야 함
  - 이 규칙이 B-트리의 탐색/삽입/삭제 알고리즘의 기반이 됨
- 이진 탐색이 가능한 이유
  - 키들이 정렬되어 있기 때문에, 각 노드 안에서 이진 검색(binary search) 을 통해 적절한 자식 포인터를 빠르게 결정할 수 있음
- 형제 노드 포인터(sibling pointers)의 존재 이유
  - B-트리는 트리 구조이기 때문에 다음 데이터를 찾으려면 일반적으로 부모 노드를 통해 탐색해야 함
  - 하지만 형제 노드 간 직접 연결이 있다면, 이 과정을 생략하고 바로 옆으로 이동 가능
- 리프 노드에서 주로 사용되는 이유
  - 리프 노드에 실제 데이터가 저장되기 때문 (B+-Tree)
  - 범위 쿼리(예: WHERE x BETWEEN 10 AND 20) 시, 리프 노드끼리 순차적으로 이동하며 결과 수집 가능
- 양방향 포인터(Double-linked list) 지원 시
  - 단순히 앞 노드뿐 아니라 이전 노드로도 이동 가능
  - 즉, 내림차순 정렬된 결과 조회나 역방향 탐색 구현 가능
- MySQL InnoDB나 PostgreSQL B-Tree 구현 등 주요 DBMS들도 리프 노드 간 연결을 지원함
- B-트리의 구축 방향
  - 대부분의 트리는 루트부터 시작하여 자식으로 내려가는(top-down) 방식으로 성장
  - 하지만 B-트리는 리프 노드부터 생성되고, 이후 필요에 따라 상위 노드(내부 노드, 루트 노드)가 추가됨 → bottom-up 방식
  - 예: 리프가 가득 차면 분할(split)되고, 상위 노드로 승격(promote)됨
- 리프 노드 수가 증가하면
  - 이를 연결하기 위한 중간 계층(내부 노드) 이 생김
  - 결국 트리의 높이도 증가
- 저장소 활용률(Storage Utilization)
  - 노드 내에 항상 여유 공간을 일부 확보해두기 때문에, 평균적으로 최대 수용량의 50% 이하까지 떨어질 수 있음
  - 하지만 이는 삽입/삭제 시의 효율성과 균형 유지를 위한 전략적 선택
- 높은 점유율(occupancy)
  - 노드가 거의 꽉 찬 상태
  - 성능에 악영향이 없으며, 오히려 디스크 공간을 더 효율적으로 활용할 수 있음

### B-Tree Lookup Complexity

- B-Tree의 조회 성능은 디스크 접근 횟수(블록 전송)와 노드 내 비교 횟수로 나눠서 볼 수 있음
- 전송 횟수 관점
  - 노드 하나에 여러 키가 저장되므로 각 자식 포인터를 따라갈 때 탐색 범위가 많이 줄어듦
  - 즉, 트리의 높이가 logₖ M 정도로 작아짐 (K = 노드당 자식 포인터 수, M = 트리 전체 키-값 쌍 수)
  - 트리의 높이는 곧 디스크 접근 횟수 = 블록 I/O 수
- 비교 횟수 관점
  - 노드 내부에서 이진 탐색을 사용함 → log₂ M 비교
  - 노드 크기가 클수록 비교할 키 수도 많아지지만, 이진 탐색을 통해 효율적으로 처리
- 로그의 밑이 달라도 결국 O(log M)으로 표기하는 이유
  - 로그 밑이 2이든 N이든 상수 차이일 뿐, 빅오 표기에서는 상수 배 차이는 생략함
- 예시
  - 어떤 B-Tree가 M = 4,000,000,000 (40억 개의 키)를 담고 있고
  - 각 노드는 N = 100개의 키를 담을 수 있다면
  - 대략적으로 트리의 높이는 log₁₀₀(4,000,000,000) ≈ 4 이며,
  - 즉 최대 4회의 디스크 접근(block read)만으로도 원하는 키에 접근할 수 있음을 의미

### B-Tree Lookup Algorithm

- 이 문단은 B-Tree에서 조회 알고리즘의 실제 동작 방식을 설명함
- 주요 과정
  1. 루트부터 시작해서 이진 탐색으로 적절한 분리 키(Separator Key)를 찾음
  2. 해당 키보다 작은/큰 범위로 연결된 자식 포인터를 따라 내려감
  3. 이 과정을 반복해 (B+-Tree 기준 데이터가 있는) 리프 노드에 도달
  4. 리프에서 찾는 키를 발견하거나, 없다면 predecessor(선행 키)를 반환
- 포인트 쿼리 (= 쿼리 조건: =)는 정확한 값만 찾고 끝남 (없다면 종료)
- 범위 쿼리 (e.g., >, <=)는 리프 노드에서 시작해서 형제 포인터(sibling pointer)를 따라 계속 이동
- 검색 성능의 핵심 요인
  - 루트에서 리프까지 한 번만 내려감 → 시간 복잡도는 트리의 높이에 비례
  - 노드 내부에 키가 정렬되어 있으므로 이진 탐색 가능
  - 리프 노드 사이에 포인터가 존재하여 범위 검색도 효율적
